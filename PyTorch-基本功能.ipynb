{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohBsx6xbr-H"
      },
      "source": [
        "# PyTorch-基本功能\n",
        "\n",
        "## 教學目標\n",
        "\n",
        "這份教學的目標是介紹 PyTorch，撰寫深度學習模型的函式庫。\n",
        "\n",
        "## 適用對象\n",
        "\n",
        "已經有基本的機器學習知識，且擁有 python、`numpy`、`matplotlib` 基礎的學生。\n",
        "\n",
        "若沒有先學過 python，請參考 [python-入門語法](./python-入門語法.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `numpy`，請參考 [numpy-基本功能](./numpy-基本功能.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `matplotlib`，請參考 [matplotlib-資料視覺化](./matplotlib-資料視覺化.ipynb) 教學。\n",
        "\n",
        "## 執行時間\n",
        "\n",
        "本教學全部執行時間約為 4.376506090164185 秒。\n",
        "\n",
        "|測試環境|名稱|\n",
        "|-|-|\n",
        "|主機板|X570 AORUS ELITE|\n",
        "|處理器|AMD Ryzen 7 3700X 8-Core Processor|\n",
        "|記憶體|Kingston KHX3200C16D4/16GX|\n",
        "|硬碟|Seagate ST1000DM003-1ER1|\n",
        "|顯示卡|GeForce RTX 2080|\n",
        "|作業系統|Ubuntu 18.04 LTS|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDTx3HZbr-I"
      },
      "source": [
        "## 大綱\n",
        "\n",
        "- [簡介](#簡介)\n",
        "- [安裝](#安裝)\n",
        "- [張量宣告](#張量宣告)\n",
        "- [張量取值](#張量取值)\n",
        "- [張量運算](#張量運算)\n",
        "- [創造張量](#創造張量)\n",
        "- [高維張量運算](#高維張量運算)\n",
        "- [維度運算](#維度運算)\n",
        "- [使用 GPU 運算](#使用-GPU-運算)\n",
        "- [深度學習](#深度學習)\n",
        "- [練習](#練習)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Hk28KHbr-I"
      },
      "source": [
        "## 簡介\n",
        "\n",
        "根據 [PyTorch 官方網站](https://pytorch.org/)（v1.4）：\n",
        "\n",
        "> PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "> \n",
        "> PyTorch 是一個開源的機器學習框架，能夠幫助加速從研究原型到商業應用的轉換過程。\n",
        "\n",
        "![PyTorch usage statistics](https://thegradient.pub/content/images/2019/10/ratio_medium-1.png)\n",
        "\n",
        "根據[統計](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)，PyTorch 在各大機器學習會議使用率逐年上升，使用者選擇 PyTorch 的原因為：\n",
        "\n",
        "- 簡單（Simplicity）\n",
        "    - 使用 `python` 作為介面\n",
        "    - 操作方法與 `numpy` 相似\n",
        "- 好用的介面（Great API）\n",
        "    - 沒有過多的抽象化\n",
        "- 效能（Performance）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwS9cuvXbr-I"
      },
      "source": [
        "## 安裝\n",
        "\n",
        "請參考 [PyTorch 官方網站](https://pytorch.org/get-started/locally/#start-locally)，並選擇適合的環境選項與安裝方法。\n",
        "\n",
        "本教學使用 `pip` 安裝 `torch`，選項如下：\n",
        "\n",
        "|選項|描述|選擇|\n",
        "|-|-|-|\n",
        "|PyTorch Build|請選**穩定版**避免未知錯誤|`Stable(1.4)`|\n",
        "|Your OS|依照**作業系統**來選擇|`Linux`|\n",
        "|Package|安裝 **PyTorch** 使用的方法|`Pip`|\n",
        "|Language|當前執行 **Python** 版本|`Python 3.6`|\n",
        "|CUDA|電腦上是否有 **GPU** 且支援 **CUDA 架構**|`10.1`|\n",
        "\n",
        "得到以下安裝指令：\n",
        "\n",
        "```sh\n",
        "pip install torch torchvision\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "_gQuDZD9cKaG",
        "outputId": "fbbfd3d6-78d8-4a37-e9c7-6e3ee556ed23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8q-VOUcbr-J",
        "outputId": "4ec36342-b15b-44a4-9e43-056826034819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version 2.0.0+cu118\n",
            "GPU-enabled installation? True\n"
          ]
        }
      ],
      "source": [
        "# 匯入 PyTorch 套件\n",
        "# 在 python 中的介面名稱為 torch\n",
        "import torch\n",
        "\n",
        "# 匯入 numpy 與 matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print((\n",
        "    'PyTorch version {}\\n' +\n",
        "    'GPU-enabled installation? {}'\n",
        ").format(\n",
        "    # 確認 torch 的版本\n",
        "    torch.__version__,        \n",
        "    # 確認是否有 GPU 裝置\n",
        "    torch.cuda.is_available() \n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Tensor\n",
        "程式語言框架通常有其主要的資料型態，像是 numpy 中的 ndarray。在 PyTorch 內則是叫做 tensor（張量）的一種資料型態。PyTorch 的所有操作和 numpy 都很相似，但重要的是 tensor 支援 CUDA 的硬體加速（GPU），使得 GPU 深度學習變得簡單可行。tensor 可以在GPU/CPU上傳輸：只要使用 `tensor.cuda(device_id)`\n",
        "即可以將 tensor 移動到第 `device_id` 個（0-indexed）的 GPU 核心上。或者 `tensor.cpu()`可以將 tensor 移動回到 CPU 上。另外一個更通用的方法是 `tensor.to(device)`。\n",
        "\n",
        "--- \n",
        "## 額外補充\n",
        "### 什麼是 GPU ？\n",
        "GPU全稱為圖形處理器（Graphics Processing Unit），是一種專門進行繪圖運算工作的微處理器。儘管GPU在遊戲中以3D渲染而聞名，但GPU相較於「傳統的專為通用計算而設計的CPU，具有數百或數千個核心，經過優化，可並行運行大量計算，對運行深度學習和機器學習算法尤其有用。GPU允許某些計算機比傳統CPU上運行相同的計算速度快10-100倍。\n",
        "\n",
        "### 什麼是CUDA？\n",
        "\n",
        "CUDA全稱為計算統一設備架構（Compute Unified Device Architecture），是NVIDIA（輝達）創建的平行計算平臺和應用程序編程接口模型。CUDA 平臺是一個軟件層，可直接訪問GPU的虛擬指令集和並行計算元素，以執行計算內核。因此，如果我們想利用 GPU 加速運行深度學習算法，那麼 CUDA 就是一個不可或缺的中間層，它代替我們直接和GPU硬體打交道，並對外開放接口。而 PyTorch 則對這層接口再次進行封裝，以方便程式設計人員使用。\n",
        "\n",
        "### 什麼是cuDNN？\n",
        "\n",
        "cuDNN 全稱為 CUDA 深度神經網絡庫（CUDA Deep Neural Network library），是 NVIDIA 打造的針對深度神經網絡的加速庫，是一個用於深層神經網絡的 GPU 加速庫。如果你要使用 GPU 訓練模型，cuDNN 不是必須的，但一般會採用這個加速庫。\n",
        "\n",
        "## 參考資料\n",
        "- [知乎：什麼是張量？& 深度學習](https://zhuanlan.zhihu.com/p/48982978)\n",
        "- [CUDA 入門, nvidia 公司官方網站](https://blogs.nvidia.com.tw/2020/10/27/cuda-refresher-getting-started-with-cuda/)\n",
        "- [CUDA、cuDNN、pytorch 安装分析](https://blog.csdn.net/weixin_38481963/article/details/105313471) \n",
        "- [NQU Tensor 介紹 slides](https://www.nqu.edu.tw/upload/educsie/attachment/529fa35c91b055e7da3c8dc7a9bc975e.pdf)\n"
      ],
      "metadata": {
        "id": "QQOYX-sffjQN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okJuKPxbr-J"
      },
      "source": [
        "## 張量宣告\n",
        "\n",
        "在 `torch` 中陣列稱為張量（Tensor），創造張量的語法為 `torch.tensor([value1, value2, ...])`。\n",
        "\n",
        "- 每個 `torch.Tensor` 都有不同的**數值型態屬性** `torch.Tensor.dtype`\n",
        "    - 必須透過 `torch.Tensor.dtype` 取得，無法透過 `type()` 取得\n",
        "- 可以指定型態\n",
        "    - 透過參數 `dtype` 指定型態\n",
        "    - 透過 `torch.LongTensor` 創造整數，預設為 `torch.int64`\n",
        "    - 透過 `torch.FloatTensor` 創造浮點數，預設為 `torch.float32`\n",
        "\n",
        "|`torch` 型態|`numpy` 型態|C 型態|範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.int8`|`numpy.int8`|`int_8`|-128~127|\n",
        "|`torch.int16`|`numpy.int16`|`int_16`|-32768~32767|\n",
        "|`torch.int32`|`numpy.int32`|`int_32`|-2147483648~2147483647|\n",
        "|`torch.int64`|`numpy.int64`|`int_64`|-9223372036854775808~9223372036854775807|\n",
        "|`torch.float32`|`numpy.float32`|`float`||\n",
        "|`torch.float64`|`numpy.float64`|`double`||\n",
        "\n",
        "- 每個 `torch.Tensor` 都有**維度屬性** `torch.Size`\n",
        "    - 呼叫 `torch.Tensor.size()` 來取得維度屬性\n",
        "    - `torch.Tensor.size` 本質是 `tuple`\n",
        "    - 張量維度愈高，`len(torch.Tensor.size)` 數字愈大\n",
        "- 可以使用 `torch.Tensor.reshape` 或 `torch.Tensor.view` 進行維度變更\n",
        "    - 變更後的維度必須要與變更前的維度乘積相同\n",
        "    - 變更後的內容為 **shallow copy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KGb8WQKbr-J",
        "outputId": "a05f52cc-4cf6-4ce6-baa0-73ce6a7ce6c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "True\n",
            "torch.int64\n",
            "\n",
            "tensor([1., 2., 3.])\n",
            "True\n",
            "torch.float32\n",
            "\n",
            "torch.int8\n",
            "torch.int16\n",
            "torch.int32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.float64\n",
            "\n",
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# 張量宣告\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t1 = torch.tensor([1, 2, 3])                           \n",
        "# 輸出 Tensor\n",
        "print(t1)                                              \n",
        "# 輸出 True\n",
        "print(type(t1) == torch.Tensor)                        \n",
        "# 輸出 torch.int64\n",
        "print(t1.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t2 = torch.tensor([1., 2., 3.])                        \n",
        "# 輸出 Tensor\n",
        "print(t2)                                              \n",
        "# 輸出 True\n",
        "print(type(t2) == torch.Tensor)                        \n",
        "# 輸出 torch.float32\n",
        "print(t2.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 各種 dtype\n",
        "# 輸出 torch.int8\n",
        "print(torch.tensor([1, 2], dtype=torch.int8).dtype)    \n",
        "# 輸出 torch.int16\n",
        "print(torch.tensor([1, 2], dtype=torch.int16).dtype)   \n",
        "# 輸出 torch.int32\n",
        "print(torch.tensor([1, 2], dtype=torch.int32).dtype)   \n",
        "# 輸出 torch.int64\n",
        "print(torch.tensor([1, 2], dtype=torch.int64).dtype)   \n",
        "# 輸出 torch.float32\n",
        "print(torch.tensor([1, 2], dtype=torch.float32).dtype) \n",
        "# 輸出 torch.float64\n",
        "print(torch.tensor([1, 2], dtype=torch.float64).dtype) \n",
        "print()\n",
        "\n",
        "# 宣告 LongTensor 變數\n",
        "t3 = torch.LongTensor([1, 2, 3])                       \n",
        "# 輸出 torch.int64\n",
        "print(t3.dtype)                                        \n",
        "\n",
        "# 宣告 FloatTensor 變數\n",
        "t4 = torch.FloatTensor([1, 2, 3])                      \n",
        "# 輸出 torch.float32\n",
        "print(t4.dtype)                                        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(4.)\n",
        "print(a)\n",
        "resa = torch.reshape(a, (2, 2))\n",
        "print(resa)"
      ],
      "metadata": {
        "id": "1G-IX1n6ckRw",
        "outputId": "fc8560d1-33a5-43da-ac6c-921b87b192da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3.])\n",
            "tensor([[0., 1.],\n",
            "        [2., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## view 和 reshape \n",
        "- 參考[官方網站連結](https://pytorch.org/docs/stable/tensor_view.html)，PyTorch allows a tensor to be a View of an existing tensor. `View` tensor shares the same underlying data with its base tensor. Supporting View avoids explicit data copy, thus allows us to do fast and memory efficient reshaping, slicing and element-wise operations.\n",
        "- ``torch.view(*shape)->Tensor``: Returns a new tensor with the same data as the self tensor but of a different shape. The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions $d,d+1,…,d+k$ that satisfy the following contiguity-like condition that $\\forall i = d, ... d+k-1$\n",
        "$$\n",
        "stride[i] = stride[i+1] \\times size[i+1]\n",
        "$$\n",
        "\n",
        "- ``torch.reshape(*shape)->Tensor``: \n",
        "Returns a tensor with the same data and number of elements as self but with the specified shape. This method returns a view if shape is compatible with the current shape. See ``torch.Tensor.view()`` on when it is possible to return a view.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "CaPUOTC7dhxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Kg9RgMObbr-K",
        "outputId": "7ce67e53-f074-4cad-f00f-3958a192bef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "torch.Size([4, 3])\n",
            "\n",
            "reshaped to (3,4): tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.Size([3, 4])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.Size([3, 4])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]])\n",
            "torch.Size([2, 6])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]])\n",
            "torch.Size([2, 6])\n",
            "\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[ 7,  8],\n",
            "         [ 9, 10],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 3, 2])\n",
            "\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[ 7,  8],\n",
            "         [ 9, 10],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "# size 屬性\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t5 = torch.tensor([               \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12],\n",
        "])\n",
        "\n",
        "# 輸出 Tensor\n",
        "print(t5)                         \n",
        "# 輸出 t5.size (4, 3)\n",
        "print(t5.size())                  \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(\"reshaped to (3,4):\", t5.reshape(3, 4))           \n",
        "# 輸出更改後的維度 (3, 4)\n",
        "print(t5.reshape(3, 4).size())    \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(3, 4))              \n",
        "# 輸出更改後的維度 (3, 4)\n",
        "print(t5.view(3, 4).size())       \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(t5.reshape(2, 6))           \n",
        "# 輸出更改後的維度 (2, 6)\n",
        "print(t5.reshape(2, 6).size())    \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(2, 6))              \n",
        "# 輸出更改後的維度 (2, 6)\n",
        "print(t5.view(2, 6).size())       \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(t5.reshape(2, 3, 2))        \n",
        "# 輸出更改後的維度 (2, 3, 2)\n",
        "print(t5.reshape(2, 3, 2).size()) \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(2, 3, 2))           \n",
        "# 輸出更改後的維度 (2, 3, 2)\n",
        "print(t5.view(2, 3, 2).size())    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy1L8FOqbr-K"
      },
      "source": [
        "## 張量取值\n",
        "\n",
        "與 `numpy` 語法概念相似。\n",
        "\n",
        "- 使用 `torch.Tensor[位置]` 來取得 `torch.Tensor` 中指定位置的值\n",
        "    - 若為**多個維度**的張量，則使用 `tuple` 來取得指定位置的值\n",
        "    - 若位置為**負數**，則等同於反向取得指定位置的值\n",
        "    - 取出的值會以 `torch.Tensor.dtype` 的形式保留\n",
        "- 使用 `torch.Tensor[起始位置:結束位置]` 來取得 `torch.Tensor` 中的部分**連續**值\n",
        "    - **包含起始位置**的值\n",
        "    - **不包含結束位置**的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用 `torch.Tensor[iterable]`（例如 `list`, `tuple` 等）來取得**多個** `torch.Tensor` 中的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用判斷式來取得 `torch.Tensor` 中的部份資料\n",
        "    - 經由判斷式所得結果也為 `torch.Tensor`\n",
        "    - 判斷式所得結果之 `torch.Tensor.dtype` 為**布林值** `bool`（`True` 或 `False`）\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "214IwVJEbr-K",
        "outputId": "daaee408-eeb4-4836-92c5-31eb8a5ffa20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2])\n",
            "tensor([3, 4, 5])\n",
            "tensor([6, 7, 8])\n",
            "tensor([6, 7, 8])\n",
            "tensor([ 9, 10, 11])\n",
            "\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor(5)\n",
            "tensor(11)\n",
            "tensor(10)\n",
            "tensor(8)\n"
          ]
        }
      ],
      "source": [
        "# 張量取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t6 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t6 中的第 0 個位置的值 [0, 1, 2]\n",
        "print(t6[0])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [3, 4, 5]\n",
        "print(t6[1])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [6, 7, 8]\n",
        "print(t6[2])        \n",
        "# 輸出張量 t6 中的第 -2 個位置的值 [6, 7, 8]\n",
        "print(t6[-2])       \n",
        "# 輸出張量 t6 中的第 -1 個位置的值 [9, 10, 11]\n",
        "print(t6[-1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t6 中的第 [0, 0] 個位置的值 0\n",
        "print(t6[0, 0])     \n",
        "# 輸出張量 t6 中的第 [0, 1] 個位置的值 1\n",
        "print(t6[0, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 1] 個位置的值 4\n",
        "print(t6[1, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 2] 個位置的值 5\n",
        "print(t6[1, 2])     \n",
        "# 輸出張量 t6 中的第 [-1, -1] 個位置的值 11\n",
        "print(t6[-1, -1])   \n",
        "# 輸出張量 t6 中的第 [-1, -2] 個位置的值 10\n",
        "print(t6[-1, -2])   \n",
        "# 輸出張量 t6 中的第 [-2, -1] 個位置的值 8\n",
        "print(t6[-2, -1])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TTmmlRLbr-K",
        "outputId": "4e0a0eee-0766-44c6-badb-1432de18717d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20])\n",
            "tensor([70, 80, 90])\n",
            "tensor([ 0, 10])\n",
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "\n",
            "tensor([[ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 1, 2]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "# 取連續值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t7 = torch.tensor([ \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t7 位置 0, 1, 2 但是不含位置 3 的值 [0, 10, 20]\n",
        "print(t7[0:3])      \n",
        "# 輸出張量 t7 位置 7, 8, 9 的值 [70, 80, 90]\n",
        "print(t7[7:])       \n",
        "# 輸出張量 t7 位置 0, 1 但是不含位置 2 的值 [0, 10]\n",
        "print(t7[:2])       \n",
        "# 輸出張量 t7 所有位置的值 [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "print(t7[:])        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t8 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t8 位置 0, 1, 但是不含位置 2 的值 [[0, 1, 2], [3, 4, 5]]\n",
        "print(t8[0:2])      \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 1, 2, 3 的值 [[3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[1:])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2]]\n",
        "print(t8[:1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[:])        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q5w2A_hbr-K",
        "outputId": "68f5efa5-01ab-4fd1-93b8-6eae16e59691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 20, 40, 60, 80])\n",
            "\n",
            "tensor([10, 30, 50, 70, 90])\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "\n",
            "tensor([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# 使用 iterable 取得多個值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t9 = torch.tensor([        \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t9 中偶數位置的值 [0, 20, 40, 60, 80]\n",
        "print(t9[[0, 2, 4, 6, 8]]) \n",
        "print()\n",
        "# 輸出張量 t9 中奇數位置的值 [10, 30, 50, 70, 90]\n",
        "print(t9[[1, 3, 5, 7, 9]]) \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t10 = torch.tensor([       \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 輸出張量 t10[0] 與 t10[1] 的值 [[1, 2, 3, 4] [5, 6, 7, 8]]\n",
        "print(t10[[0, 1]])         \n",
        "print()\n",
        "# 輸出張量 t10[0, 2] 與 t10[1, 3] 的值 [3, 8]\n",
        "print(t10[[0, 1], [2, 3]]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJBfUCkxbr-K",
        "outputId": "13257ce4-76d5-42cb-9b7f-7a45331e1c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False, False, False, False, False,  True,  True,  True,  True])\n",
            "torch.bool\n",
            "tensor([60, 70, 80, 90])\n",
            "tensor([ 0, 20, 40, 60, 80])\n"
          ]
        }
      ],
      "source": [
        "# 判斷式取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t11 = torch.tensor([      \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出每個值是否大於 50 的 `torch.Tensor`\n",
        "print(t11 > 50)           \n",
        "# 輸出 torch.bool\n",
        "print((t11 > 50).dtype)   \n",
        "# 輸出大於 50 的值 [60, 70, 80, 90]\n",
        "print(t11[t11 > 50])      \n",
        "# 輸出除以 20 餘數為 0 的值 [0, 20, 40, 60, 80]\n",
        "print(t11[t11 % 20 == 0]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x72LPvvtbr-K"
      },
      "source": [
        "## 張量運算\n",
        "\n",
        "### 純量運算（Scalar Operation）\n",
        "\n",
        "對張量內所有數值與單一純量（Scalar）進行相同計算。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`torch.Tensor + scalar`|張量中的每個數值加上 `scalar`|\n",
        "|`torch.Tensor - scalar`|張量中的每個數值減去 `scalar`|\n",
        "|`torch.Tensor * scalar`|張量中的每個數值乘上 `scalar`|\n",
        "|`torch.Tensor / scalar`|張量中的每個數值除以 `scalar`|\n",
        "|`torch.Tensor // scalar`|張量中的每個數值除以 `scalar` 所得之商|\n",
        "|`torch.Tensor % scalar`|張量中的每個數值除以 `scalar` 所得之餘數|\n",
        "|`torch.Tensor ** scalar`|張量中的每個數值取 `scalar` 次方|\n",
        "\n",
        "### 個別數值運算（Element-wise Operation）\n",
        "\n",
        "若兩個張量想要進行運算，則兩個張量的**維度必須相同**（即兩張量之 `torch.size()` 相同）。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`A + B`|張量 `A` 中的每個數值加上張量 `B` 中相同位置的數值|\n",
        "|`A - B`|張量 `A` 中的每個數值減去張量 `B` 中相同位置的數值|\n",
        "|`A * B`|張量 `A` 中的每個數值乘上張量 `B` 中相同位置的數值|\n",
        "|`A / B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值|\n",
        "|`A // B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之商|\n",
        "|`A % B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之餘數|\n",
        "|`A ** B`|張量 `A` 中的每個數值取張量 `B` 中相同位置的數值之次方|\n",
        "\n",
        "### 個別數值函數運算（Element-wise Functional Operation）\n",
        "\n",
        "若想對張量中的**所有數值**進行**相同函數運算**，必須透過 `torch` 提供的介面進行。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sin`|張量中的每個數值 $x$ 計算 $\\sin(x)$|\n",
        "|`torch.cos`|張量中的每個數值 $x$ 計算 $\\cos(x)$|\n",
        "|`torch.tan`|張量中的每個數值 $x$ 計算 $\\tan(x)$|\n",
        "|`torch.exp`|張量中的每個數值 $x$ 計算 $e^{x}$|\n",
        "|`torch.log`|張量中的每個數值 $x$ 計算 $\\log x$\n",
        "|`torch.ceil`|張量中的每個數值 $x$ 計算 $\\left\\lceil x \\right\\rceil$\n",
        "|`torch.floor`|張量中的每個數值 $x$ 計算 $\\left\\lfloor x \\right\\rfloor$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR54kMUdbr-L",
        "outputId": "be0f0dd1-9f3c-46ea-f7b9-3b97415423e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,  10,  20],\n",
            "        [ 30,  40,  50],\n",
            "        [ 60,  70,  80],\n",
            "        [ 90, 100, 110]])\n",
            "\n",
            "tensor([[  5,  15,  25],\n",
            "        [ 35,  45,  55],\n",
            "        [ 65,  75,  85],\n",
            "        [ 95, 105, 115]])\n",
            "\n",
            "tensor([[ -4,   6,  16],\n",
            "        [ 26,  36,  46],\n",
            "        [ 56,  66,  76],\n",
            "        [ 86,  96, 106]])\n",
            "\n",
            "tensor([[  0,  30,  60],\n",
            "        [ 90, 120, 150],\n",
            "        [180, 210, 240],\n",
            "        [270, 300, 330]])\n",
            "\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 3, 6],\n",
            "        [2, 5, 1],\n",
            "        [4, 0, 3],\n",
            "        [6, 2, 5]])\n",
            "\n",
            "tensor([[    0,   100,   400],\n",
            "        [  900,  1600,  2500],\n",
            "        [ 3600,  4900,  6400],\n",
            "        [ 8100, 10000, 12100]])\n"
          ]
        }
      ],
      "source": [
        "# 純量運算(Scalar Operation)\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t12 = torch.tensor([ \n",
        "    [0, 10, 20],\n",
        "    [30, 40, 50],\n",
        "    [60, 70, 80],\n",
        "    [90, 100, 110],\n",
        "])\n",
        "\n",
        "# 輸出張量 t12\n",
        "print(t12)           \n",
        "print()\n",
        "# 對張量 t12 所有數值加 5\n",
        "print(t12 + 5)       \n",
        "print()\n",
        "# 對張量 t12 所有數值減 4\n",
        "print(t12 - 4)       \n",
        "print()\n",
        "# 對張量 t12 所有數值乘 3\n",
        "print(t12 * 3)       \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10\n",
        "print(t12 / 10)      \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10 所得整數部份\n",
        "print(t12 // 10)     \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 7 得到餘數\n",
        "print(t12 % 7)       \n",
        "print()\n",
        "# 對張量 t12 所有數值取 2 次方\n",
        "print(t12 ** 2)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0xQnAE0br-L",
        "outputId": "15ee2e34-64e9-4f31-b6eb-145ce11aac74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7, 7, 7],\n",
            "        [7, 7, 7]])\n",
            "\n",
            "tensor([[-5, -3, -1],\n",
            "        [ 1,  3,  5]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 個別數值運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t13 = torch.tensor([ \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t14 = torch.tensor([ \n",
        "    [6, 5, 4],\n",
        "    [3, 2, 1]\n",
        "])\n",
        "\n",
        "# 張量相加\n",
        "print(t13 + t14)     \n",
        "print()\n",
        "# 張量相減\n",
        "print(t13 - t14)     \n",
        "print()    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Q: 有辦法做這個效果嗎？**\n",
        "\n",
        "```\n",
        "F(v) = (f(v_1),f(v_2),f(v_3),…,f(v_n))\n",
        "```\n",
        "Ans: 沒辦法提供一個可以直接輸入 f() 的函數，如果 f 能夠被 rewritten into torch.cos(), torch.sin() 等函數的組合就可以平行做 element-wise operation。\n",
        "- [Can we do an element-wise any function similar to map()](https://discuss.pytorch.org/t/apply-a-function-similar-to-map-on-a-tensor/51088)\n"
      ],
      "metadata": {
        "id": "K9af-M7xux8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GenMDYK4br-L",
        "outputId": "0c79e347-6861-4d68-af5d-12c23500b19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000e+00,  7.0711e-01,  1.0000e+00,  7.0711e-01],\n",
            "        [-8.7423e-08, -7.0711e-01, -1.0000e+00, -7.0711e-01]])\n",
            "\n",
            "tensor([[ 1.0000e+00,  7.0711e-01, -4.3711e-08, -7.0711e-01],\n",
            "        [-1.0000e+00, -7.0711e-01,  1.1925e-08,  7.0711e-01]])\n",
            "\n",
            "tensor([[ 0.0000e+00,  1.0000e+00, -2.2877e+07, -1.0000e+00],\n",
            "        [ 8.7423e-08,  1.0000e+00, -8.3858e+07, -1.0000e+00]])\n",
            "\n",
            "tensor([[  2.7183,   7.3891,  20.0855],\n",
            "        [ 54.5981, 148.4132, 403.4288]])\n",
            "\n",
            "tensor([[0.0000, 0.6931, 1.0986],\n",
            "        [1.3863, 1.6094, 1.7918]])\n",
            "\n",
            "tensor([[0., 1., 2.],\n",
            "        [2., 2., 2.]])\n",
            "\n",
            "tensor([[0., 0., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# 個別數值函數運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t15 = torch.tensor([               \n",
        "    [0,     np.pi / 4,     np.pi / 2,     np.pi / 4 * 3],\n",
        "    [np.pi, np.pi / 4 * 5, np.pi / 2 * 3, np.pi / 4 * 7]\n",
        "])\n",
        "\n",
        "# 張量所有數值計算 sine\n",
        "print(torch.sin(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 cosine\n",
        "print(torch.cos(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 tangent\n",
        "print(torch.tan(t15))              \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t16 = torch.tensor([               \n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "])\n",
        "\n",
        "# 張量所有數值取指數\n",
        "print(torch.exp(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數\n",
        "print(torch.log(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數後無條件進位\n",
        "print(torch.ceil(torch.log(t16)))  \n",
        "print()\n",
        "# 張量所有數值取對數後無條件捨去\n",
        "print(torch.floor(torch.log(t16))) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t13 = torch.tensor([ \n",
        "#     [1, 2, 3],\n",
        "#     [4, 5, 6]\n",
        "# ])\n",
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t14 = torch.tensor([ \n",
        "#     [6, 5, 4],\n",
        "#     [3, 2, 1]\n",
        "# ])\n",
        "\n",
        "\n",
        "# 張量相乘\n",
        "print(t13 * t14)     \n",
        "print()\n",
        "# 張量相除\n",
        "print(t13 / t14)     \n",
        "print()\n",
        "# 張量相除取商\n",
        "print(t13 // t14)    \n",
        "print()\n",
        "# 張量相除取餘數\n",
        "print(t13 % t14)     \n",
        "print()\n",
        "# 張量 A 取張量 B 次方\n",
        "print(t13 ** t14)\n",
        "# res[0][0] = A[0][0]**B[0][0]\n",
        "# res[0][1] = A[0][1]**B[0][1]\n",
        "# ...\n",
        "# res[i][j] = A[i][j]**B[i][j]\n",
        "# 0 <= i < 2\n",
        "# 0 <= j < 3 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqQy9aOrdyw",
        "outputId": "51511ac1-3fa5-4f21-865a-f15de0cd19c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6, 10, 12],\n",
            "        [12, 10,  6]])\n",
            "\n",
            "tensor([[0.1667, 0.4000, 0.7500],\n",
            "        [1.3333, 2.5000, 6.0000]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [1, 2, 6]])\n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 1, 0]])\n",
            "\n",
            "tensor([[ 1, 32, 81],\n",
            "        [64, 25,  6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[2], [1]])\n",
        "print(a.size())         # a shape: (2, 1) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "\n",
        "try:\n",
        "  print(y:=a**b)\n",
        "  # a, b 雖然 size mismatch，但適用張量自動擴充的條件3\n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnh-f7nOXZsV",
        "outputId": "92323936-2bf9-4ee4-f137-85a73bfa45d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1])\n",
            "tensor([[0.7449, 0.8160, 3.8002, 0.2895, 1.2484],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
            "torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[2,5], [1,4]])\n",
        "print(a.size())         # a shape: (2, 2) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "print(b.size())\n",
        "try:\n",
        "  print(y:=a**b) \n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print('Error Message:', e)\n",
        "  # 從最後一個維度開始比較，如果有任何維度無法滿足條件，則得到 error "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f69658-9077-47d8-af76-59011d53735d",
        "id": "K8zfKUqcdHjO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 5])\n",
            "Error Message: The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###🚧 **張量自動擴充（Broadcasting)**\n",
        "\n",
        "若張量 `A` 的維度為 `(a1, a2, ..., an)`（即 `A.size() == (a1, a2, ..., an)`），則張量 `B` 在滿足以下其中一種條件時即可與張量 `A` 進行運算：\n",
        "\n",
        "- 張量 `B` 與張量 `A` 維度完全相同（即 `B.size() == (a1, a2, ..., an)`）\n",
        "- 張量 `B` 為純量（即 `B.size() == (1,)`）\n",
        "- 張量 `B` 的維度為 `(b1, b2, ..., bn)`，若 `ai != bi`，則 `ai == 1` 或 `bi == 1`\n",
        "    - 從**最後**一個維度開始比較\n",
        "    - 如果有任何一個維度無法滿足前述需求，則會得到 `ValueError`"
      ],
      "metadata": {
        "id": "RqUbDIOiv4Uk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6pu71GVbr-L",
        "outputId": "379f17c1-8e58-416b-a124-534eb3604055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 2])\n",
            "torch.Size([2, 3, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 張量自動擴充\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t17 = torch.tensor([ \n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "    ],\n",
        "    [\n",
        "        [7, 8],\n",
        "        [9 ,10],\n",
        "        [11, 12]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t18 = torch.tensor([ \n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]\n",
        "    ],\n",
        "    [\n",
        "        [2],\n",
        "        [2],\n",
        "        [2]\n",
        "    ],\n",
        "])\n",
        "\n",
        "# 輸出張量 t17 維度\n",
        "print(t17.size())    \n",
        "# 輸出張量 t18 維度\n",
        "print(t18.size())    \n",
        "print()   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量 t17 與張量 t17 維度相同，所以可以直接運算\n",
        "print(t17 + t17)     \n",
        "print()\n",
        "# 張量 t17 與張量 t18 可以擴充成相同維度，所以可以運算\n",
        "print(t17 + t18)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ryiNnF9wDOr",
        "outputId": "49c0c912-b68d-4ac4-db99-6d22f6e7c9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2,  4],\n",
            "         [ 6,  8],\n",
            "         [10, 12]],\n",
            "\n",
            "        [[14, 16],\n",
            "         [18, 20],\n",
            "         [22, 24]]])\n",
            "\n",
            "tensor([[[ 2,  3],\n",
            "         [ 4,  5],\n",
            "         [ 6,  7]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [11, 12],\n",
            "         [13, 14]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdmIDslGbr-L"
      },
      "source": [
        "## 創造張量\n",
        "\n",
        "### 賦值（Assignment）\n",
        "\n",
        "使用 `=` 賦與指定位置數值。可以使用 `iterable` 一次指定多個位置。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`=`|賦值|\n",
        "|`+=`|進行加法後賦值|\n",
        "|`-=`|進行減法後賦值|\n",
        "|`*=`|進行乘法後賦值|\n",
        "\n",
        "### 隨機（Random）\n",
        "\n",
        "創造出新的張量，所有數值皆為**隨機決定**，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|備註|\n",
        "|-|-|-|-|\n",
        "|`torch.empty`|創造隨機未初始化張量|已確認維度，尚未確認數值|無法控制隨機|\n",
        "|`torch.rand`|創造隨機浮點數張量，並符合均勻分佈|需要隨機浮點數時|透過均勻分佈決定亂數，範圍介於 0 到 1之間|\n",
        "|`torch.randn`|創造隨機浮點數張量，並符合常態分佈|需要符合常態分佈的隨機浮點數時|透過常態分佈決定亂數，$\\mu = 0$ 且 $\\sigma = 1$|\n",
        "|`torch.randint`|創造隨機整數張量|需要隨機整數時|透過均勻分佈決定亂數，可以控制隨機範圍|\n",
        "\n",
        "### 指定數值（Filled In）\n",
        "\n",
        "**快速創造**擁有特定數值的張量，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|\n",
        "|-|-|-|\n",
        "|`torch.zeros`|創造指定維度大小的張量，所有數值初始化為 0|快速初始化|\n",
        "|`torch.zeros_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 0|複製張量並初始化|\n",
        "|`torch.ones`|創造指定維度大小的張量，所有數值初始化為 1|快速初始化|\n",
        "|`torch.ones_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 1|複製張量並初始化|\n",
        "|`torch.full`|創造指定維度大小的張量，所有數值初始化為指定數值|快速初始化|\n",
        "|`torch.full_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為指定數值|複製張量並初始化|\n",
        "|`torch.eye`|創造單位矩陣|矩陣微分|\n",
        "|`torch.arange`|列舉數字|等同於 `list(range(value))`|\n",
        "\n",
        "### 從 numpy 轉換\n",
        "\n",
        "可以使用 `torch.tensor()` 將 `numpy.ndarray` 轉換成 `torch.Tensor`；\n",
        "使用 `torch.numpy()` 將 `torch.Tensor` 轉換成 `numpy.ndarray`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvxSd3X1br-L",
        "outputId": "99dc0132-e0ca-4054-8228-691b67b01261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1995, 1995, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10,   12],\n",
            "        [   4,    5,    6],\n",
            "        [   7,   12,    9],\n",
            "        [  10,   11,   12]])\n"
          ]
        }
      ],
      "source": [
        "# 賦值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t19 = torch.tensor([     \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 0 的所有數值改成 1995\n",
        "t19[0] = 1995            \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [0, 1] 的所有數值改成 10\n",
        "t19[0, 1] = 10           \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [2, 1] 與 [0, 2] 的所有數值改成 12\n",
        "t19[[2, 0], [1, 2]] = 12 \n",
        "print(t19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6LzdLlgbr-L",
        "outputId": "86617d59-d3f7-4d96-a078-62240a2313da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1996, 1997, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1996, 1987, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t20 = torch.tensor([      \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 0 的所有數值加上 1995\n",
        "t20[0] += 1995            \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [0, 1] 的所有數值減掉 10\n",
        "t20[0, 1] -= 10           \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [2, 1] 與 [0, 2] 的所有數值乘上 12\n",
        "t20[[2, 0], [1, 2]] *= 12 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2p5aidybr-L",
        "outputId": "8c79bb15-c76b-44b0-f85d-ac06766fa457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7.6424e-35, 0.0000e+00, 7.6233e-35],\n",
            "        [0.0000e+00, 7.9050e+31, 5.5515e-08]])\n",
            "\n",
            "tensor([[0.9792, 0.7769, 0.0042],\n",
            "        [0.0970, 0.0852, 0.2350]])\n",
            "\n",
            "tensor([[7.0244, 0.0352, 8.6536],\n",
            "        [3.2376, 2.8807, 7.6093]])\n",
            "\n",
            "tensor([[-1.8597,  2.7890, -1.1310],\n",
            "        [-1.3648, -1.8921, -0.2046]])\n",
            "\n",
            "tensor([[ 0.3973,  1.0959, -0.1656],\n",
            "        [ 0.6208, -0.1334,  0.9573]])\n",
            "\n",
            "tensor([[ 3, -2, -5],\n",
            "        [ 3, -5,  0]])\n"
          ]
        }
      ],
      "source": [
        "# 隨機\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為無法控制範圍的浮點\n",
        "print(torch.empty((2, 3)))               \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 1 之間的浮點\n",
        "print(torch.rand(2, 3))                  \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 10 之間的浮點\n",
        "print(torch.rand(2, 3) * 10)             \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.rand(2, 3) * 10 - 5)         \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，分佈為平均值為 0 標準差為 1 的常態分佈\n",
        "print(torch.randn(2, 3))                 \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.randint(-5, 5, size=(2, 3))) \n",
        "                                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmziKBTmbr-L",
        "outputId": "e573b226-6f80-4367-e988-6473282df5f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "tensor([[1, 1, 1, 1],\n",
            "        [1, 1, 1, 1],\n",
            "        [1, 1, 1, 1]])\n",
            "\n",
            "tensor([[420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420]])\n",
            "\n",
            "tensor([[69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69]])\n"
          ]
        }
      ],
      "source": [
        "# 指定數值\n",
        "# 創造維度為 (2, 3) 的張量，並初始化為 0\n",
        "print(torch.zeros((2, 3)))      \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t21 = torch.tensor([            \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "# 複製張量 t21 的維度，創造出新的張量，並初始化為 0\n",
        "print(torch.zeros_like(t21))    \n",
        "print()\n",
        "\n",
        "# 創造維度為 (3, 4) 的張量，並初始化為 1\n",
        "print(torch.ones((3, 4)))       \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t22 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "# 複製張量 t22 的維度，創造出新的張量，並初始化為 1\n",
        "print(torch.ones_like(t22))     \n",
        "print()\n",
        "\n",
        "# 創造維度為 (5, 6) 的張量，並初始化為 420\n",
        "print(torch.full((5, 6), 420))  \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t23 = torch.tensor([            \n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "    [7, 8, 9, 10, 11, 12],\n",
        "    [13, 14, 15, 16, 17, 18],\n",
        "    [19, 20, 21, 22, 23, 24],\n",
        "    [25, 26, 27, 28, 29, 30]\n",
        "])\n",
        "# 複製張量 t23 的維度，創造出新的張量，並初始化為 69\n",
        "print(torch.full_like(t23, 69)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJgdH-vabr-L",
        "outputId": "ffab6382-383b-4dde-cddb-b4cd1e29b8c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "tensor([6, 7, 8])\n",
            "\n",
            "tensor([ 4, 11, 18])\n"
          ]
        }
      ],
      "source": [
        "# 創造 3x3 單位矩陣\n",
        "print(torch.eye(3))           \n",
        "print()\n",
        "\n",
        "# 從 0 列舉至 10，但不包含 10\n",
        "print(torch.arange(10))       \n",
        "print()\n",
        "\n",
        "# 從 6 列舉至 9，但不包含 9\n",
        "print(torch.arange(6, 9))     \n",
        "print()\n",
        "\n",
        "# 從 4 遞增至 20，但不包含 20，每次遞增 7\n",
        "print(torch.arange(4, 20, 7)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvkT3EX7br-L",
        "outputId": "16ae7f16-37a4-46b8-d714-99fa73b6999d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy.ndarray: [1. 2. 3.], dtype: float64\n",
            "converted torch.Tensor: tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n",
            "converted numpy.ndarray: [1. 2. 3.], dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 從 numpy 轉換\n",
        "\n",
        "# 宣告 ndarray 變數\n",
        "arr1 = np.array([1., 2., 3.]) \n",
        "# 將 numpy.ndarray 轉換為 torch.Tensor\n",
        "t24 = torch.tensor(arr1)      \n",
        "# 將 torch.Tensor 轉換為 numpy.ndarray\n",
        "arr2 = t24.numpy()            \n",
        "\n",
        "print((\n",
        "    'original numpy.ndarray: {}, dtype: {}\\n' + \n",
        "    'converted torch.Tensor: {}, dtype: {}\\n' +\n",
        "    'converted numpy.ndarray: {}, dtype: {}'\n",
        ").format(\n",
        "    arr1, arr1.dtype,\n",
        "    t24, t24.dtype,\n",
        "    arr2, arr2.dtype\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STyE59Zgbr-M"
      },
      "source": [
        "## 高維張量運算\n",
        "\n",
        "矩陣等同於是維度為 2 的張量。\n",
        "而高維度的張量運算等同於**固定大部分的維度**，只使用**其中的兩個維度進行計算**。\n",
        "\n",
        "### 張量乘法（Tensor Multiplication）\n",
        "\n",
        "令 $A$ 與 $B$ 為兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$, $B.\\text{size}() = (b_1, b_2, ..., b_{n - 1}, b_n)$。定義 $A \\times B$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "a_i &= b_i \\forall i \\in \\{1, \\dots, n - 2\\} \\\\\n",
        "a_n &= b_{n - 1} \\\\\n",
        "(A \\times B).\\text{size}() &= (d_1, d_2, \\dots, d_{n - 2}, a_{n - 1}, b_n) \\\\\n",
        "&, \\text{where } d_i = a_i = b_i \\forall i \\in \\{1, 2, \\dots, n - 2\\} \\\\\n",
        "(A \\times B)_{d_1, d_2, \\dots, d_{n - 2}, i, j} &=\n",
        "\\begin{cases}\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{i, k} \\times B_{k, j} & \\text{if } n = 2 \\\\\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{d_1, d_2, \\dots, d_{n - 2}, i, k} \\times B_{d_1, d_2, \\dots, d_{n - 2}, k, j} & \\text{if } n > 2\n",
        "\\end{cases} \\\\\n",
        "&, \\forall i \\in \\{1, \\dots, a_1\\}, j \\in \\{1, \\dots, b_2\\}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 與 $B.\\text{size}() = (5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (5, 4, 2)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 與 $B.\\text{size}() = (1995, 10, 12, 5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (1995, 10, 12, 5, 4, 2)$。\n",
        "\n",
        "在 `torch` 中張量乘法為 `torch.matmul(A, B)`。\n",
        "\n",
        "### 張量轉置（Tensor Transpose）\n",
        "\n",
        "令 $A$ 兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$。定義 $A^{\\top}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top} &= (A_{a_1, a_2, \\dots, a_{n - 2}, a_{n - 1}, a_n})^{\\top} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_{n - 2}, a_n, a_{n - 1}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "即交換張量 $A$ 的最後兩個維度。若想要指定不同的維度 $i, j$ 進行轉置，則定義 $A^{\\top_{i, j}}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top_{i, j}} &= (A_{a_1, a_2, \\dots, a_i, \\dots, a_j, \\dots, a_n})^{\\top_i, j} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_j, \\dots, a_i, \\dots, a_n}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 來說，$A^{\\top_{1, 2}}.\\text{size}() = (5, 3, 4)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 來說，$A^{\\top_{3, 4}}.\\text{size}() = (1995, 10, 12, 4, 5, 3)$。\n",
        "\n",
        "在 `torch` 中張量轉置為 `torch.transpose(A, i, j)`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0ntJ0Jzbr-M",
        "outputId": "5faaf6fb-06c5-4cce-e0b8-49bc569ab0f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 4, 3])\n",
            "torch.Size([5, 3, 2])\n",
            "torch.Size([5, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "# 張量乘法\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t25 = torch.ones(5, 4, 3)    \n",
        "# 宣告 Tensor 變數\n",
        "t26 = torch.ones(5, 3, 2)    \n",
        "# 進行張量乘法\n",
        "t27 = torch.matmul(t25, t26) \n",
        "\n",
        "# 輸出張量 t25 的維度\n",
        "print(t25.size())            \n",
        "# 輸出張量 t26 的維度\n",
        "print(t26.size())            \n",
        "# 輸出張量 t27 的維度\n",
        "print(t27.size())            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iELV2wlbbr-M",
        "outputId": "c9c89622-150c-4b50-9273-c7ddd4265988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 4])\n",
            "torch.Size([5, 3, 4])\n",
            "torch.Size([3, 4, 5])\n",
            "torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "# 張量轉置\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t28 = torch.ones(5, 4, 3)                \n",
        "\n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(torch.transpose(t28, 1, 2).size()) \n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(t28.transpose(1, 2).size())        \n",
        "\n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(torch.transpose(t28, 0, 2).size()) \n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(t28.transpose(0, 2).size())        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwt4npXsbr-M"
      },
      "source": [
        "## 維度運算\n",
        "\n",
        "### 降維函數（Dimension Decreasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**小於輸入**張量維度。\n",
        "在機器學習中你幾乎必定會用到 `torch.argmax`。\n",
        "![](https://www.researchgate.net/publication/326914586/figure/fig1/AS:657671334150145@1533812473734/Proposed-neural-network-classifier-with-softmax-output-function-and-a-bias-unit.png)\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sum`|將所有數值相加|\n",
        "|`torch.max`|取出所有數值中最大者|\n",
        "|`torch.min`|取出所有數值中最小者|\n",
        "|`torch.argmax`|取出所有數值中最大者的位置|\n",
        "|`torch.argmin`|取出所有數值中最小者的位置|\n",
        "|`torch.mean`|取出所有數值的平均值|\n",
        "|`torch.var`|取出所有數值的變異數|\n",
        "|`torch.std`|取出所有數值的標準差|\n",
        "|`torch.squeeze`|移除數字為 1 的維度|\n",
        "\n",
        "### 增維函數（Dimension Increasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**大於輸入**張量維度。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.cat`|串接多個相同維度的張量|\n",
        "|`torch.unsqueeze`|在指定的維度間增加 1 維度|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuN13HnNbr-M",
        "outputId": "c9c9fa52-3349-4cf1-f40e-a77be5b2befa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(78)\n",
            "tensor(78)\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([10, 26, 42])\n",
            "tensor([10, 26, 42])\n",
            "tensor(12)\n",
            "tensor(12)\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "tensor([ 9, 10, 11, 12])\n",
            "tensor([2, 2, 2, 2])\n",
            "\n",
            "tensor(1)\n",
            "tensor(1)\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "tensor([1, 5, 9])\n",
            "tensor([0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# 降維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t29 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 將張量 t29 中所有值相加\n",
        "print(torch.sum(t29))           \n",
        "# 將張量 t29 中所有值相加\n",
        "print(t29.sum())                \n",
        "\n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(torch.sum(t29, dim=0))    \n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(t29.sum(dim=0))           \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(torch.sum(t29, dim=1))    \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(t29.sum(dim=1))           \n",
        "\n",
        "# 找出張量 t29 中最大值\n",
        "print(torch.max(t29))          \n",
        "# 找出張量 t29 中最大值\n",
        "print(t29.max())                \n",
        "print()\n",
        "\n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(torch.max(t29, dim=0))    \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(t29.max(dim=0))           \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值\n",
        "print(torch.max(t29, dim=0)[0]) \n",
        "# 依照維度 0 找出張量 t29 中最大值位置\n",
        "print(torch.max(t29, dim=0)[1]) \n",
        "print()\n",
        "\n",
        "# 找出張量 t29 中最小值\n",
        "print(torch.min(t29))           \n",
        "# 找出張量 t29 中最小值\n",
        "print(t29.min())                \n",
        "print()\n",
        "\n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(torch.min(t29, dim=1))    \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(t29.min(dim=1))           \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值\n",
        "print(torch.min(t29, dim=1)[0]) \n",
        "# 依照維度 1 找出張量 t29 中最小值位置\n",
        "print(torch.min(t29, dim=1)[1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmWn28FWbr-M",
        "outputId": "00eb6da5-fc1d-4366-92a9-955a6a11ac4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11)\n",
            "tensor(11)\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([3, 3, 3])\n",
            "tensor([3, 3, 3])\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor([0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0])\n",
            "tensor([0, 0, 0])\n",
            "tensor([0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t30 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30))        \n",
        "# 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax())             \n",
        "\n",
        "# 依照維度 0 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30, dim=0)) \n",
        "# 依照維度 0 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=0))        \n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30, dim=1)) \n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=1))        \n",
        "\n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30))        \n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin())             \n",
        "\n",
        "# 依照維度 0 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30, dim=0)) \n",
        "# 依照維度 0 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin(dim=0))        \n",
        "# 依照維度 1 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30, dim=1)) \n",
        "# 依照維度 1 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin(dim=1))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJwYUYHgbr-M",
        "outputId": "1cb7e250-de49-49f5-bf82-7c5a950c23b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.5000)\n",
            "tensor(6.5000)\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor(13.)\n",
            "tensor(13.)\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor(3.6056)\n",
            "tensor(3.6056)\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t31 = torch.tensor([            \n",
        "    [1., 2., 3., 4.],\n",
        "    [5., 6., 7., 8.],\n",
        "    [9., 10., 11., 12.]\n",
        "])\n",
        "\n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31))         \n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean())              \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=0)) \n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=0))        \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=1)) \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=1))        \n",
        "\n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31))          \n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(t31.var())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=1))         \n",
        "\n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31))          \n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(t31.std())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=1))         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfXHwo9-br-M",
        "outputId": "bfaa7ffd-e9da-4a36-96f6-ffd3acfdfdac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "torch.Size([1, 3])\n",
            "tensor([1, 2, 3])\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t32 = torch.tensor([        \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 移除張量 t32 中多餘的維度\n",
        "t32_sq = torch.squeeze(t32) \n",
        "\n",
        "# 輸出張量 t32\n",
        "print(t32)                  \n",
        "# 輸出張量 t32 的維度\n",
        "print(t32.size())           \n",
        "# 輸出移除維度後的張量 t32\n",
        "print(t32_sq)               \n",
        "# 輸出移除維度後張量 t32 的維度\n",
        "print(t32_sq.size())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROt_wvYWbr-M",
        "outputId": "4a354c6d-1ba0-40b2-e3de-a27452320b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "torch.Size([4, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# 增維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t33 = torch.tensor([                  \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 串接多個張量 t33\n",
        "t33_cat = torch.cat([                 \n",
        "    t33,\n",
        "    t33,\n",
        "    t33,\n",
        "    t33\n",
        "]) \n",
        "\n",
        "# 輸出串接後的張量 t33_cat\n",
        "print(t33_cat)                        \n",
        "# 輸出串接後的張量 t33_cat 維度\n",
        "print(t33_cat.size())                 \n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t34 = torch.tensor([                  \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "print(t34)\n",
        "print(t34.size())\n",
        "\n",
        "# 對張量 t34 維度 0 增加 1 維\n",
        "t34_usq = torch.unsqueeze(t34, dim=0) \n",
        "\n",
        "# 輸出張量 t34 維度 0 增加 1 維後的結果\n",
        "print(t34_usq)                        \n",
        "# 輸出張量 t34 維度 0 增加 1 維後的維度\n",
        "print(t34_usq.size())                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpkIiN9Vbr-M"
      },
      "source": [
        "## 使用 GPU 運算\n",
        "\n",
        "上述的所有教學都是在 CPU 上進行運算，而大多數的深度學習框架都會提供操作 GPU 的介面幫助平型化運算。\n",
        "而 `torch` 與大部分的深度學習框架相同，使用 Nvidia 開發的 CUDA（Compute Unified Device Architecture）幫助使用 GPU 進行深度學習的運算（cuDNN）。\n",
        "\n",
        "使用 CUDA 操作平型化運算的流程為：\n",
        "\n",
        "1. 宣告 GPU 運算所需要佔用的記憶體（`cudaMalloc`）\n",
        "2. 定義每個平型化運算節點的運算內容\n",
        "3. 在主記憶體上創造資料（`malloc`）\n",
        "4. 將資料搬移至 GPU 的記憶體（`cudaMemcpy`）\n",
        "5. 每個節點獨立運算\n",
        "6. 將計算結果搬回至主記憶體（`memcpy`）\n",
        "7. 釋放 GPU 的記憶體（`cudaFree`）\n",
        "\n",
        "而在 `torch` 中將以上流程簡化成以下兩種方法\n",
        "\n",
        "- 宣告 `torch.Tensor` 變數時使用 `device='cuda:0'` 參數將變數宣告於 GPU 記憶體第0顆（0-indexed）。\n",
        "- 對已經創造於主記憶體的 `torch.Tensor` 變數使用 `torch.to('cuda:0')` 搬移至 GPU 記憶體第0顆（0-indexed）。\n",
        "```python\n",
        "torch.tensor([1., 2., 3.], device='cuda:0') # 使用 device 參數將變數宣告於 GPU 記憶體\n",
        "torch.tensor([1., 2., 3.]).to('cuda:0')     # 使用 to 將變數搬移至 GPU 記憶體\n",
        "```\n",
        "\n",
        "宣告於 GPU 或搬移至 GPU 後，之後所有的運算便會在 GPU 上進行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djuqIr7vbr-M",
        "outputId": "9c908a0d-17f7-4119-eba8-2b31a63bc5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 使用 GPU 運算\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # 使用 device 參數創造張量於 GPU 上\n",
        "    t35 = torch.tensor([1., 2., 3.], device='cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled')     \n",
        "    t35 = None\n",
        "    \n",
        "# 輸出張量 t35\n",
        "print(t35)                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKtEO_4Nbr-M",
        "outputId": "bc81130a-0364-46f8-f285-4e9dc15e71c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    # 使用 to 將張量搬移至 GPU 上\n",
        "    t36 = torch.tensor([1., 2., 3.]).to('cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled') \n",
        "    t36 = None\n",
        "    \n",
        "# 輸出張量 t36\n",
        "print(t36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14dZ9N1Ybr-M",
        "outputId": "cfbd5e50-4101-4edb-8ed4-4f57532f2ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "tensor([1., 2., 3.], device='cuda:0')\n",
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "\n",
        "# 根據 device 創造張量\n",
        "t37 = torch.tensor([1., 2., 3.], device=device) \n",
        "# 使用 to 搬移張量至指定的裝置\n",
        "t38 = torch.tensor([1., 2., 3.]).to(device)     \n",
        "\n",
        "# 輸出張量 t37\n",
        "print(t37)                                      \n",
        "# 輸出張量 t38\n",
        "print(t38)                                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLKGH_vbr-M"
      },
      "source": [
        "## 深度學習\n",
        "\n",
        "![Deep Learning](https://miro.medium.com/max/1000/1*51D0MqtqHu3h2vTE5oJ-7g.png)\n",
        "![Deep Learning vs. Machine Learning](https://learn.microsoft.com/zh-tw/azure/machine-learning/media/concept-deep-learning-vs-machine-learning/ai-vs-machine-learning-vs-deep-learning.png)\n",
        "## 深度學習要幹嘛？\n",
        "上課教的 SVM, Bayes 等等的模型算是 （傳統）Machine Learning 的範疇，比較偏向建立於統計的假設的數學統計模型。而深度學習則是機器學習內的一個子集合（subset），他是以類神經網路來模擬人類大腦的神經元之間的互動。\n",
        "\n",
        "\n",
        "使用 `torch` 進行深度學習主要包含以下步驟：\n",
        "\n",
        "1. 將資料轉換成 `torch.Tensor`，使用 Dataset 和 Dataloader 包裝管理資料。\n",
        "2. 使用 `torch.nn` 建立深度學習模型架構。\n",
        "3. 從 `torch.optim` 選擇最佳化工具。\n",
        "4. 選擇目標函數。\n",
        "5. 訓練深度學習模型（train）。\n",
        "6. 測試深度學習模型（test, inference）。\n",
        "\n",
        "### 資料集\n",
        "\n",
        "1. 使用 `torch.utils.data.Dataset` 將資料集轉換成 `torch.Tensor`\n",
        "2. 使用 `torch.utils.data.DataLoader` 將資料集以批次（mini-batch）取出\n",
        "3.（Optional）額外定義 `collate_fn` 將抽樣的資料整理成固定的格式\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFiFnsh5br-N",
        "outputId": "912e0668-6434-4d31-8111-bb111208753d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "(tensor(-0.5519), tensor(15.9535))\n"
          ]
        }
      ],
      "source": [
        "# 資料集\n",
        "\n",
        "# 匯入資料集 base class\n",
        "from torch.utils.data import Dataset \n",
        "\n",
        "# 繼承 base class 創造資料集\n",
        "class MyDataset(Dataset):            \n",
        "    # 給予資料集大小，並隨機創造資料\n",
        "    def __init__(self, size):        \n",
        "        self.x = torch.rand(size) * 2 - 1\n",
        "        self.y = 2 * self.x ** 2 + 3 * self.x + 17\n",
        "        \n",
        "    # 定義總資料數\n",
        "    def __len__(self):               \n",
        "        return len(self.x)\n",
        "    \n",
        "    # 定義取出單一資料的方法\n",
        "    def __getitem__(self, index):    \n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "# 創造資料集\n",
        "my_dataset = MyDataset(10)           \n",
        "\n",
        "# 取得總資料數\n",
        "print(len(my_dataset))               \n",
        "# 取出單一資料\n",
        "print(my_dataset[0])                 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWP1moMObr-N",
        "outputId": "703e9283-8e0f-4f81-e5c4-8e008071aed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[-0.1877],\n",
            "        [ 0.0055],\n",
            "        [-0.5519]]), tensor([[16.5073],\n",
            "        [17.0166],\n",
            "        [15.9535]])]\n",
            "\n",
            "[tensor([[-0.3740],\n",
            "        [ 0.8185],\n",
            "        [ 0.3821]]), tensor([[16.1577],\n",
            "        [20.7951],\n",
            "        [18.4385]])]\n",
            "\n",
            "[tensor([[ 0.3836],\n",
            "        [-0.1347],\n",
            "        [ 0.3989]]), tensor([[18.4453],\n",
            "        [16.6323],\n",
            "        [18.5150]])]\n",
            "\n",
            "[tensor([[-0.4692]]), tensor([[16.0327]])]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 匯入資料集抽樣工具\n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "# 定義格式化的方法\n",
        "def collate_fn(batch):                  \n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    \n",
        "    for x, y in batch:\n",
        "        # 將每個 x 轉換成 [x]\n",
        "        x_list.append([x])              \n",
        "        # 將每個 y 轉換成 [y]\n",
        "        y_list.append([y])              \n",
        "        \n",
        "    # 最終回傳的維度為 [(batch_size, features), (batch_size, labels)]\n",
        "    return [torch.tensor(x_list), torch.tensor(y_list)] \n",
        "\n",
        "# 創造 DataLoader 實例\n",
        "my_data_loader = DataLoader(            \n",
        "    # 對資料集 my_dataset 進行抽樣\n",
        "    my_dataset,                         \n",
        "    # 設定每次抽樣的數量\n",
        "    batch_size=3,                       \n",
        "    # 設定隨機抽樣\n",
        "    shuffle=True,                       \n",
        "    # 指定格式化的方法\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for data in my_data_loader:             \n",
        "    # 輸出抽樣結果\n",
        "    print(data)                         \n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立模型\n",
        "\n",
        "可以使用 `torch.nn` 現成的模型進行深度學習，常用的包含：\n",
        "\n",
        "|模型介面|名稱|常見用途|\n",
        "|-|-|-|\n",
        "|`torch.nn.Linear`|線性層（Linear Layer）|轉換特徵|\n",
        "|`torch.nn.Embedding`|嵌入層（Embedding Layer）|學習特徵向量表達法|\n",
        "|`torch.nn.Conv1d`|1 維卷積層（1-Dimensional Convolution Layer）|抽取連續資料區域特徵|\n",
        "|`torch.nn.Conv2d`|2 維卷積層（2-Dimensional Convolution Layer）|抽取平面圖片區域特徵|\n",
        "|`torch.nn.Conv3d`|3 維卷積層（3-Dimensional Convolution Layer）|抽取立體圖片區域特徵|\n",
        "|`torch.nn.RNN`|循環神經網路（Recurrent Neural Network）|壓縮動態長度文字|\n",
        "|`torch.nn.LSTM`|長短期記憶神經網路（Long Short-Term Memory）|有效壓縮動態長度文字|\n",
        "|`torch.nn.Transformer`|多面向自我注意力機制模型（Multi-Head Self-Attention）|機器翻譯|\n",
        "\n",
        "如果需要使用深度學習模型（即多個模型串接），則必須透過繼承 `torch.nn.Module` 來定義**模型結構**與**運算流程**：\n",
        "使用 `nn.Module` 定義模型時必須要記得以下規則：\n",
        "\n",
        "- 在類別方法 `__init__` 中定義模型結構\n",
        "    - 必須要執行 `super(MyModel, self).__init__()`\n",
        "    - 為什麼需要：[colab link](https://colab.research.google.com/drive/1LL1RVaoGoGYE68HCaMOEVSCR8bEPgqqc?usp=sharing)\n",
        "- 必須透過定義類別方法 `forward` 才能定義計算流程"
      ],
      "metadata": {
        "id": "bqeXVb2e0tlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 啟動函數（Activation Functions）\n",
        "\n",
        "若模型需要啟動函數，可以使用 `torch.nn.functional` 中事先定義好的啟動函數：\n",
        "常見的啟動函數包含：\n",
        "\n",
        "|啟動函數|名稱|定義|數值範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.nn.functional.relu`|ReLU|$$f(x_i) = \\max(0, x_i)$$|$$\\mathbb{R}^+$$|\n",
        "|`torch.nn.functional.softmax`|Softmax|$$f(x_i) = \\frac{e^{x_i}}{\\sum_{j = 0}^n e^{x_j}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.sigmoid`|Sigmoid|$$f(x_i) = \\frac{1}{1 + e^{-x_i}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.tanh`|Hyperbolic Tangent|$$f(x_i) = \\frac{e^{x_i} - e^{-x_i}}{e^{x_i} + e^{-x_i}}$$|$$[-1, 1]$$|"
      ],
      "metadata": {
        "id": "QWrkuLw005aB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmmUqpKLbr-N",
        "outputId": "8c4252de-75a9-4bac-e425-84fb8e3e4017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1877],\n",
            "        [-0.1347],\n",
            "        [-0.5519]])\n",
            "tensor([[16.5073],\n",
            "        [16.6323],\n",
            "        [15.9535]])\n",
            "tensor([[-0.1087],\n",
            "        [-0.0957],\n",
            "        [-0.1984]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4692],\n",
            "        [-0.3740],\n",
            "        [ 0.8185]])\n",
            "tensor([[16.0327],\n",
            "        [16.1577],\n",
            "        [20.7951]])\n",
            "tensor([[-0.1836],\n",
            "        [-0.1561],\n",
            "        [-0.0068]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.3821],\n",
            "        [0.3836],\n",
            "        [0.0055]])\n",
            "tensor([[18.4385],\n",
            "        [18.4453],\n",
            "        [17.0166]])\n",
            "tensor([[ 0.0247],\n",
            "        [ 0.0246],\n",
            "        [-0.0616]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.3989]])\n",
            "tensor([[18.5150]])\n",
            "tensor([[0.0237]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 建立模型\n",
        "\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn                   \n",
        "# 匯入啟動函數\n",
        "import torch.nn.functional as F         \n",
        "\n",
        "# 模型需要繼承自 nn.Module\n",
        "class MyModel(nn.Module):               \n",
        "    # 定義模型結構, 輸入層維度, 隱藏層維度, 輸出層維度\n",
        "    def __init__(self,                  \n",
        "                 in_dim,                \n",
        "                 hid_dim,               \n",
        "                 out_dim):              \n",
        "\n",
        "        # 繼承 nn.Module 所有屬性\n",
        "        super(MyModel, self).__init__() \n",
        "        \n",
        "        # 創造線性層 self.layer1\n",
        "        self.layer1 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=in_dim,         \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=hid_dim        \n",
        "        )\n",
        "        # 創造線性層 self.layer2\n",
        "        self.layer2 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=hid_dim,        \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=out_dim        \n",
        "        )\n",
        "        \n",
        "    # 定義運算流程\n",
        "    def forward(self, batch_x):         \n",
        "        # 使用線性層 self.layer1 輸入 batch_x 計算得到 h\n",
        "        h = self.layer1(batch_x)        \n",
        "        # 使用 ReLU 啟動函數輸入 h 得到 a\n",
        "        a = F.relu(h)                   \n",
        "        # 使用線性層 self.layer2 輸入 a 計算得到 y\n",
        "        y = self.layer2(a)              \n",
        "        # 輸出 y\n",
        "        return y                        \n",
        "    \n",
        "# 創造 MyModel 模型實例\n",
        "my_model = MyModel(                     \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=10,                         \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    print(batch_x)\n",
        "    print(batch_y)\n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    print(pred_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 目標函數（Objective Functions）\n",
        "\n",
        "使用 `torch.nn` 中事先定義好的目標函數進行模型最佳化，計算模型預測結果與標記訓練資料的誤差值，並透過向後傳播（Back Propagation）演算法取得相對於誤差值的梯度（Gradient）：\n",
        "\n",
        "```python\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn             \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()          \n",
        "\n",
        "# 計算 batch_x 得到 pred_y\n",
        "pred_y = my_model(batch_x)        \n",
        "# 計算 pred_y 與 batch_y 的均方誤差\n",
        "loss = criterion(pred_y, batch_y) \n",
        "\n",
        "# 使用向後傳播計算梯度\n",
        "loss.backward()                   \n",
        "```\n",
        "\n",
        "常見的目標函數包含：\n",
        "\n",
        "|目標函數|名稱|\n",
        "|-|-|\n",
        "|`torch.nn.MSELoss`|均方誤差（Mean Square Error）|\n",
        "|`torch.nn.CrossEntropyLoss`|交叉熵（Cross Entropy）|\n",
        "|`torch.nn.BCELoss`|二元交叉熵（Binary Cross Entropy）|\n",
        "|`torch.nn.NLLLoss`|負對數似然（Negative Log Likelihood）|"
      ],
      "metadata": {
        "id": "ACOTX8Jw1Ci2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LdZoW-abr-N",
        "outputId": "cbd3f16c-31cd-4ced-f4c4-1772b491c74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(293.8513, grad_fn=<MseLossBackward0>)\n",
            "tensor(267.8932, grad_fn=<MseLossBackward0>)\n",
            "tensor(324.2202, grad_fn=<MseLossBackward0>)\n",
            "tensor(432.7185, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 目標函數\n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    print(loss)\n",
        "    \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()                     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最佳化（Optimization）\n",
        "\n",
        "![Gradient Descent](https://img-blog.csdnimg.cn/20181110102438617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpX2tfeQ==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "使用 `torch.optim` 中的不同的最佳化策略進行梯度下降（Gradient Descent）演算法：\n",
        "\n",
        "$$\n",
        "\\theta_t = \\theta_{t - 1} - \\text{lr} \\cdot \\nabla \\mathcal{L}(x)\n",
        "$$\n",
        "\n",
        "進行最佳化時需要注意以下事項：\n",
        "\n",
        "- 創造最佳化工具時必須指定哪些參數被更新\n",
        "    - 使用 `model.parameters()` 取得模型中所有可以被更新的參數\n",
        "    - 學習率（Learning Rate）負責決定模型參數更新的幅度，可以透過 `lr` 參數設定\n",
        "- 必須先計算誤差並且透過誤差向後傳播（`loss.backward()`），才能執行梯度下降更新參數（`optimizer.step()`）"
      ],
      "metadata": {
        "id": "igh-yFNr1K3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqC3vN9gbr-N"
      },
      "outputs": [],
      "source": [
        "# 最佳化\n",
        "\n",
        "# 匯入計算梯度下降演算法的工具\n",
        "from torch.optim import SGD             \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    # 設定計算梯度下降的目標\n",
        "    my_model.parameters(),              \n",
        "    # 設定學習率\n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()\n",
        "    \n",
        "    # 使用梯度下降更新模型參數\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 清空計算過後的梯度值\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB1tspVHbr-N",
        "outputId": "51d33a4c-331e-4c32-82bc-471739c4065b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, training loss: 311.82000274658196\n",
            "Epoch 0, testing loss: 309.1819274902344\n",
            "Epoch 1, training loss: 306.2461364746094\n",
            "Epoch 1, testing loss: 303.6107879638672\n",
            "Epoch 2, training loss: 300.7908325195312\n",
            "Epoch 2, testing loss: 298.1565368652344\n",
            "Epoch 3, training loss: 295.40490875244143\n",
            "Epoch 3, testing loss: 292.76988220214844\n",
            "Epoch 4, training loss: 290.0375091552734\n",
            "Epoch 4, testing loss: 287.40258178710934\n"
          ]
        }
      ],
      "source": [
        "# 驗證\n",
        "\n",
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# 創造訓練資料集\n",
        "train_dataset = MyDataset(1000)         \n",
        "# 創造測試資料集\n",
        "test_dataset = MyDataset(500)           \n",
        "\n",
        "# 設定超參數\n",
        "\n",
        "# 設定每次抽樣的數量\n",
        "batch_size = 50                         \n",
        "# 設定資料集總訓練次數\n",
        "n_epoch = 5                             \n",
        "# 設定隱藏層維度\n",
        "hid_dim = 10                            \n",
        "\n",
        "# 創造 DataLoader 實例\n",
        "train_data_loader = DataLoader(         \n",
        "    # 對資料集 train_dataset 進行抽樣\n",
        "    train_dataset,                      \n",
        "    # 設定每次抽樣的數量\n",
        "    batch_size=batch_size,              \n",
        "    # 設定隨機抽樣\n",
        "    shuffle=True,                       \n",
        "    # 指定格式化的方法\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "# 創造 DataLoader 實例\n",
        "test_data_loader = DataLoader(          \n",
        "    test_dataset,                       \n",
        "    batch_size=batch_size,              \n",
        "    shuffle=True,                       \n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# 創造 MyModel 模型實例\n",
        "model = MyModel(                        \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=hid_dim,                    \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "# 將模型搬移至 GPU\n",
        "model = model.to(device)                \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    model.parameters(),                 \n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 總共訓練 n_epoch 次\n",
        "for epoch in range(n_epoch):            \n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        # 將訓練資料搬移至 GPU\n",
        "        batch_x = batch_x.to(device)    \n",
        "        # 將訓練資料標記搬移至 GPU\n",
        "        batch_y = batch_y.to(device)    \n",
        "        \n",
        "        # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "        pred_y = model(batch_x)         \n",
        "        # 計算 pred_y (預測標記）與 batch_y （真實標記）的均方誤差\n",
        "        loss = criterion(pred_y, batch_y)\n",
        "        \n",
        "        # 使用向後傳播計算梯度\n",
        "        loss.backward()                 \n",
        "        # 使用梯度下降更新模型參數\n",
        "        optimizer.step()\n",
        "        # 清空計算過後的梯度值\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # 此區塊不會計算梯度\n",
        "    with torch.no_grad():               \n",
        "        # 統計訓練資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in train_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(train_data_loader)\n",
        "        \n",
        "        print('Epoch {}, training loss: {}'.format(epoch, total_loss))\n",
        "        \n",
        "        # 統計測試資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in test_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(test_data_loader)\n",
        "            \n",
        "        print('Epoch {}, testing loss: {}'.format(epoch, total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkmZGlVEbr-O",
        "outputId": "cdebfe36-079d-4e4f-a458-0b29bd72d253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出訓練資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出訓練資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "        \n",
        "    plt.title('Training data performance')\n",
        "    plt.show()\n",
        "    \n",
        "    for batch_x, batch_y in test_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出測試資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出測試資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "    \n",
        "    plt.title('Testing data performance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試\n",
        "\n",
        "深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 `with torch.no_grad():`：\n",
        "\n",
        "### 儲存 & 載入模型\n",
        "\n",
        "使用 `torch.save()` 配合 `model.state_dict()` 儲存訓練後的模型參數；\n",
        "使用 `model.load_state_dict()` 配合 `torch.load()` 載入儲存的訓練過的模型參數。\n"
      ],
      "metadata": {
        "id": "lMbkzFUU1S2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnq25QSFbr-O"
      },
      "outputs": [],
      "source": [
        "# 儲存 & 載入模型\n",
        "\n",
        "# 儲存模型參數\n",
        "# torch.save(model.state_dict(), './data/model.ckpt')    \n",
        "# 載入模型參數\n",
        "# model.load_state_dict(torch.load('./data/model.ckpt')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VHNeeFnbr-O"
      },
      "source": [
        "## 練習\n",
        "\n",
        "### 練習 1：調整超參數\n",
        "\n",
        "請試著更改前述範例中的超參數讓模型表現變好：\n",
        "\n",
        "- 增加訓練次數 `n_epoch`\n",
        "- 增大單一訓練資料次數 `batch_size`\n",
        "- 增大隱藏層的維度 `hid_dim`\n",
        "- 更改啟動函數 `F.relu`\n",
        "\n",
        "### 練習 2：加深模型\n",
        "\n",
        "請試著更改前述範例中的模型深度讓模型表現變好：\n",
        "\n",
        "- 增加 1 個或多個 `nn.Linear`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-tutorial-pytorch",
      "language": "python",
      "name": "nlp-tutorial-pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}