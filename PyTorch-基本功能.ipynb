{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohBsx6xbr-H"
      },
      "source": [
        "# PyTorch-基本功能\n",
        "\n",
        "## 教學目標\n",
        "\n",
        "這份教學的目標是介紹 PyTorch，撰寫深度學習模型的函式庫。\n",
        "\n",
        "## 適用對象\n",
        "\n",
        "已經有基本的機器學習知識，且擁有 python、`numpy`、`matplotlib` 基礎的學生。\n",
        "\n",
        "若沒有先學過 python，請參考 [python-入門語法](./python-入門語法.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `numpy`，請參考 [numpy-基本功能](./numpy-基本功能.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `matplotlib`，請參考 [matplotlib-資料視覺化](./matplotlib-資料視覺化.ipynb) 教學。\n",
        "\n",
        "## 執行時間\n",
        "\n",
        "本教學全部執行時間約為 4.376506090164185 秒。\n",
        "\n",
        "|測試環境|名稱|\n",
        "|-|-|\n",
        "|主機板|X570 AORUS ELITE|\n",
        "|處理器|AMD Ryzen 7 3700X 8-Core Processor|\n",
        "|記憶體|Kingston KHX3200C16D4/16GX|\n",
        "|硬碟|Seagate ST1000DM003-1ER1|\n",
        "|顯示卡|GeForce RTX 2080|\n",
        "|作業系統|Ubuntu 18.04 LTS|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDTx3HZbr-I"
      },
      "source": [
        "## 大綱\n",
        "\n",
        "- [簡介](#簡介)\n",
        "- [安裝](#安裝)\n",
        "- [張量宣告](#張量宣告)\n",
        "- [張量取值](#張量取值)\n",
        "- [張量運算](#張量運算)\n",
        "- [創造張量](#創造張量)\n",
        "- [高維張量運算](#高維張量運算)\n",
        "- [維度運算](#維度運算)\n",
        "- [使用 GPU 運算](#使用-GPU-運算)\n",
        "- [深度學習](#深度學習)\n",
        "- [練習](#練習)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Hk28KHbr-I"
      },
      "source": [
        "## 簡介\n",
        "\n",
        "根據 [PyTorch 官方網站](https://pytorch.org/)（v1.4）：\n",
        "\n",
        "> PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "> \n",
        "> PyTorch 是一個開源的機器學習框架，能夠幫助加速從研究原型到商業應用的轉換過程。\n",
        "\n",
        "![PyTorch usage statistics](https://thegradient.pub/content/images/2019/10/ratio_medium-1.png)\n",
        "\n",
        "根據[統計](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)，PyTorch 在各大機器學習會議使用率逐年上升，使用者選擇 PyTorch 的原因為：\n",
        "\n",
        "- 簡單（Simplicity）\n",
        "    - 使用 `python` 作為介面\n",
        "    - 操作方法與 `numpy` 相似\n",
        "- 好用的介面（Great API）\n",
        "    - 沒有過多的抽象化\n",
        "- 效能（Performance）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwS9cuvXbr-I"
      },
      "source": [
        "## 安裝\n",
        "\n",
        "請參考 [PyTorch 官方網站](https://pytorch.org/get-started/locally/#start-locally)，並選擇適合的環境選項與安裝方法。\n",
        "\n",
        "本教學使用 `pip` 安裝 `torch`，選項如下：\n",
        "\n",
        "|選項|描述|選擇|\n",
        "|-|-|-|\n",
        "|PyTorch Build|請選**穩定版**避免未知錯誤|`Stable(1.4)`|\n",
        "|Your OS|依照**作業系統**來選擇|`Linux`|\n",
        "|Package|安裝 **PyTorch** 使用的方法|`Pip`|\n",
        "|Language|當前執行 **Python** 版本|`Python 3.6`|\n",
        "|CUDA|電腦上是否有 **GPU** 且支援 **CUDA 架構**|`10.1`|\n",
        "\n",
        "得到以下安裝指令：\n",
        "\n",
        "```sh\n",
        "pip install torch torchvision\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gQuDZD9cKaG",
        "outputId": "fbbfd3d6-78d8-4a37-e9c7-6e3ee556ed23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
            "Requirement already satisfied: torch in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
            "Requirement already satisfied: cmake in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
            "Requirement already satisfied: lit in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: numpy in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
            "Requirement already satisfied: requests in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torchvision) (2.29.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from torchvision) (9.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from requests->torchvision) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/nanaeilish/micromamba/envs/fdata/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8q-VOUcbr-J",
        "outputId": "4ec36342-b15b-44a4-9e43-056826034819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version 2.0.0+cu117\n",
            "GPU-enabled installation? True\n"
          ]
        }
      ],
      "source": [
        "# 匯入 PyTorch 套件\n",
        "# 在 python 中的介面名稱為 torch\n",
        "import torch\n",
        "\n",
        "# 匯入 numpy 與 matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print((\n",
        "    'PyTorch version {}\\n' +\n",
        "    'GPU-enabled installation? {}'\n",
        ").format(\n",
        "    # 確認 torch 的版本\n",
        "    torch.__version__,        \n",
        "    # 確認是否有 GPU 裝置\n",
        "    torch.cuda.is_available() \n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOYX-sffjQN"
      },
      "source": [
        "## Torch Tensor\n",
        "程式語言框架通常有其主要的資料型態，像是 numpy 中的 ndarray。在 PyTorch 內則是叫做 tensor（張量）的一種資料型態。PyTorch 的所有操作和 numpy 都很相似，但重要的是 tensor 支援 CUDA 的硬體加速（GPU），使得 GPU 深度學習變得簡單可行。tensor 可以在GPU/CPU上傳輸：只要使用 `tensor.cuda(device_id)`\n",
        "即可以將 tensor 移動到第 `device_id` 個（0-indexed）的 GPU 核心上。或者 `tensor.cpu()`可以將 tensor 移動回到 CPU 上。另外一個更通用的方法是 `tensor.to(device)`。\n",
        "\n",
        "--- \n",
        "## 額外補充\n",
        "### 什麼是 GPU ？\n",
        "GPU全稱為圖形處理器（Graphics Processing Unit），是一種專門進行繪圖運算工作的微處理器。儘管GPU在遊戲中以3D渲染而聞名，但GPU相較於「傳統的專為通用計算而設計的CPU，具有數百或數千個核心，經過優化，可並行運行大量計算，對運行深度學習和機器學習算法尤其有用。GPU允許某些計算機比傳統CPU上運行相同的計算速度快10-100倍。\n",
        "\n",
        "### 什麼是CUDA？\n",
        "\n",
        "CUDA全稱為計算統一設備架構（Compute Unified Device Architecture），是NVIDIA（輝達）創建的平行計算平臺和應用程序編程接口模型。CUDA 平臺是一個軟件層，可直接訪問GPU的虛擬指令集和並行計算元素，以執行計算內核。因此，如果我們想利用 GPU 加速運行深度學習算法，那麼 CUDA 就是一個不可或缺的中間層，它代替我們直接和GPU硬體打交道，並對外開放接口。而 PyTorch 則對這層接口再次進行封裝，以方便程式設計人員使用。\n",
        "\n",
        "### 什麼是cuDNN？\n",
        "\n",
        "cuDNN 全稱為 CUDA 深度神經網絡庫（CUDA Deep Neural Network library），是 NVIDIA 打造的針對深度神經網絡的加速庫，是一個用於深層神經網絡的 GPU 加速庫。如果你要使用 GPU 訓練模型，cuDNN 不是必須的，但一般會採用這個加速庫。\n",
        "\n",
        "## 參考資料\n",
        "- [知乎：什麼是張量？& 深度學習](https://zhuanlan.zhihu.com/p/48982978)\n",
        "- [CUDA 入門, nvidia 公司官方網站](https://blogs.nvidia.com.tw/2020/10/27/cuda-refresher-getting-started-with-cuda/)\n",
        "- [CUDA、cuDNN、pytorch 安装分析](https://blog.csdn.net/weixin_38481963/article/details/105313471) \n",
        "- [NQU Tensor 介紹 slides](https://www.nqu.edu.tw/upload/educsie/attachment/529fa35c91b055e7da3c8dc7a9bc975e.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okJuKPxbr-J"
      },
      "source": [
        "## 張量宣告\n",
        "\n",
        "在 `torch` 中陣列稱為張量（Tensor），創造張量的語法為 `torch.tensor([value1, value2, ...])`。\n",
        "\n",
        "- 每個 `torch.Tensor` 都有不同的**數值型態屬性** `torch.Tensor.dtype`\n",
        "    - 必須透過 `torch.Tensor.dtype` 取得，無法透過 `type()` 取得\n",
        "- 可以指定型態\n",
        "    - 透過參數 `dtype` 指定型態\n",
        "    - 透過 `torch.LongTensor` 創造整數，預設為 `torch.int64`\n",
        "    - 透過 `torch.FloatTensor` 創造浮點數，預設為 `torch.float32`\n",
        "\n",
        "|`torch` 型態|`numpy` 型態|C 型態|範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.int8`|`numpy.int8`|`int_8`|-128~127|\n",
        "|`torch.int16`|`numpy.int16`|`int_16`|-32768~32767|\n",
        "|`torch.int32`|`numpy.int32`|`int_32`|-2147483648~2147483647|\n",
        "|`torch.int64`|`numpy.int64`|`int_64`|-9223372036854775808~9223372036854775807|\n",
        "|`torch.float32`|`numpy.float32`|`float`||\n",
        "|`torch.float64`|`numpy.float64`|`double`||\n",
        "\n",
        "- 每個 `torch.Tensor` 都有**維度屬性** `torch.Size`\n",
        "    - 呼叫 `torch.Tensor.size()` 來取得維度屬性\n",
        "    - `torch.Tensor.size` 本質是 `tuple`\n",
        "    - 張量維度愈高，`len(torch.Tensor.size)` 數字愈大\n",
        "- 可以使用 `torch.Tensor.reshape` 或 `torch.Tensor.view` 進行維度變更\n",
        "    - 變更後的維度必須要與變更前的維度乘積相同\n",
        "    - 變更後的內容為 **shallow copy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KGb8WQKbr-J",
        "outputId": "a05f52cc-4cf6-4ce6-baa0-73ce6a7ce6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n",
            "True\n",
            "torch.int64\n",
            "\n",
            "tensor([1., 2., 3.])\n",
            "True\n",
            "torch.float32\n",
            "\n",
            "torch.int8\n",
            "torch.int16\n",
            "torch.int32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.float64\n",
            "\n",
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# 張量宣告\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t1 = torch.tensor([1, 2, 3])                           \n",
        "# 輸出 Tensor\n",
        "print(t1)                                              \n",
        "# 輸出 True\n",
        "print(type(t1) == torch.Tensor)                        \n",
        "# 輸出 torch.int64\n",
        "print(t1.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t2 = torch.tensor([1., 2., 3.])                        \n",
        "# 輸出 Tensor\n",
        "print(t2)                                              \n",
        "# 輸出 True\n",
        "print(type(t2) == torch.Tensor)                        \n",
        "# 輸出 torch.float32\n",
        "print(t2.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 各種 dtype\n",
        "# 輸出 torch.int8\n",
        "print(torch.tensor([1, 2], dtype=torch.int8).dtype)    \n",
        "# 輸出 torch.int16\n",
        "print(torch.tensor([1, 2], dtype=torch.int16).dtype)   \n",
        "# 輸出 torch.int32\n",
        "print(torch.tensor([1, 2], dtype=torch.int32).dtype)   \n",
        "# 輸出 torch.int64\n",
        "print(torch.tensor([1, 2], dtype=torch.int64).dtype)   \n",
        "# 輸出 torch.float32\n",
        "print(torch.tensor([1, 2], dtype=torch.float32).dtype) \n",
        "# 輸出 torch.float64\n",
        "print(torch.tensor([1, 2], dtype=torch.float64).dtype) \n",
        "print()\n",
        "\n",
        "# 宣告 LongTensor 變數\n",
        "t3 = torch.LongTensor([1, 2, 3])                       \n",
        "# 輸出 torch.int64\n",
        "print(t3.dtype)                                        \n",
        "\n",
        "# 宣告 FloatTensor 變數\n",
        "t4 = torch.FloatTensor([1, 2, 3])                      \n",
        "# 輸出 torch.float32\n",
        "print(t4.dtype)                                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G-IX1n6ckRw",
        "outputId": "fc8560d1-33a5-43da-ac6c-921b87b192da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3.])\n",
            "tensor([[0., 1.],\n",
            "        [2., 3.]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.arange(4.)\n",
        "print(a)\n",
        "resa = torch.reshape(a, (2, 2))\n",
        "print(resa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaPUOTC7dhxd"
      },
      "source": [
        "## view 和 reshape \n",
        "- 參考[官方網站連結](https://pytorch.org/docs/stable/tensor_view.html)，PyTorch allows a tensor to be a View of an existing tensor. `View` tensor shares the same underlying data with its base tensor. Supporting View avoids explicit data copy, thus allows us to do fast and memory efficient reshaping, slicing and element-wise operations.\n",
        "- ``torch.view(*shape)->Tensor``: Returns a new tensor with the same data as the self tensor but of a different shape. The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions $d,d+1,…,d+k$ that satisfy the following contiguity-like condition that $\\forall i = d, ... d+k-1$\n",
        "$$\n",
        "stride[i] = stride[i+1] \\times size[i+1]\n",
        "$$\n",
        "\n",
        "- ``torch.reshape(*shape)->Tensor``: \n",
        "Returns a tensor with the same data and number of elements as self but with the specified shape. This method returns a view if shape is compatible with the current shape. See ``torch.Tensor.view()`` on when it is possible to return a view.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg9RgMObbr-K",
        "outputId": "7ce67e53-f074-4cad-f00f-3958a192bef4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "torch.Size([4, 3])\n",
            "\n",
            "reshaped to (3,4): tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.Size([3, 4])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.Size([3, 4])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]])\n",
            "torch.Size([2, 6])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]])\n",
            "torch.Size([2, 6])\n",
            "\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[ 7,  8],\n",
            "         [ 9, 10],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 3, 2])\n",
            "\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[ 7,  8],\n",
            "         [ 9, 10],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "# size 屬性\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t5 = torch.tensor([               \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12],\n",
        "])\n",
        "\n",
        "# 輸出 Tensor\n",
        "print(t5)                         \n",
        "# 輸出 t5.size (4, 3)\n",
        "print(t5.size())                  \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(\"reshaped to (3,4):\", t5.reshape(3, 4))           \n",
        "# 輸出更改後的維度 (3, 4)\n",
        "print(t5.reshape(3, 4).size())    \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(3, 4))              \n",
        "# 輸出更改後的維度 (3, 4)\n",
        "print(t5.view(3, 4).size())       \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(t5.reshape(2, 6))           \n",
        "# 輸出更改後的維度 (2, 6)\n",
        "print(t5.reshape(2, 6).size())    \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(2, 6))              \n",
        "# 輸出更改後的維度 (2, 6)\n",
        "print(t5.view(2, 6).size())       \n",
        "print()\n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(t5.reshape(2, 3, 2))        \n",
        "# 輸出更改後的維度 (2, 3, 2)\n",
        "print(t5.reshape(2, 3, 2).size()) \n",
        "print()\n",
        "# 重新更改 t5.size\n",
        "print(t5.view(2, 3, 2))           \n",
        "# 輸出更改後的維度 (2, 3, 2)\n",
        "print(t5.view(2, 3, 2).size())    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy1L8FOqbr-K"
      },
      "source": [
        "## 張量取值\n",
        "\n",
        "與 `numpy` 語法概念相似。\n",
        "\n",
        "- 使用 `torch.Tensor[位置]` 來取得 `torch.Tensor` 中指定位置的值\n",
        "    - 若為**多個維度**的張量，則使用 `tuple` 來取得指定位置的值\n",
        "    - 若位置為**負數**，則等同於反向取得指定位置的值\n",
        "    - 取出的值會以 `torch.Tensor.dtype` 的形式保留\n",
        "- 使用 `torch.Tensor[起始位置:結束位置]` 來取得 `torch.Tensor` 中的部分**連續**值\n",
        "    - **包含起始位置**的值\n",
        "    - **不包含結束位置**的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用 `torch.Tensor[iterable]`（例如 `list`, `tuple` 等）來取得**多個** `torch.Tensor` 中的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用判斷式來取得 `torch.Tensor` 中的部份資料\n",
        "    - 經由判斷式所得結果也為 `torch.Tensor`\n",
        "    - 判斷式所得結果之 `torch.Tensor.dtype` 為**布林值** `bool`（`True` 或 `False`）\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214IwVJEbr-K",
        "outputId": "daaee408-eeb4-4836-92c5-31eb8a5ffa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2])\n",
            "tensor([3, 4, 5])\n",
            "tensor([6, 7, 8])\n",
            "tensor([6, 7, 8])\n",
            "tensor([ 9, 10, 11])\n",
            "\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor(5)\n",
            "tensor(11)\n",
            "tensor(10)\n",
            "tensor(8)\n"
          ]
        }
      ],
      "source": [
        "# 張量取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t6 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t6 中的第 0 個位置的值 [0, 1, 2]\n",
        "print(t6[0])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [3, 4, 5]\n",
        "print(t6[1])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [6, 7, 8]\n",
        "print(t6[2])        \n",
        "# 輸出張量 t6 中的第 -2 個位置的值 [6, 7, 8]\n",
        "print(t6[-2])       \n",
        "# 輸出張量 t6 中的第 -1 個位置的值 [9, 10, 11]\n",
        "print(t6[-1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t6 中的第 [0, 0] 個位置的值 0\n",
        "print(t6[0, 0])     \n",
        "# 輸出張量 t6 中的第 [0, 1] 個位置的值 1\n",
        "print(t6[0, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 1] 個位置的值 4\n",
        "print(t6[1, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 2] 個位置的值 5\n",
        "print(t6[1, 2])     \n",
        "# 輸出張量 t6 中的第 [-1, -1] 個位置的值 11\n",
        "print(t6[-1, -1])   \n",
        "# 輸出張量 t6 中的第 [-1, -2] 個位置的值 10\n",
        "print(t6[-1, -2])   \n",
        "# 輸出張量 t6 中的第 [-2, -1] 個位置的值 8\n",
        "print(t6[-2, -1])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TTmmlRLbr-K",
        "outputId": "4e0a0eee-0766-44c6-badb-1432de18717d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0, 10, 20])\n",
            "tensor([70, 80, 90])\n",
            "tensor([ 0, 10])\n",
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "\n",
            "tensor([[ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 1, 2]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "# 取連續值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t7 = torch.tensor([ \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t7 位置 0, 1, 2 但是不含位置 3 的值 [0, 10, 20]\n",
        "print(t7[0:3])      \n",
        "# 輸出張量 t7 位置 7, 8, 9 的值 [70, 80, 90]\n",
        "print(t7[7:])       \n",
        "# 輸出張量 t7 位置 0, 1 但是不含位置 2 的值 [0, 10]\n",
        "print(t7[:2])       \n",
        "# 輸出張量 t7 所有位置的值 [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "print(t7[:])        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t8 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t8 位置 0, 1, 但是不含位置 2 的值 [[0, 1, 2], [3, 4, 5]]\n",
        "print(t8[0:2])      \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 1, 2, 3 的值 [[3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[1:])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2]]\n",
        "print(t8[:1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[:])        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5w2A_hbr-K",
        "outputId": "68f5efa5-01ab-4fd1-93b8-6eae16e59691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0, 20, 40, 60, 80])\n",
            "\n",
            "tensor([10, 30, 50, 70, 90])\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "\n",
            "tensor([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# 使用 iterable 取得多個值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t9 = torch.tensor([        \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t9 中偶數位置的值 [0, 20, 40, 60, 80]\n",
        "print(t9[[0, 2, 4, 6, 8]]) \n",
        "print()\n",
        "# 輸出張量 t9 中奇數位置的值 [10, 30, 50, 70, 90]\n",
        "print(t9[[1, 3, 5, 7, 9]]) \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t10 = torch.tensor([       \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 輸出張量 t10[0] 與 t10[1] 的值 [[1, 2, 3, 4] [5, 6, 7, 8]]\n",
        "print(t10[[0, 1]])         \n",
        "print()\n",
        "# 輸出張量 t10[0, 2] 與 t10[1, 3] 的值 [3, 8]\n",
        "print(t10[[0, 1], [2, 3]]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBfUCkxbr-K",
        "outputId": "13257ce4-76d5-42cb-9b7f-7a45331e1c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([False, False, False, False, False, False,  True,  True,  True,  True])\n",
            "torch.bool\n",
            "tensor([60, 70, 80, 90])\n",
            "tensor([ 0, 20, 40, 60, 80])\n"
          ]
        }
      ],
      "source": [
        "# 判斷式取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t11 = torch.tensor([      \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出每個值是否大於 50 的 `torch.Tensor`\n",
        "print(t11 > 50)           \n",
        "# 輸出 torch.bool\n",
        "print((t11 > 50).dtype)   \n",
        "# 輸出大於 50 的值 [60, 70, 80, 90]\n",
        "print(t11[t11 > 50])      \n",
        "# 輸出除以 20 餘數為 0 的值 [0, 20, 40, 60, 80]\n",
        "print(t11[t11 % 20 == 0]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x72LPvvtbr-K"
      },
      "source": [
        "## 張量運算\n",
        "\n",
        "### 純量運算（Scalar Operation）\n",
        "\n",
        "對張量內所有數值與單一純量（Scalar）進行相同計算。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`torch.Tensor + scalar`|張量中的每個數值加上 `scalar`|\n",
        "|`torch.Tensor - scalar`|張量中的每個數值減去 `scalar`|\n",
        "|`torch.Tensor * scalar`|張量中的每個數值乘上 `scalar`|\n",
        "|`torch.Tensor / scalar`|張量中的每個數值除以 `scalar`|\n",
        "|`torch.Tensor // scalar`|張量中的每個數值除以 `scalar` 所得之商|\n",
        "|`torch.Tensor % scalar`|張量中的每個數值除以 `scalar` 所得之餘數|\n",
        "|`torch.Tensor ** scalar`|張量中的每個數值取 `scalar` 次方|\n",
        "\n",
        "### 個別數值運算（Element-wise Operation）\n",
        "\n",
        "若兩個張量想要進行運算，則兩個張量的**維度必須相同**（即兩張量之 `torch.size()` 相同）。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`A + B`|張量 `A` 中的每個數值加上張量 `B` 中相同位置的數值|\n",
        "|`A - B`|張量 `A` 中的每個數值減去張量 `B` 中相同位置的數值|\n",
        "|`A * B`|張量 `A` 中的每個數值乘上張量 `B` 中相同位置的數值|\n",
        "|`A / B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值|\n",
        "|`A // B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之商|\n",
        "|`A % B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之餘數|\n",
        "|`A ** B`|張量 `A` 中的每個數值取張量 `B` 中相同位置的數值之次方|\n",
        "\n",
        "### 個別數值函數運算（Element-wise Functional Operation）\n",
        "\n",
        "若想對張量中的**所有數值**進行**相同函數運算**，必須透過 `torch` 提供的介面進行。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sin`|張量中的每個數值 $x$ 計算 $\\sin(x)$|\n",
        "|`torch.cos`|張量中的每個數值 $x$ 計算 $\\cos(x)$|\n",
        "|`torch.tan`|張量中的每個數值 $x$ 計算 $\\tan(x)$|\n",
        "|`torch.exp`|張量中的每個數值 $x$ 計算 $e^{x}$|\n",
        "|`torch.log`|張量中的每個數值 $x$ 計算 $\\log x$\n",
        "|`torch.ceil`|張量中的每個數值 $x$ 計算 $\\left\\lceil x \\right\\rceil$\n",
        "|`torch.floor`|張量中的每個數值 $x$ 計算 $\\left\\lfloor x \\right\\rfloor$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR54kMUdbr-L",
        "outputId": "be0f0dd1-9f3c-46ea-f7b9-3b97415423e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  0,  10,  20],\n",
            "        [ 30,  40,  50],\n",
            "        [ 60,  70,  80],\n",
            "        [ 90, 100, 110]])\n",
            "\n",
            "tensor([[  5,  15,  25],\n",
            "        [ 35,  45,  55],\n",
            "        [ 65,  75,  85],\n",
            "        [ 95, 105, 115]])\n",
            "\n",
            "tensor([[ -4,   6,  16],\n",
            "        [ 26,  36,  46],\n",
            "        [ 56,  66,  76],\n",
            "        [ 86,  96, 106]])\n",
            "\n",
            "tensor([[  0,  30,  60],\n",
            "        [ 90, 120, 150],\n",
            "        [180, 210, 240],\n",
            "        [270, 300, 330]])\n",
            "\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 3, 6],\n",
            "        [2, 5, 1],\n",
            "        [4, 0, 3],\n",
            "        [6, 2, 5]])\n",
            "\n",
            "tensor([[    0,   100,   400],\n",
            "        [  900,  1600,  2500],\n",
            "        [ 3600,  4900,  6400],\n",
            "        [ 8100, 10000, 12100]])\n"
          ]
        }
      ],
      "source": [
        "# 純量運算(Scalar Operation)\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t12 = torch.tensor([ \n",
        "    [0, 10, 20],\n",
        "    [30, 40, 50],\n",
        "    [60, 70, 80],\n",
        "    [90, 100, 110],\n",
        "])\n",
        "\n",
        "# 輸出張量 t12\n",
        "print(t12)           \n",
        "print()\n",
        "# 對張量 t12 所有數值加 5\n",
        "print(t12 + 5)       \n",
        "print()\n",
        "# 對張量 t12 所有數值減 4\n",
        "print(t12 - 4)       \n",
        "print()\n",
        "# 對張量 t12 所有數值乘 3\n",
        "print(t12 * 3)       \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10\n",
        "print(t12 / 10)      \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10 所得整數部份\n",
        "print(t12 // 10)     \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 7 得到餘數\n",
        "print(t12 % 7)       \n",
        "print()\n",
        "# 對張量 t12 所有數值取 2 次方\n",
        "print(t12 ** 2)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0xQnAE0br-L",
        "outputId": "15ee2e34-64e9-4f31-b6eb-145ce11aac74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7, 7, 7],\n",
            "        [7, 7, 7]])\n",
            "\n",
            "tensor([[-5, -3, -1],\n",
            "        [ 1,  3,  5]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 個別數值運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t13 = torch.tensor([ \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t14 = torch.tensor([ \n",
        "    [6, 5, 4],\n",
        "    [3, 2, 1]\n",
        "])\n",
        "\n",
        "# 張量相加\n",
        "print(t13 + t14)     \n",
        "print()\n",
        "# 張量相減\n",
        "print(t13 - t14)     \n",
        "print()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9af-M7xux8i"
      },
      "source": [
        "\n",
        "**Q: 有辦法做這個效果嗎？**\n",
        "\n",
        "```\n",
        "F(v) = (f(v_1),f(v_2),f(v_3),…,f(v_n))\n",
        "```\n",
        "Ans: 沒辦法提供一個可以直接輸入 f() 的函數，如果 f 能夠被 rewritten into torch.cos(), torch.sin() 等函數的組合就可以平行做 element-wise operation。\n",
        "- [Can we do an element-wise any function similar to map()](https://discuss.pytorch.org/t/apply-a-function-similar-to-map-on-a-tensor/51088)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GenMDYK4br-L",
        "outputId": "0c79e347-6861-4d68-af5d-12c23500b19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  7.0711e-01,  1.0000e+00,  7.0711e-01],\n",
            "        [-8.7423e-08, -7.0711e-01, -1.0000e+00, -7.0711e-01]])\n",
            "\n",
            "tensor([[ 1.0000e+00,  7.0711e-01, -4.3711e-08, -7.0711e-01],\n",
            "        [-1.0000e+00, -7.0711e-01,  1.1925e-08,  7.0711e-01]])\n",
            "\n",
            "tensor([[ 0.0000e+00,  1.0000e+00, -2.2877e+07, -1.0000e+00],\n",
            "        [ 8.7423e-08,  1.0000e+00, -8.3858e+07, -1.0000e+00]])\n",
            "\n",
            "tensor([[  2.7183,   7.3891,  20.0855],\n",
            "        [ 54.5981, 148.4132, 403.4288]])\n",
            "\n",
            "tensor([[0.0000, 0.6931, 1.0986],\n",
            "        [1.3863, 1.6094, 1.7918]])\n",
            "\n",
            "tensor([[0., 1., 2.],\n",
            "        [2., 2., 2.]])\n",
            "\n",
            "tensor([[0., 0., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# 個別數值函數運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t15 = torch.tensor([               \n",
        "    [0,     np.pi / 4,     np.pi / 2,     np.pi / 4 * 3],\n",
        "    [np.pi, np.pi / 4 * 5, np.pi / 2 * 3, np.pi / 4 * 7]\n",
        "])\n",
        "\n",
        "# 張量所有數值計算 sine\n",
        "print(torch.sin(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 cosine\n",
        "print(torch.cos(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 tangent\n",
        "print(torch.tan(t15))              \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t16 = torch.tensor([               \n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "])\n",
        "\n",
        "# 張量所有數值取指數\n",
        "print(torch.exp(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數\n",
        "print(torch.log(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數後無條件進位\n",
        "print(torch.ceil(torch.log(t16)))  \n",
        "print()\n",
        "# 張量所有數值取對數後無條件捨去\n",
        "print(torch.floor(torch.log(t16))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqQy9aOrdyw",
        "outputId": "51511ac1-3fa5-4f21-865a-f15de0cd19c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 6, 10, 12],\n",
            "        [12, 10,  6]])\n",
            "\n",
            "tensor([[0.1667, 0.4000, 0.7500],\n",
            "        [1.3333, 2.5000, 6.0000]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [1, 2, 6]])\n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 1, 0]])\n",
            "\n",
            "tensor([[ 1, 32, 81],\n",
            "        [64, 25,  6]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t13 = torch.tensor([ \n",
        "#     [1, 2, 3],\n",
        "#     [4, 5, 6]\n",
        "# ])\n",
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t14 = torch.tensor([ \n",
        "#     [6, 5, 4],\n",
        "#     [3, 2, 1]\n",
        "# ])\n",
        "\n",
        "\n",
        "# 張量相乘\n",
        "print(t13 * t14)     \n",
        "print()\n",
        "# 張量相除\n",
        "print(t13 / t14)     \n",
        "print()\n",
        "# 張量相除取商\n",
        "print(t13 // t14)    \n",
        "print()\n",
        "# 張量相除取餘數\n",
        "print(t13 % t14)     \n",
        "print()\n",
        "# 張量 A 取張量 B 次方\n",
        "print(t13 ** t14)\n",
        "# res[0][0] = A[0][0]**B[0][0]\n",
        "# res[0][1] = A[0][1]**B[0][1]\n",
        "# ...\n",
        "# res[i][j] = A[i][j]**B[i][j]\n",
        "# 0 <= i < 2\n",
        "# 0 <= j < 3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnh-f7nOXZsV",
        "outputId": "92323936-2bf9-4ee4-f137-85a73bfa45d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1])\n",
            "tensor([[5.3276, 0.3323, 0.5104, 2.3186, 0.7108],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
            "torch.Size([2, 5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[2], [1]])\n",
        "print(a.size())         # a shape: (2, 1) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "\n",
        "try:\n",
        "  print(y:=a**b)\n",
        "  # a, b 雖然 size mismatch，但適用張量自動擴充的條件3\n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8zfKUqcdHjO",
        "outputId": "65f69658-9077-47d8-af76-59011d53735d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 5])\n",
            "Error Message: The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[2,5], [1,4]])\n",
        "print(a.size())         # a shape: (2, 2) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "print(b.size())\n",
        "try:\n",
        "  print(y:=a**b) \n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print('Error Message:', e)\n",
        "  # 從最後一個維度開始比較，如果有任何維度無法滿足條件，則得到 error "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUbDIOiv4Uk"
      },
      "source": [
        "\n",
        "### 🚧 **張量自動擴充（Broadcasting)**\n",
        "\n",
        "若張量 `A` 的維度為 `(a1, a2, ..., an)`（即 `A.size() == (a1, a2, ..., an)`），則張量 `B` 在滿足以下其中一種條件時即可與張量 `A` 進行運算：\n",
        "\n",
        "- 張量 `B` 與張量 `A` 維度完全相同（即 `B.size() == (a1, a2, ..., an)`）\n",
        "- 張量 `B` 為純量（即 `B.size() == (1,)`）\n",
        "- 張量 `B` 的維度為 `(b1, b2, ..., bn)`，若 `ai != bi`，則 `ai == 1` 或 `bi == 1`\n",
        "    - 從**最後**一個維度開始比較\n",
        "    - 如果有任何一個維度無法滿足前述需求，則會得到 `ValueError`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6pu71GVbr-L",
        "outputId": "379f17c1-8e58-416b-a124-534eb3604055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 2])\n",
            "torch.Size([2, 3, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 張量自動擴充\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t17 = torch.tensor([ \n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "    ],\n",
        "    [\n",
        "        [7, 8],\n",
        "        [9 ,10],\n",
        "        [11, 12]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t18 = torch.tensor([ \n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]\n",
        "    ],\n",
        "    [\n",
        "        [2],\n",
        "        [2],\n",
        "        [2]\n",
        "    ],\n",
        "])\n",
        "\n",
        "# 輸出張量 t17 維度\n",
        "print(t17.size())    \n",
        "# 輸出張量 t18 維度\n",
        "print(t18.size())    \n",
        "print()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ryiNnF9wDOr",
        "outputId": "49c0c912-b68d-4ac4-db99-6d22f6e7c9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2,  4],\n",
            "         [ 6,  8],\n",
            "         [10, 12]],\n",
            "\n",
            "        [[14, 16],\n",
            "         [18, 20],\n",
            "         [22, 24]]])\n",
            "\n",
            "tensor([[[ 2,  3],\n",
            "         [ 4,  5],\n",
            "         [ 6,  7]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [11, 12],\n",
            "         [13, 14]]])\n"
          ]
        }
      ],
      "source": [
        "# 張量 t17 與張量 t17 維度相同，所以可以直接運算\n",
        "print(t17 + t17)     \n",
        "print()\n",
        "# 張量 t17 與張量 t18 可以擴充成相同維度，所以可以運算\n",
        "print(t17 + t18)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdmIDslGbr-L"
      },
      "source": [
        "## 創造張量\n",
        "\n",
        "### 賦值（Assignment）\n",
        "\n",
        "使用 `=` 賦與指定位置數值。可以使用 `iterable` 一次指定多個位置。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`=`|賦值|\n",
        "|`+=`|進行加法後賦值|\n",
        "|`-=`|進行減法後賦值|\n",
        "|`*=`|進行乘法後賦值|\n",
        "\n",
        "### 隨機（Random）\n",
        "\n",
        "創造出新的張量，所有數值皆為**隨機決定**，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|備註|\n",
        "|-|-|-|-|\n",
        "|`torch.empty`|創造隨機未初始化張量|已確認維度，尚未確認數值|無法控制隨機|\n",
        "|`torch.rand`|創造隨機浮點數張量，並符合均勻分佈|需要隨機浮點數時|透過均勻分佈決定亂數，範圍介於 0 到 1之間|\n",
        "|`torch.randn`|創造隨機浮點數張量，並符合常態分佈|需要符合常態分佈的隨機浮點數時|透過常態分佈決定亂數，$\\mu = 0$ 且 $\\sigma = 1$|\n",
        "|`torch.randint`|創造隨機整數張量|需要隨機整數時|透過均勻分佈決定亂數，可以控制隨機範圍|\n",
        "\n",
        "### 指定數值（Filled In）\n",
        "\n",
        "**快速創造**擁有特定數值的張量，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|\n",
        "|-|-|-|\n",
        "|`torch.zeros`|創造指定維度大小的張量，所有數值初始化為 0|快速初始化|\n",
        "|`torch.zeros_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 0|複製張量並初始化|\n",
        "|`torch.ones`|創造指定維度大小的張量，所有數值初始化為 1|快速初始化|\n",
        "|`torch.ones_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 1|複製張量並初始化|\n",
        "|`torch.full`|創造指定維度大小的張量，所有數值初始化為指定數值|快速初始化|\n",
        "|`torch.full_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為指定數值|複製張量並初始化|\n",
        "|`torch.eye`|創造單位矩陣|矩陣微分|\n",
        "|`torch.arange`|列舉數字|等同於 `list(range(value))`|\n",
        "\n",
        "### 從 numpy 轉換\n",
        "\n",
        "可以使用 `torch.tensor()` 將 `numpy.ndarray` 轉換成 `torch.Tensor`；\n",
        "使用 `torch.numpy()` 將 `torch.Tensor` 轉換成 `numpy.ndarray`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvxSd3X1br-L",
        "outputId": "99dc0132-e0ca-4054-8228-691b67b01261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1995, 1995, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10,   12],\n",
            "        [   4,    5,    6],\n",
            "        [   7,   12,    9],\n",
            "        [  10,   11,   12]])\n"
          ]
        }
      ],
      "source": [
        "# 賦值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t19 = torch.tensor([     \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 0 的所有數值改成 1995\n",
        "t19[0] = 1995            \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [0, 1] 的所有數值改成 10\n",
        "t19[0, 1] = 10           \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [2, 1] 與 [0, 2] 的所有數值改成 12\n",
        "t19[[2, 0], [1, 2]] = 12 \n",
        "print(t19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LzdLlgbr-L",
        "outputId": "86617d59-d3f7-4d96-a078-62240a2313da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1996, 1997, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1996, 1987, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t20 = torch.tensor([      \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 0 的所有數值加上 1995\n",
        "t20[0] += 1995            \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [0, 1] 的所有數值減掉 10\n",
        "t20[0, 1] -= 10           \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [2, 1] 與 [0, 2] 的所有數值乘上 12\n",
        "t20[[2, 0], [1, 2]] *= 12 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2p5aidybr-L",
        "outputId": "8c79bb15-c76b-44b0-f85d-ac06766fa457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.7332e+25, 4.5979e+24, 4.3060e+21],\n",
            "        [2.7374e+20, 2.0499e-10, 1.9524e+31]])\n",
            "\n",
            "tensor([[0.5329, 0.1845, 0.9435],\n",
            "        [0.2427, 0.7500, 0.5814]])\n",
            "\n",
            "tensor([[3.4029, 7.9352, 8.4165],\n",
            "        [1.8039, 9.6753, 4.2124]])\n",
            "\n",
            "tensor([[ 0.6507,  3.0926, -3.0998],\n",
            "        [-1.6097,  1.3854,  1.5861]])\n",
            "\n",
            "tensor([[ 0.2872, -1.3126, -0.8284],\n",
            "        [-0.9454, -0.7942, -0.7240]])\n",
            "\n",
            "tensor([[ 2,  2, -4],\n",
            "        [-4, -1,  4]])\n"
          ]
        }
      ],
      "source": [
        "# 隨機\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為無法控制範圍的浮點\n",
        "print(torch.empty((2, 3)))               \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 1 之間的浮點\n",
        "print(torch.rand(2, 3))                  \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 10 之間的浮點\n",
        "print(torch.rand(2, 3) * 10)             \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.rand(2, 3) * 10 - 5)         \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，分佈為平均值為 0 標準差為 1 的常態分佈\n",
        "print(torch.randn(2, 3))                 \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.randint(-5, 5, size=(2, 3))) \n",
        "                                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmziKBTmbr-L",
        "outputId": "e573b226-6f80-4367-e988-6473282df5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "tensor([[1, 1, 1, 1],\n",
            "        [1, 1, 1, 1],\n",
            "        [1, 1, 1, 1]])\n",
            "\n",
            "tensor([[420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420]])\n",
            "\n",
            "tensor([[69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69]])\n"
          ]
        }
      ],
      "source": [
        "# 指定數值\n",
        "# 創造維度為 (2, 3) 的張量，並初始化為 0\n",
        "print(torch.zeros((2, 3)))      \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t21 = torch.tensor([            \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "# 複製張量 t21 的維度，創造出新的張量，並初始化為 0\n",
        "print(torch.zeros_like(t21))    \n",
        "print()\n",
        "\n",
        "# 創造維度為 (3, 4) 的張量，並初始化為 1\n",
        "print(torch.ones((3, 4)))       \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t22 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "# 複製張量 t22 的維度，創造出新的張量，並初始化為 1\n",
        "print(torch.ones_like(t22))     \n",
        "print()\n",
        "\n",
        "# 創造維度為 (5, 6) 的張量，並初始化為 420\n",
        "print(torch.full((5, 6), 420))  \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t23 = torch.tensor([            \n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "    [7, 8, 9, 10, 11, 12],\n",
        "    [13, 14, 15, 16, 17, 18],\n",
        "    [19, 20, 21, 22, 23, 24],\n",
        "    [25, 26, 27, 28, 29, 30]\n",
        "])\n",
        "# 複製張量 t23 的維度，創造出新的張量，並初始化為 69\n",
        "print(torch.full_like(t23, 69)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJgdH-vabr-L",
        "outputId": "ffab6382-383b-4dde-cddb-b4cd1e29b8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "tensor([6, 7, 8])\n",
            "\n",
            "tensor([ 4, 11, 18])\n"
          ]
        }
      ],
      "source": [
        "# 創造 3x3 單位矩陣\n",
        "print(torch.eye(3))           \n",
        "print()\n",
        "\n",
        "# 從 0 列舉至 10，但不包含 10\n",
        "print(torch.arange(10))       \n",
        "print()\n",
        "\n",
        "# 從 6 列舉至 9，但不包含 9\n",
        "print(torch.arange(6, 9))     \n",
        "print()\n",
        "\n",
        "# 從 4 遞增至 20，但不包含 20，每次遞增 7\n",
        "print(torch.arange(4, 20, 7)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkT3EX7br-L",
        "outputId": "16ae7f16-37a4-46b8-d714-99fa73b6999d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original numpy.ndarray: [1. 2. 3.], dtype: float64\n",
            "converted torch.Tensor: tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n",
            "converted numpy.ndarray: [1. 2. 3.], dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 從 numpy 轉換\n",
        "\n",
        "# 宣告 ndarray 變數\n",
        "arr1 = np.array([1., 2., 3.]) \n",
        "# 將 numpy.ndarray 轉換為 torch.Tensor\n",
        "t24 = torch.tensor(arr1)      \n",
        "# 將 torch.Tensor 轉換為 numpy.ndarray\n",
        "arr2 = t24.numpy()            \n",
        "\n",
        "print((\n",
        "    'original numpy.ndarray: {}, dtype: {}\\n' + \n",
        "    'converted torch.Tensor: {}, dtype: {}\\n' +\n",
        "    'converted numpy.ndarray: {}, dtype: {}'\n",
        ").format(\n",
        "    arr1, arr1.dtype,\n",
        "    t24, t24.dtype,\n",
        "    arr2, arr2.dtype\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STyE59Zgbr-M"
      },
      "source": [
        "## 高維張量運算\n",
        "\n",
        "矩陣等同於是維度為 2 的張量。\n",
        "而高維度的張量運算等同於**固定大部分的維度**，只使用**其中的兩個維度進行計算**。\n",
        "\n",
        "### 張量乘法（Tensor Multiplication）\n",
        "\n",
        "令 $A$ 與 $B$ 為兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$, $B.\\text{size}() = (b_1, b_2, ..., b_{n - 1}, b_n)$。定義 $A \\times B$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "a_i &= b_i \\forall i \\in \\{1, \\dots, n - 2\\} \\\\\n",
        "a_n &= b_{n - 1} \\\\\n",
        "(A \\times B).\\text{size}() &= (d_1, d_2, \\dots, d_{n - 2}, a_{n - 1}, b_n) \\\\\n",
        "&, \\text{where } d_i = a_i = b_i \\forall i \\in \\{1, 2, \\dots, n - 2\\} \\\\\n",
        "(A \\times B)_{d_1, d_2, \\dots, d_{n - 2}, i, j} &=\n",
        "\\begin{cases}\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{i, k} \\times B_{k, j} & \\text{if } n = 2 \\\\\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{d_1, d_2, \\dots, d_{n - 2}, i, k} \\times B_{d_1, d_2, \\dots, d_{n - 2}, k, j} & \\text{if } n > 2\n",
        "\\end{cases} \\\\\n",
        "&, \\forall i \\in \\{1, \\dots, a_1\\}, j \\in \\{1, \\dots, b_2\\}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 與 $B.\\text{size}() = (5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (5, 4, 2)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 與 $B.\\text{size}() = (1995, 10, 12, 5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (1995, 10, 12, 5, 4, 2)$。\n",
        "\n",
        "在 `torch` 中張量乘法為 `torch.matmul(A, B)`。\n",
        "\n",
        "### 張量轉置（Tensor Transpose）\n",
        "\n",
        "令 $A$ 兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$。定義 $A^{\\top}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top} &= (A_{a_1, a_2, \\dots, a_{n - 2}, a_{n - 1}, a_n})^{\\top} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_{n - 2}, a_n, a_{n - 1}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "即交換張量 $A$ 的最後兩個維度。若想要指定不同的維度 $i, j$ 進行轉置，則定義 $A^{\\top_{i, j}}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top_{i, j}} &= (A_{a_1, a_2, \\dots, a_i, \\dots, a_j, \\dots, a_n})^{\\top_i, j} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_j, \\dots, a_i, \\dots, a_n}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 來說，$A^{\\top_{1, 2}}.\\text{size}() = (5, 3, 4)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 來說，$A^{\\top_{3, 4}}.\\text{size}() = (1995, 10, 12, 4, 5, 3)$。\n",
        "\n",
        "在 `torch` 中張量轉置為 `torch.transpose(A, i, j)`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ntJ0Jzbr-M",
        "outputId": "5faaf6fb-06c5-4cce-e0b8-49bc569ab0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 4, 3])\n",
            "torch.Size([5, 3, 2])\n",
            "torch.Size([5, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "# 張量乘法\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t25 = torch.ones(5, 4, 3)    \n",
        "# 宣告 Tensor 變數\n",
        "t26 = torch.ones(5, 3, 2)    \n",
        "# 進行張量乘法\n",
        "t27 = torch.matmul(t25, t26) \n",
        "\n",
        "# 輸出張量 t25 的維度\n",
        "print(t25.size())            \n",
        "# 輸出張量 t26 的維度\n",
        "print(t26.size())            \n",
        "# 輸出張量 t27 的維度\n",
        "print(t27.size())            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iELV2wlbbr-M",
        "outputId": "c9c89622-150c-4b50-9273-c7ddd4265988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 4])\n",
            "torch.Size([5, 3, 4])\n",
            "torch.Size([3, 4, 5])\n",
            "torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "# 張量轉置\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t28 = torch.ones(5, 4, 3)                \n",
        "\n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(torch.transpose(t28, 1, 2).size()) \n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(t28.transpose(1, 2).size())        \n",
        "\n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(torch.transpose(t28, 0, 2).size()) \n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(t28.transpose(0, 2).size())        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uwt4npXsbr-M"
      },
      "source": [
        "## 維度運算\n",
        "\n",
        "### 降維函數（Dimension Decreasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**小於輸入**張量維度。\n",
        "在機器學習中你幾乎必定會用到 `torch.argmax()`。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sum`|將所有數值相加|\n",
        "|`torch.max`|取出所有數值中最大者|\n",
        "|`torch.min`|取出所有數值中最小者|\n",
        "|`torch.argmax`|取出所有數值中最大者的位置|\n",
        "|`torch.argmin`|取出所有數值中最小者的位置|\n",
        "|`torch.mean`|取出所有數值的平均值|\n",
        "|`torch.var`|取出所有數值的變異數|\n",
        "|`torch.std`|取出所有數值的標準差|\n",
        "|`torch.squeeze`|移除數字為 1 的維度|\n",
        "\n",
        "### 增維函數（Dimension Increasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**大於輸入**張量維度。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.cat`|串接多個相同維度的張量|\n",
        "|`torch.unsqueeze`|在指定的維度間增加 1 維度|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuN13HnNbr-M",
        "outputId": "c9c9fa52-3349-4cf1-f40e-a77be5b2befa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(78)\n",
            "tensor(78)\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([10, 26, 42])\n",
            "tensor([10, 26, 42])\n",
            "tensor(12)\n",
            "tensor(12)\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "tensor([ 9, 10, 11, 12])\n",
            "tensor([2, 2, 2, 2])\n",
            "\n",
            "tensor(1)\n",
            "tensor(1)\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "tensor([1, 5, 9])\n",
            "tensor([0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# 降維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t29 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 將張量 t29 中所有值相加\n",
        "print(torch.sum(t29))           \n",
        "# 將張量 t29 中所有值相加\n",
        "print(t29.sum())                \n",
        "\n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(torch.sum(t29, dim=0))    \n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(t29.sum(dim=0))           \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(torch.sum(t29, dim=1))    \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(t29.sum(dim=1))           \n",
        "\n",
        "# 找出張量 t29 中最大值\n",
        "print(torch.max(t29))          \n",
        "# 找出張量 t29 中最大值\n",
        "print(t29.max())                \n",
        "print()\n",
        "\n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(torch.max(t29, dim=0))    \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(t29.max(dim=0))           \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值\n",
        "print(torch.max(t29, dim=0)[0]) \n",
        "# 依照維度 0 找出張量 t29 中最大值位置\n",
        "print(torch.max(t29, dim=0)[1]) \n",
        "print()\n",
        "\n",
        "# 找出張量 t29 中最小值\n",
        "print(torch.min(t29))           \n",
        "# 找出張量 t29 中最小值\n",
        "print(t29.min())                \n",
        "print()\n",
        "\n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(torch.min(t29, dim=1))    \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(t29.min(dim=1))           \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值\n",
        "print(torch.min(t29, dim=1)[0]) \n",
        "# 依照維度 1 找出張量 t29 中最小值位置\n",
        "print(torch.min(t29, dim=1)[1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWn28FWbr-M",
        "outputId": "00eb6da5-fc1d-4366-92a9-955a6a11ac4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11)\n",
            "tensor(11)\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([3, 3, 3])\n",
            "tensor([3, 3, 3])\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor([0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0])\n",
            "tensor([0, 0, 0])\n",
            "tensor([0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t30 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30))        \n",
        "# 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax())             \n",
        "\n",
        "# 依照維度 0 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30, dim=0)) \n",
        "# 依照維度 0 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=0))        \n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30, dim=1)) \n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=1))        \n",
        "\n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30))        \n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin())             \n",
        "\n",
        "# 依照維度 0 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30, dim=0)) \n",
        "# 依照維度 0 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin(dim=0))        \n",
        "# 依照維度 1 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30, dim=1)) \n",
        "# 依照維度 1 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin(dim=1))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJwYUYHgbr-M",
        "outputId": "1cb7e250-de49-49f5-bf82-7c5a950c23b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5000)\n",
            "tensor(6.5000)\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor(13.)\n",
            "tensor(13.)\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor(3.6056)\n",
            "tensor(3.6056)\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t31 = torch.tensor([            \n",
        "    [1., 2., 3., 4.],\n",
        "    [5., 6., 7., 8.],\n",
        "    [9., 10., 11., 12.]\n",
        "])\n",
        "\n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31))         \n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean())              \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=0)) \n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=0))        \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=1)) \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=1))        \n",
        "\n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31))          \n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(t31.var())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=1))         \n",
        "\n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31))          \n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(t31.std())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=1))         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfXHwo9-br-M",
        "outputId": "bfaa7ffd-e9da-4a36-96f6-ffd3acfdfdac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "torch.Size([1, 3])\n",
            "tensor([1, 2, 3])\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t32 = torch.tensor([        \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 移除張量 t32 中多餘的維度\n",
        "t32_sq = torch.squeeze(t32) \n",
        "\n",
        "# 輸出張量 t32\n",
        "print(t32)                  \n",
        "# 輸出張量 t32 的維度\n",
        "print(t32.size())           \n",
        "# 輸出移除維度後的張量 t32\n",
        "print(t32_sq)               \n",
        "# 輸出移除維度後張量 t32 的維度\n",
        "print(t32_sq.size())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROt_wvYWbr-M",
        "outputId": "4a354c6d-1ba0-40b2-e3de-a27452320b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "torch.Size([4, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# 增維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t33 = torch.tensor([                  \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 串接多個張量 t33\n",
        "t33_cat = torch.cat([                 \n",
        "    t33,\n",
        "    t33,\n",
        "    t33,\n",
        "    t33\n",
        "]) \n",
        "\n",
        "# 輸出串接後的張量 t33_cat\n",
        "print(t33_cat)                        \n",
        "# 輸出串接後的張量 t33_cat 維度\n",
        "print(t33_cat.size())                 \n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t34 = torch.tensor([                  \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "print(t34)\n",
        "print(t34.size())\n",
        "\n",
        "# 對張量 t34 維度 0 增加 1 維\n",
        "t34_usq = torch.unsqueeze(t34, dim=0) \n",
        "\n",
        "# 輸出張量 t34 維度 0 增加 1 維後的結果\n",
        "print(t34_usq)                        \n",
        "# 輸出張量 t34 維度 0 增加 1 維後的維度\n",
        "print(t34_usq.size())                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpkIiN9Vbr-M"
      },
      "source": [
        "## 使用 GPU 運算\n",
        "\n",
        "上述的所有教學都是在 CPU 上進行運算，而大多數的深度學習框架都會提供操作 GPU 的介面幫助平型化運算。\n",
        "而 `torch` 與大部分的深度學習框架相同，使用 Nvidia 開發的 CUDA（Compute Unified Device Architecture）幫助使用 GPU 進行深度學習的運算（cuDNN）。\n",
        "\n",
        "使用 CUDA 操作平型化運算的流程為：\n",
        "\n",
        "1. 宣告 GPU 運算所需要佔用的記憶體（`cudaMalloc`）\n",
        "2. 定義每個平型化運算節點的運算內容\n",
        "3. 在主記憶體上創造資料（`malloc`）\n",
        "4. 將資料搬移至 GPU 的記憶體（`cudaMemcpy`）\n",
        "5. 每個節點獨立運算\n",
        "6. 將計算結果搬回至主記憶體（`memcpy`）\n",
        "7. 釋放 GPU 的記憶體（`cudaFree`）\n",
        "\n",
        "而在 `torch` 中將以上流程簡化成以下兩種方法\n",
        "\n",
        "- 宣告 `torch.Tensor` 變數時使用 `device='cuda:0'` 參數將變數宣告於 GPU 記憶體第0顆（0-indexed）。\n",
        "- 對已經創造於主記憶體的 `torch.Tensor` 變數使用 `torch.to('cuda:0')` 搬移至 GPU 記憶體第0顆（0-indexed）。\n",
        "```python\n",
        "torch.tensor([1., 2., 3.], device='cuda:0') # 使用 device 參數將變數宣告於 GPU 記憶體\n",
        "torch.tensor([1., 2., 3.]).to('cuda:0')     # 使用 to 將變數搬移至 GPU 記憶體\n",
        "```\n",
        "\n",
        "宣告於 GPU 或搬移至 GPU 後，之後所有的運算便會在 GPU 上進行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djuqIr7vbr-M",
        "outputId": "9c908a0d-17f7-4119-eba8-2b31a63bc5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 使用 GPU 運算\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # 使用 device 參數創造張量於 GPU 上\n",
        "    t35 = torch.tensor([1., 2., 3.], device='cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled')     \n",
        "    t35 = None\n",
        "    \n",
        "# 輸出張量 t35\n",
        "print(t35)                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKtEO_4Nbr-M",
        "outputId": "bc81130a-0364-46f8-f285-4e9dc15e71c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    # 使用 to 將張量搬移至 GPU 上\n",
        "    t36 = torch.tensor([1., 2., 3.]).to('cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled') \n",
        "    t36 = None\n",
        "    \n",
        "# 輸出張量 t36\n",
        "print(t36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dZ9N1Ybr-M",
        "outputId": "cfbd5e50-4101-4edb-8ed4-4f57532f2ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "tensor([1., 2., 3.], device='cuda:0')\n",
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "\n",
        "# 根據 device 創造張量\n",
        "t37 = torch.tensor([1., 2., 3.], device=device) \n",
        "# 使用 to 搬移張量至指定的裝置\n",
        "t38 = torch.tensor([1., 2., 3.]).to(device)     \n",
        "\n",
        "# 輸出張量 t37\n",
        "print(t37)                                      \n",
        "# 輸出張量 t38\n",
        "print(t38)                                      "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLKGH_vbr-M"
      },
      "source": [
        "## 深度學習\n",
        "\n",
        "![Deep Learning](https://miro.medium.com/max/1000/1*51D0MqtqHu3h2vTE5oJ-7g.png)\n",
        "![Deep Learning vs. Machine Learning](https://learn.microsoft.com/zh-tw/azure/machine-learning/media/concept-deep-learning-vs-machine-learning/ai-vs-machine-learning-vs-deep-learning.png)\n",
        "### 深度學習要幹嘛？\n",
        "上課教的 SVM, Bayes 等等的模型算是 （傳統）Machine Learning 的範疇，比較偏向建立於統計的假設的數學統計模型。而深度學習則是機器學習內的一個子集合（subset），他是以類神經網路來模擬人類大腦的神經元之間的互動。\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "使用 `torch` 進行深度學習主要包含以下步驟：\n",
        "1. 將資料轉換成 `torch.Tensor`，使用 Dataset 和 Dataloader 包裝管理資料。\n",
        "2. 使用 `torch.nn` 建立深度學習模型架構。\n",
        "3. 從 `torch.optim` 選擇最佳化工具。\n",
        "4. 選擇目標函數。\n",
        "5. 訓練深度學習模型（train）。\n",
        "6. 測試深度學習模型（test, inference）。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 資料集\n",
        "\n",
        "1. 使用 `torch.utils.data.Dataset` 將資料集轉換成 `torch.Tensor`\n",
        "2. 使用 `torch.utils.data.DataLoader` 將資料集以批次（mini-batch）取出\n",
        "3.（Optional）額外定義 `collate_fn` 將抽樣的資料整理成固定的格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFiFnsh5br-N",
        "outputId": "912e0668-6434-4d31-8111-bb111208753d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "(tensor(0.6629), tensor(19.8675))\n"
          ]
        }
      ],
      "source": [
        "# 資料集\n",
        "\n",
        "# 匯入資料集 base class\n",
        "from torch.utils.data import Dataset \n",
        "\n",
        "# 繼承 base class 創造資料集\n",
        "class MyDataset(Dataset):            \n",
        "    # 給予資料集大小，並隨機創造資料\n",
        "    def __init__(self, size):        \n",
        "        self.x = torch.rand(size) * 2 - 1\n",
        "        self.y = 2 * self.x ** 2 + 3 * self.x + 17\n",
        "        \n",
        "    # 定義總資料數\n",
        "    def __len__(self):               \n",
        "        return len(self.x)\n",
        "    \n",
        "    # 定義取出單一資料的方法\n",
        "    def __getitem__(self, index):    \n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "# 創造資料集\n",
        "my_dataset = MyDataset(10)           \n",
        "\n",
        "# 取得總資料數\n",
        "print(len(my_dataset))               \n",
        "# 取出單一資料\n",
        "print(my_dataset[0])                 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWP1moMObr-N",
        "outputId": "703e9283-8e0f-4f81-e5c4-8e008071aed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[-0.9473],\n",
            "        [-0.4346],\n",
            "        [-0.7715]]), tensor([[15.9529],\n",
            "        [16.0740],\n",
            "        [15.8759]])]\n",
            "\n",
            "[tensor([[-0.1021],\n",
            "        [-0.3618],\n",
            "        [ 0.6627]]), tensor([[16.7146],\n",
            "        [16.1765],\n",
            "        [19.8666]])]\n",
            "\n",
            "[tensor([[-0.5185],\n",
            "        [ 0.0592],\n",
            "        [ 0.6629]]), tensor([[15.9822],\n",
            "        [17.1846],\n",
            "        [19.8675]])]\n",
            "\n",
            "[tensor([[0.7855]]), tensor([[20.5905]])]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 匯入資料集抽樣工具\n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "# 定義格式化的方法\n",
        "def collate_fn(batch):                  \n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    \n",
        "    for x, y in batch:\n",
        "        # 將每個 x 轉換成 [x]\n",
        "        x_list.append([x])              \n",
        "        # 將每個 y 轉換成 [y]\n",
        "        y_list.append([y])              \n",
        "        \n",
        "    # 最終回傳的維度為 [(batch_size, features), (batch_size, labels)]\n",
        "    return [torch.tensor(x_list), torch.tensor(y_list)] \n",
        "batch_size = 3\n",
        "# 創造 DataLoader 實例\n",
        "my_data_loader = DataLoader(            \n",
        "    # 對資料集 my_dataset 進行抽樣\n",
        "    my_dataset,                         \n",
        "    # 設定每次抽樣的數量\n",
        "    batch_size=batch_size,                       \n",
        "    # 設定隨機抽樣\n",
        "    shuffle=True,                       \n",
        "    # 指定格式化的方法\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for data in my_data_loader:             \n",
        "    # 輸出抽樣結果\n",
        "    print(data)                         \n",
        "    print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqeXVb2e0tlT"
      },
      "source": [
        "### 建立模型\n",
        "\n",
        "可以使用 `torch.nn` 現成的模型進行深度學習，``torch`` 提供很多「神經層」（layer），可以用來建立模型的架構（architecture）。\n",
        "- 面對哪個任務應該用什麼模型？\n",
        "- 模型的輸入輸出的形式要如何定義？\n",
        "- 模型要怎麼架構？\n",
        "- 沒辦法一一的講，在[NN中文文本分類](NN-中文文本分類.ipynb)會講怎麼架構一顆 RNN 來做文本分類任務。其他神經層可以去[torch.nn](https://pytorch.org/docs/stable/nn.html)看看，怎麼架構只能先了解原理然後多查多練習：[PyTorch Tutorial](https://pytorch.org/tutorials/)。\n",
        "\n",
        "|模型介面|名稱|常見用途|\n",
        "|-|-|-|\n",
        "|`torch.nn.Linear`|線性層（Linear Layer）|轉換特徵|\n",
        "|`torch.nn.Embedding`|嵌入層（Embedding Layer）|學習特徵向量表達法|\n",
        "|`torch.nn.Conv1d`|1 維卷積層（1-Dimensional Convolution Layer）|抽取連續資料區域特徵|\n",
        "|`torch.nn.Conv2d`|2 維卷積層（2-Dimensional Convolution Layer）|抽取平面圖片區域特徵|\n",
        "|`torch.nn.Conv3d`|3 維卷積層（3-Dimensional Convolution Layer）|抽取立體圖片區域特徵|\n",
        "|`torch.nn.RNN`|循環神經網路（Recurrent Neural Network）|壓縮動態長度文字|\n",
        "|`torch.nn.LSTM`|長短期記憶神經網路（Long Short-Term Memory）|有效壓縮動態長度文字|\n",
        "|`torch.nn.Transformer`|多面向自我注意力機制模型（Multi-Head Self-Attention）|機器翻譯|\n",
        "\n",
        "如果需要使用深度學習模型，必須透過繼承 `torch.nn.Module` 來定義**模型結構**與**運算流程**：\n",
        "使用 `nn.Module` 定義模型時必須要記得以下規則：\n",
        "\n",
        "- 在類別方法 `__init__` 中定義模型結構\n",
        "    - 必須要執行 `super(MyModel, self).__init__()`\n",
        "    - 為什麼需要：[colab link](https://colab.research.google.com/drive/1LL1RVaoGoGYE68HCaMOEVSCR8bEPgqqc?usp=sharing)\n",
        "- 必須透過定義類別方法 `forward` 才能定義計算流程"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QWrkuLw005aB"
      },
      "source": [
        "\n",
        "### 啟動函數（Activation Functions）\n",
        "\n",
        "若模型需要啟動函數，可以使用 `torch.nn.functional` 中事先定義好的啟動函數：\n",
        "常見的啟動函數包含：\n",
        "\n",
        "|啟動函數|名稱|定義|數值範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.nn.functional.relu`|ReLU|$$f(x_i) = \\max(0, x_i)$$|$$\\mathbb{R}^+$$|\n",
        "|`torch.nn.functional.softmax`|Softmax|$$f(x_i) = \\frac{e^{x_i}}{\\sum_{j = 0}^n e^{x_j}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.sigmoid`|Sigmoid|$$f(x_i) = \\frac{1}{1 + e^{-x_i}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.tanh`|Hyperbolic Tangent|$$f(x_i) = \\frac{e^{x_i} - e^{-x_i}}{e^{x_i} + e^{-x_i}}$$|$$[-1, 1]$$|\n",
        "\n",
        "#### Why do we need Activation Functions? \n",
        "- "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/Screenshot-from-2020-02-03-22-14-21-300x195.png)\n",
        "- $X$: input \n",
        "- $W, b$: the parameters we would like to fit. \n",
        "- $Z$: the output we would like to get. \n",
        "- If multiple layers are stacked, $Z$ will be the input of the next layer. In general, we would like the FINAL layer's output to be close \n",
        "to the ground truth $Y$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmmUqpKLbr-N",
        "outputId": "8c4252de-75a9-4bac-e425-84fb8e3e4017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_x shape: torch.Size([3, 1])\n",
            "batch_y shape: torch.Size([3, 1])\n",
            "pred_y shape: torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# 建立模型\n",
        "\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn                   \n",
        "# 匯入啟動函數\n",
        "import torch.nn.functional as F         \n",
        "\n",
        "# 模型需要繼承自 nn.Module\n",
        "class MyModel(nn.Module):               \n",
        "    # 定義模型結構, 輸入層維度, 隱藏層維度, 輸出層維度\n",
        "    def __init__(self,                  \n",
        "                 in_dim,                \n",
        "                 hid_dim,               \n",
        "                 out_dim):              \n",
        "\n",
        "        # 繼承 nn.Module 所有屬性\n",
        "        super(MyModel, self).__init__() \n",
        "        \n",
        "        # 創造線性層 self.layer1\n",
        "        self.layer1 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=in_dim,         \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=hid_dim        \n",
        "        )\n",
        "        # 創造線性層 self.layer2\n",
        "        self.layer2 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=hid_dim,        \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=out_dim      \n",
        "        )\n",
        "        \n",
        "    # [Important] 定義運算流程\n",
        "    def forward(self, batch_x): \n",
        "        # Why use ReLU?       \n",
        "        # 使用線性層 self.layer1 輸入 batch_x 計算得到 h\n",
        "                                     # batch_x's shape: (batch_size, in_dim)\n",
        "        h = self.layer1(batch_x)     # h = Wx + b, h's shape: (batch_size, hid_dim)   \n",
        "                                    # 使用 ReLU 啟動函數輸入 h 得到 a\n",
        "        a = F.relu(h)                # a = ReLU(h), a's shape: (batch_size, hid_dim)        \n",
        "                                    # 使用線性層 self.layer2 輸入 a 計算得到 y\n",
        "        y = self.layer2(a)           # y = Wa + b, y's shape: (batch_size, out_dim) \n",
        "        \n",
        "        \n",
        "        # 輸出 y\n",
        "        return y                        \n",
        "    \n",
        "# 創造 MyModel 模型實例\n",
        "my_model = MyModel(                     \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=10,                         \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    print('batch_x shape:', batch_x.shape)\n",
        "    print('batch_y shape:', batch_y.shape) \n",
        "    pred_y = my_model(batch_x)   # this part calls my_model.forward(batch_x)       \n",
        "    print('pred_y shape:', pred_y.shape) # should be the same as batch_y in most of the cases, sometimes this should be postprocessed \n",
        "    # to match the shape of batch_y, HERE is the simplest case that the shape of pred_y is the same as batch_y\n",
        "    break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOTX8Jw1Ci2"
      },
      "source": [
        "### 目標函數（Objective Functions）\n",
        "\n",
        "使用 `torch.nn` 中事先定義好的目標函數進行模型最佳化，計算模型預測結果與標記訓練資料的誤差值，並透過向後傳播（Back Propagation）演算法取得相對於誤差值的梯度（Gradient）。\n",
        "- 基本上就是去計算每個參數的偏微分。\n",
        "- 和 gradient descent 是完全相同的概念，只是在神經網路中 neurons 數量龐大，因此需要有有效率的演算法去計算 gradient。這個演算法就是 back propagation。\n",
        "- 使用了 Chain Rule 的概念。計算每個參數內對 cost function 的偏微分。這個 cost function 就是「正確答案與預測答案的距離」，更適當的名字是 loss function。\n",
        "- 對一個 weight matrix $W \\in R^{a \\times b}$ 內，$W_{ij}$ 是 $l$層$i$ 神經元與 $l-1$ 層 $j$ 神經元之間的權重。\n",
        "    - ![](https://i.imgur.com/fk5HCm4.png)\n",
        "- 想更新這個權重值，就要計算 $\\frac{\\partial C}{\\partial W_{ij}}$，其中 $C$ 是 loss function。使用 Chain Rule，可以拆解成 $\\frac{\\partial C}{\\partial W_{ij}} =  \\frac{\\partial C}{\\partial Z_{i}} \\frac{\\partial Z_{i}}{\\partial W_{ij}}$，$Z_i$ 是 $i$ 所在的神經元的輸入值，$a^i$ 是 $i$ 神經元的輸出值。（下圖上標意義解釋：上標 $l$ 是你的層數（你現在更新的是哪一層的權重矩陣？實際上每一層都需要算），$r$ 是第$r$組資料）。所以這兩個 terms 分別要怎麼計算？請去看下面第一個影片 XD。\n",
        "    - ![](https://i.imgur.com/3EihDh7.png)\n",
        "- Resources (a lot of maths): \n",
        "    - [DNN Back propagation](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/index.html)\n",
        "    - [Computational Graph 的角度去看 Back propagation](https://www.youtube.com/watch?v=-yhm3WdGFok)\n",
        "\n",
        "```python\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn             \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()          \n",
        "\n",
        "# 計算 batch_x 得到 pred_y\n",
        "pred_y = my_model(batch_x)        \n",
        "# 計算 pred_y 與 batch_y 的均方誤差\n",
        "loss = criterion(pred_y, batch_y) \n",
        "\n",
        "# 使用向後傳播計算梯度\n",
        "loss.backward()                   \n",
        "```\n",
        "\n",
        "常見的目標函數包含：\n",
        "\n",
        "|目標函數|名稱|\n",
        "|-|-|\n",
        "|`torch.nn.MSELoss`|均方誤差（Mean Square Error）|\n",
        "|`torch.nn.CrossEntropyLoss`|交叉熵（Cross Entropy）|\n",
        "|`torch.nn.BCELoss`|二元交叉熵（Binary Cross Entropy）|\n",
        "|`torch.nn.NLLLoss`|負對數似然（Negative Log Likelihood）|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LdZoW-abr-N",
        "outputId": "cbd3f16c-31cd-4ced-f4c4-1772b491c74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(306.8647, grad_fn=<MseLossBackward0>)\n",
            "tensor(331.8914, grad_fn=<MseLossBackward0>)\n",
            "tensor(317.4485, grad_fn=<MseLossBackward0>)\n",
            "tensor(266.8327, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 目標函數\n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    print(loss)\n",
        "    \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()                     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igh-yFNr1K3o"
      },
      "source": [
        "### 最佳化（Optimization）\n",
        "\n",
        "![Gradient Descent](https://img-blog.csdnimg.cn/20181110102438617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpX2tfeQ==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "使用 `torch.optim` 中的不同的最佳化策略進行梯度下降（Gradient Descent）演算法：\n",
        "\n",
        "$$\n",
        "\\theta_t = \\theta_{t - 1} - \\text{lr} \\cdot \\nabla \\mathcal{L}(x)\n",
        "$$\n",
        "\n",
        "進行最佳化時需要注意以下事項：\n",
        "\n",
        "- 創造最佳化工具時必須指定哪些參數被更新\n",
        "    - 使用 `model.parameters()` 取得模型中所有可以被更新的參數\n",
        "    - 學習率（Learning Rate）負責決定模型參數更新的幅度，可以透過 `lr` 參數設定\n",
        "- 必須先計算誤差並且透過誤差向後傳播（`loss.backward()`），才能執行梯度下降更新參數（`optimizer.step()`）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "FqC3vN9gbr-N"
      },
      "outputs": [],
      "source": [
        "# 最佳化\n",
        "\n",
        "# 匯入計算梯度下降演算法的工具\n",
        "from torch.optim import SGD             \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    # 設定計算梯度下降的目標\n",
        "    my_model.parameters(),              \n",
        "    # 設定學習率\n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()\n",
        "    \n",
        "    # 使用梯度下降更新模型參數\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 清空計算過後的梯度值\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1tspVHbr-N",
        "outputId": "51d33a4c-331e-4c32-82bc-471739c4065b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, training loss: 291.65966644287107\n",
            "Epoch 0, testing loss: 288.98561096191406\n",
            "Epoch 1, training loss: 266.379898071289\n",
            "Epoch 1, testing loss: 263.9512466430664\n",
            "Epoch 2, training loss: 231.47439575195315\n",
            "Epoch 2, testing loss: 229.39228515625\n",
            "Epoch 3, training loss: 184.60029907226567\n",
            "Epoch 3, testing loss: 182.97408447265624\n",
            "Epoch 4, training loss: 128.77998580932618\n",
            "Epoch 4, testing loss: 127.6830238342285\n",
            "Epoch 5, training loss: 74.66538772583007\n",
            "Epoch 5, testing loss: 74.06685333251953\n",
            "Epoch 6, training loss: 34.83086090087891\n",
            "Epoch 6, testing loss: 34.58117599487305\n",
            "Epoch 7, training loss: 13.196218538284302\n",
            "Epoch 7, testing loss: 13.120167255401611\n",
            "Epoch 8, training loss: 4.273850345611572\n",
            "Epoch 8, testing loss: 4.258555746078491\n",
            "Epoch 9, training loss: 1.2783835649490356\n",
            "Epoch 9, testing loss: 1.277258837223053\n"
          ]
        }
      ],
      "source": [
        "# 驗證\n",
        "\n",
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# 創造訓練資料集\n",
        "train_dataset = MyDataset(1000)         \n",
        "# 創造測試資料集\n",
        "test_dataset = MyDataset(500)           \n",
        "\n",
        "# 設定超參數\n",
        "\n",
        "# 設定每次抽樣的數量\n",
        "batch_size = 50                         \n",
        "# 設定資料集總訓練次數\n",
        "n_epoch = 10                          \n",
        "# 設定隱藏層維度\n",
        "hid_dim = 100                            \n",
        "\n",
        "# 創造 DataLoader 實例\n",
        "train_data_loader = DataLoader(         \n",
        "    # 對資料集 train_dataset 進行抽樣\n",
        "    train_dataset,                      \n",
        "    # 設定每次抽樣的數量\n",
        "    batch_size=batch_size,              \n",
        "    # 設定隨機抽樣\n",
        "    shuffle=True,                       \n",
        "    # 指定格式化的方法\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "# 創造 DataLoader 實例\n",
        "test_data_loader = DataLoader(          \n",
        "    test_dataset,                       \n",
        "    batch_size=batch_size,              \n",
        "    shuffle=True,                       \n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# 創造 MyModel 模型實例\n",
        "model = MyModel(                        \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=hid_dim,                    \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "# 將模型搬移至 GPU\n",
        "model = model.to(device)                \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    model.parameters(),                 \n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 總共訓練 n_epoch 次\n",
        "for epoch in range(n_epoch):            \n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        # 將訓練資料搬移至 GPU\n",
        "        batch_x = batch_x.to(device)    \n",
        "        # 將訓練資料標記搬移至 GPU\n",
        "        batch_y = batch_y.to(device)    \n",
        "        \n",
        "        # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "        pred_y = model(batch_x)  # shape: (batch_size, 1)      \n",
        "        # 計算 pred_y (預測標記）與 batch_y （真實標記）的均方誤差\n",
        "        loss = criterion(pred_y, batch_y) \n",
        "        \n",
        "        # 使用向後傳播計算梯度\n",
        "        loss.backward()                 \n",
        "        # 使用梯度下降更新模型參數\n",
        "        optimizer.step()\n",
        "        # 清空計算過後的梯度值\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # 此區塊不會計算梯度\n",
        "    with torch.no_grad():               \n",
        "        # 統計訓練資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in train_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(train_data_loader)\n",
        "        \n",
        "        print('Epoch {}, training loss: {}'.format(epoch, total_loss))\n",
        "        \n",
        "        # 統計測試資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in test_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(test_data_loader)\n",
        "            \n",
        "        print('Epoch {}, testing loss: {}'.format(epoch, total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "JkmZGlVEbr-O",
        "outputId": "cdebfe36-079d-4e4f-a458-0b29bd72d253"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出訓練資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出訓練資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "        \n",
        "    plt.title('Training data performance')\n",
        "    plt.show()\n",
        "    \n",
        "    for batch_x, batch_y in test_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出測試資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出測試資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "    \n",
        "    plt.title('Testing data performance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMbkzFUU1S2K"
      },
      "source": [
        "### 測試\n",
        "\n",
        "深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 `with torch.no_grad():`：\n",
        "\n",
        "### 儲存 & 載入模型\n",
        "\n",
        "使用 `torch.save()` 配合 `model.state_dict()` 儲存訓練後的模型參數；\n",
        "使用 `model.load_state_dict()` 配合 `torch.load()` 載入儲存的訓練過的模型參數。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "Pnq25QSFbr-O"
      },
      "outputs": [],
      "source": [
        "# 儲存 & 載入模型\n",
        "\n",
        "# 儲存模型參數\n",
        "# torch.save(model.state_dict(), './data/model.ckpt')    \n",
        "# 載入模型參數\n",
        "# model.load_state_dict(torch.load('./data/model.ckpt')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VHNeeFnbr-O"
      },
      "source": [
        "## 練習\n",
        "\n",
        "### 練習 1：調整超參數\n",
        "\n",
        "請試著更改前述範例中的超參數讓模型表現變好：\n",
        "\n",
        "- 增加訓練次數 `n_epoch`\n",
        "- 增大單一訓練資料次數 `batch_size`\n",
        "- 增大隱藏層的維度 `hid_dim`\n",
        "- 更改啟動函數 `F.relu`\n",
        "\n",
        "### 練習 2：加深模型\n",
        "\n",
        "請試著更改前述範例中的模型深度讓模型表現變好：\n",
        "\n",
        "- 增加 1 個或多個 `nn.Linear`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 簡單的機器學習任務練習\n",
        "- MNIST 資料集：手寫數字圖像分類任務 (Image Classification)\n",
        "  - ![](https://thumbs.gfycat.com/AdorableJoyfulLemming-max-1mb.gif)\n",
        "  - MNIST 一筆 data $\\in \\mathbb{R}^{784}$ （784 維的 feature vector）\n",
        "  - [datahacker/cnn/#005 PyTorch - Convolutional Neural Network on MNIST Handwritten Digit Recognition in PyTorch 1.3.ipynb](https://github.com/maticvl/dataHacker/blob/master/CNN/%23005%20PyTorch%20-%20Convolutional%20Neural%20Network%20on%20MNIST%20Handwritten%20Digit%20Recognition%20in%20PyTorch%201.3.ipynb)\n",
        "- Kaggle Titanic Survival Prediction (Feature Classification)\n",
        "    - [Example Notebook: Introduction to Pytorch (a very gentle start)](https://www.kaggle.com/code/frtgnn/introduction-to-pytorch-a-very-gentle-start)\n",
        "- Real-and-Fake Text Classification (Text Classifcation)\n",
        "    - [A step-by-step guide: LSTM Text Classification Using Pytorch](https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0)\n",
        "- 分類問題是最簡單也是最核心的，所有任務（文字生成 text-generation，文字翻譯 translation，問答 QA，序列標注 sequence labeling 等等）全都是分類問題的變形而已，只是因為資料形式不同，這些任務的資料前處理與模型預測後處理會比分類問題更加複雜和不直覺。建議從最直觀的分類問題下手練習。\n",
        "- 例子都是提供 PyTorch 架構的範例。為什麼選擇 PyTorch 進行教學與開發？PyTorch 文檔詳細，community 活躍。Keras 較為簡單但相對的彈性低，對想要在模型內開發的人而言十分侷限（如果之後想要從事 ML 相關，使用 keras 者勢必需要轉換跑道）。Tensorflow 對初學者來說相對不友善。\n",
        "\n",
        "### （TA 個人使用過的）深度學習或自然語言處理學習資源\n",
        "  - 比較輕鬆入門深度學習的方式：\n",
        "    - [Hung-Yi Lee 's NTU ML Course Website](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)\n",
        "      - 如果想要更加熟悉，可以寫裡面的作業（大概寫 Regression, Classifcation, CNN, Self-attention, Transformer, BERT 就能夠 cover 這堂課需要的所有技能，比較有趣的作業可以寫看看 Explainable AI）。\n",
        "    - [Hung Yi Lee's Youtube Channel](https://www.youtube.com/@HungyiLeeNTU)\n",
        "  - 史丹佛的教科書/NTU 資訊所 NLP 課程用書：[Stanford Textbook: Speech & language Processing](https://web.stanford.edu/~jurafsky/slp3/) \n",
        "這本書寫很仔細，從 sequence models 和 word embeddings 開始講，後面的章節是分成多個不同 NLP 任務講解。想要知道一些 NLP 的基礎，詳讀以下章節應該可以收穫良多：\n",
        "    - 6:\tVector Semantics and Embeddings\t6: Vector Semantics\t[new in this edition]\n",
        "    - 7:\tNeural Networks and Neural Language Models\t7: Neural Networks [new in this edition]\n",
        "    - 9:\tRNNs and LSTMs\t\t[new in this edition]\n",
        "    - 10:\tTransformers and Pretrained Language Models\n",
        "  - Andrew Ng's Machine Learning Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "5d79344b50f250bbd6ad2de2adfaeedd1b2740d625477f4cf63f23f68cf7a998"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
