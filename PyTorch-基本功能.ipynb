{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohBsx6xbr-H"
      },
      "source": [
        "# PyTorch-åŸºæœ¬åŠŸèƒ½\n",
        "\n",
        "## æ•™å­¸ç›®æ¨™\n",
        "\n",
        "é€™ä»½æ•™å­¸çš„ç›®æ¨™æ˜¯ä»‹ç´¹ PyTorchï¼Œæ’°å¯«æ·±åº¦å­¸ç¿’æ¨¡å‹çš„å‡½å¼åº«ã€‚\n",
        "\n",
        "## é©ç”¨å°è±¡\n",
        "\n",
        "å·²ç¶“æœ‰åŸºæœ¬çš„æ©Ÿå™¨å­¸ç¿’çŸ¥è­˜ï¼Œä¸”æ“æœ‰ pythonã€`numpy`ã€`matplotlib` åŸºç¤çš„å­¸ç”Ÿã€‚\n",
        "\n",
        "è‹¥æ²’æœ‰å…ˆå­¸é pythonï¼Œè«‹åƒè€ƒ [python-å…¥é–€èªæ³•](./python-å…¥é–€èªæ³•.ipynb) æ•™å­¸ã€‚\n",
        "\n",
        "è‹¥æ²’æœ‰å…ˆå­¸é `numpy`ï¼Œè«‹åƒè€ƒ [numpy-åŸºæœ¬åŠŸèƒ½](./numpy-åŸºæœ¬åŠŸèƒ½.ipynb) æ•™å­¸ã€‚\n",
        "\n",
        "è‹¥æ²’æœ‰å…ˆå­¸é `matplotlib`ï¼Œè«‹åƒè€ƒ [matplotlib-è³‡æ–™è¦–è¦ºåŒ–](./matplotlib-è³‡æ–™è¦–è¦ºåŒ–.ipynb) æ•™å­¸ã€‚\n",
        "\n",
        "## åŸ·è¡Œæ™‚é–“\n",
        "\n",
        "æœ¬æ•™å­¸å…¨éƒ¨åŸ·è¡Œæ™‚é–“ç´„ç‚º 4.376506090164185 ç§’ã€‚\n",
        "\n",
        "|æ¸¬è©¦ç’°å¢ƒ|åç¨±|\n",
        "|-|-|\n",
        "|ä¸»æ©Ÿæ¿|X570 AORUS ELITE|\n",
        "|è™•ç†å™¨|AMD Ryzen 7 3700X 8-Core Processor|\n",
        "|è¨˜æ†¶é«”|Kingston KHX3200C16D4/16GX|\n",
        "|ç¡¬ç¢Ÿ|Seagate ST1000DM003-1ER1|\n",
        "|é¡¯ç¤ºå¡|GeForce RTX 3060|\n",
        "|ä½œæ¥­ç³»çµ±|Ubuntu 22.04 LTS|"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDTx3HZbr-I"
      },
      "source": [
        "## å¤§ç¶±\n",
        "\n",
        "- [ç°¡ä»‹](#ç°¡ä»‹)\n",
        "- [å®‰è£](#å®‰è£)\n",
        "- ğŸ“ [å¼µé‡å®£å‘Š](#å¼µé‡å®£å‘Š)\n",
        "- [å¼µé‡å–å€¼](#å¼µé‡å–å€¼)\n",
        "- [å¼µé‡é‹ç®—](#å¼µé‡é‹ç®—)\n",
        "- ğŸ“ [å‰µé€ å¼µé‡](#å‰µé€ å¼µé‡)\n",
        "- ğŸ“[é«˜ç¶­å¼µé‡é‹ç®—](#é«˜ç¶­å¼µé‡é‹ç®—)\n",
        "- ğŸ“[ç¶­åº¦é‹ç®—](#ç¶­åº¦é‹ç®—)\n",
        "- ğŸ“ğŸ“ [ä½¿ç”¨ GPU é‹ç®—](#ä½¿ç”¨-GPU-é‹ç®—)\n",
        "- ğŸ“ğŸ“ğŸ“ [æ·±åº¦å­¸ç¿’](#æ·±åº¦å­¸ç¿’)\n",
        "- [ç·´ç¿’](#ç·´ç¿’)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Hk28KHbr-I"
      },
      "source": [
        "## ç°¡ä»‹\n",
        "\n",
        "æ ¹æ“š [PyTorch å®˜æ–¹ç¶²ç«™](https://pytorch.org/)ï¼ˆç©©å®šç‰ˆ v2.0.1ï¼‰ï¼š\n",
        "\n",
        "> PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "> \n",
        "> PyTorch æ˜¯ä¸€å€‹é–‹æºçš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶ï¼Œèƒ½å¤ å¹«åŠ©åŠ é€Ÿå¾ç ”ç©¶åŸå‹åˆ°å•†æ¥­æ‡‰ç”¨çš„è½‰æ›éç¨‹ã€‚\n",
        "\n",
        "![PyTorch usage statistics](https://thegradient.pub/content/images/2019/10/ratio_medium-1.png)\n",
        "\n",
        "æ ¹æ“š[çµ±è¨ˆ](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)ï¼ŒPyTorch åœ¨å„å¤§æ©Ÿå™¨å­¸ç¿’æœƒè­°ä½¿ç”¨ç‡é€å¹´ä¸Šå‡ï¼Œä½¿ç”¨è€…é¸æ“‡ PyTorch çš„åŸå› ç‚ºï¼š\n",
        "\n",
        "- ç°¡å–®ï¼ˆSimplicityï¼‰\n",
        "    - ä½¿ç”¨ `python` ä½œç‚ºä»‹é¢\n",
        "    - æ“ä½œæ–¹æ³•èˆ‡ `numpy` ç›¸ä¼¼\n",
        "- å¥½ç”¨çš„ä»‹é¢ï¼ˆGreat APIï¼‰\n",
        "    - æ²’æœ‰éå¤šçš„æŠ½è±¡åŒ–\n",
        "- æ•ˆèƒ½ï¼ˆPerformanceï¼‰"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OwS9cuvXbr-I"
      },
      "source": [
        "## å®‰è£\n",
        "\n",
        "è«‹åƒè€ƒ [PyTorch å®˜æ–¹ç¶²ç«™](https://pytorch.org/get-started/locally/#start-locally)ï¼Œä¸¦é¸æ“‡é©åˆçš„ç’°å¢ƒé¸é …èˆ‡å®‰è£æ–¹æ³•ã€‚\n",
        "æœ‰ GPU çš„äººè«‹ç”¨ `nvidia-smi` æª¢æŸ¥ä¸€ä¸‹ cuda driver ç‰ˆæœ¬ï¼Œå› ç‚ºæœ€é‡è¦çš„æ˜¯è£å°ç¬¦åˆä½  cuda driver çš„ PyTorchï¼Œä½ æ‰èƒ½ç”¨ GPU åŠ é€Ÿã€‚\n",
        "\n",
        "æœ¬æ•™å­¸ä½¿ç”¨ `pip` å®‰è£ `torch`ï¼Œé¸é …å¦‚ä¸‹ã€‚\n",
        "|é¸é …|æè¿°|é¸æ“‡|\n",
        "|-|-|-|\n",
        "|PyTorch Build|è«‹é¸**ç©©å®šç‰ˆ**é¿å…æœªçŸ¥éŒ¯èª¤|`Stable(2.0.1)`|\n",
        "|Your OS|ä¾ç…§**ä½œæ¥­ç³»çµ±**ä¾†é¸æ“‡|`Linux`|\n",
        "|Package|å®‰è£ **PyTorch** ä½¿ç”¨çš„æ–¹æ³•|`Pip`|\n",
        "|Language|ç•¶å‰åŸ·è¡Œ **Python** ç‰ˆæœ¬|`Python 3.10.12`|\n",
        "|CUDA|é›»è…¦ä¸Šæ˜¯å¦æœ‰ **GPU** ä¸”æ”¯æ´ **CUDA æ¶æ§‹**|`11.7`|\n",
        "\n",
        "å¾—åˆ°ä»¥ä¸‹å®‰è£æŒ‡ä»¤ï¼š\n",
        "\n",
        "```sh\n",
        "pip3 install torch torchvision torchaudio\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8q-VOUcbr-J",
        "outputId": "4ec36342-b15b-44a4-9e43-056826034819"
      },
      "outputs": [],
      "source": [
        "# åŒ¯å…¥ PyTorch å¥—ä»¶\n",
        "# åœ¨ python ä¸­çš„ä»‹é¢åç¨±ç‚º torch\n",
        "import torch\n",
        "# åŒ¯å…¥ numpy èˆ‡ matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\n",
        "    # ç¢ºèª torch çš„ç‰ˆæœ¬\n",
        "    f'PyTorch version {torch.__version__}\\n' +\n",
        "    # ç¢ºèªæ˜¯å¦æœ‰ GPU è£ç½®\n",
        "    f'GPU-enabled installation? {torch.cuda.is_available()}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okJuKPxbr-J"
      },
      "source": [
        "## å¼µé‡å®£å‘Š\n",
        "\n",
        "åœ¨ `torch` ä¸­é™£åˆ—ç¨±ç‚ºå¼µé‡ï¼ˆTensorï¼‰ï¼Œå‰µé€ å¼µé‡çš„èªæ³•ç‚º `torch.tensor([value1, value2, ...])`ã€‚\n",
        "\n",
        "- æ¯å€‹ `torch.Tensor` éƒ½æœ‰ä¸åŒçš„**æ•¸å€¼å‹æ…‹å±¬æ€§** `torch.Tensor.dtype`\n",
        "    - å¿…é ˆé€é `torch.Tensor.dtype` å–å¾—ï¼Œç„¡æ³•é€é `type()` å–å¾—\n",
        "- å¯ä»¥æŒ‡å®šå‹æ…‹\n",
        "    - é€éåƒæ•¸ `dtype` æŒ‡å®šå‹æ…‹\n",
        "    - é€é `torch.LongTensor` å‰µé€ æ•´æ•¸ï¼Œé è¨­ç‚º `torch.int64`\n",
        "    - é€é `torch.FloatTensor` å‰µé€ æµ®é»æ•¸ï¼Œé è¨­ç‚º `torch.float32`\n",
        "\n",
        "|`torch` å‹æ…‹|`numpy` å‹æ…‹|C å‹æ…‹|ç¯„åœ|\n",
        "|-|-|-|-|\n",
        "|`torch.int8`|`numpy.int8`|`int_8`|-128~127|\n",
        "|`torch.int16`|`numpy.int16`|`int_16`|-32768~32767|\n",
        "|`torch.int32`|`numpy.int32`|`int_32`|-2147483648~2147483647|\n",
        "|`torch.int64`|`numpy.int64`|`int_64`|-9223372036854775808~9223372036854775807|\n",
        "|`torch.float32`|`numpy.float32`|`float`||\n",
        "|`torch.float64`|`numpy.float64`|`double`||\n",
        "\n",
        "- æ¯å€‹ `torch.Tensor` éƒ½æœ‰**ç¶­åº¦å±¬æ€§** `torch.Size`\n",
        "    - å‘¼å« `torch.Tensor.size()` ä¾†å–å¾—ç¶­åº¦å±¬æ€§\n",
        "    - `torch.Tensor.size` æœ¬è³ªæ˜¯ `tuple`\n",
        "    - å¼µé‡ç¶­åº¦æ„ˆé«˜ï¼Œ`len(torch.Tensor.size)` æ•¸å­—æ„ˆå¤§\n",
        "- å¯ä»¥ä½¿ç”¨ `torch.Tensor.reshape` æˆ– `torch.Tensor.view` é€²è¡Œç¶­åº¦è®Šæ›´\n",
        "    - è®Šæ›´å¾Œçš„ç¶­åº¦å¿…é ˆè¦èˆ‡è®Šæ›´å‰çš„ç¶­åº¦ä¹˜ç©ç›¸åŒ\n",
        "    - è®Šæ›´å¾Œçš„å…§å®¹ç‚º **shallow copy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KGb8WQKbr-J",
        "outputId": "a05f52cc-4cf6-4ce6-baa0-73ce6a7ce6c0"
      },
      "outputs": [],
      "source": [
        "# å¼µé‡å®£å‘Š\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t1 = torch.tensor([1, 2, 3])                           \n",
        "# è¼¸å‡º Tensor\n",
        "print(t1)                                              \n",
        "# è¼¸å‡º True\n",
        "print(type(t1) == torch.Tensor)                        \n",
        "# è¼¸å‡º torch.int64\n",
        "print(t1.dtype)                                        \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t2 = torch.tensor([1., 2., 3.])                        \n",
        "# è¼¸å‡º Tensor\n",
        "print(t2)                                              \n",
        "# è¼¸å‡º True\n",
        "print(type(t2) == torch.Tensor)                        \n",
        "# è¼¸å‡º torch.float32\n",
        "print(t2.dtype)                                        \n",
        "print()\n",
        "\n",
        "# å„ç¨® dtype\n",
        "# è¼¸å‡º torch.int8\n",
        "print(torch.tensor([1, 2], dtype=torch.int8).dtype)\n",
        "x = torch.tensor([1, 2], dtype=torch.int8)\n",
        "print(x)\n",
        "try:\n",
        "    x[0] = 128\n",
        "except Exception as e:\n",
        "    # int8 çš„ç¯„åœç‚º -128 ~ 127\n",
        "    # RuntimeError: value cannot be converted to type int8_t without overflow\n",
        "    print(e)\n",
        "print()\n",
        "\n",
        "# è¼¸å‡º torch.int16\n",
        "print(torch.tensor([1, 2], dtype=torch.int16).dtype)   \n",
        "# è¼¸å‡º torch.int32\n",
        "print(torch.tensor([1, 2], dtype=torch.int32).dtype)   \n",
        "# è¼¸å‡º torch.int64\n",
        "print(torch.tensor([1, 2], dtype=torch.int64).dtype)   \n",
        "# è¼¸å‡º torch.float32\n",
        "print(torch.tensor([1, 2], dtype=torch.float32).dtype) \n",
        "# è¼¸å‡º torch.float64\n",
        "print(torch.tensor([1, 2], dtype=torch.float64).dtype) \n",
        "print()\n",
        "\n",
        "# å®£å‘Š LongTensor è®Šæ•¸ -> é€šå¸¸ label æœƒä½¿ç”¨é€™ç¨®å‹æ…‹ï¼Œå› ç‚º label é€šå¸¸æ˜¯æ•´æ•¸ï¼Œåœ¨ torch è¨“ç·´çš„éŒ¯èª¤æ™‚å¯èƒ½æœƒçœ‹åˆ°é¡ä¼¼é€™ç¨®éŒ¯èª¤ï¼š\n",
        "# RuntimeError: Expected object of scalar type Long but got scalar type Float for argument #2 'target' \n",
        "# æ­¤æ™‚å°±è¦è¨˜å¾—æª¢æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨åˆ° LongTensor\n",
        "t3 = torch.LongTensor([1, 2, 3])                       \n",
        "# è¼¸å‡º torch.int64\n",
        "print(t3.dtype)                                        \n",
        "\n",
        "# å®£å‘Š FloatTensor è®Šæ•¸\n",
        "t4 = torch.FloatTensor([1, 2, 3])                      \n",
        "# è¼¸å‡º torch.float32\n",
        "print(t4.dtype)                                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg9RgMObbr-K",
        "outputId": "7ce67e53-f074-4cad-f00f-3958a192bef4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# size å±¬æ€§\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t5 = torch.tensor([               \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12],\n",
        "])\n",
        "\n",
        "# è¼¸å‡º Tensor\n",
        "print(t5)                         \n",
        "# è¼¸å‡º t5.size (4, 3)\n",
        "print(t5.size())                  \n",
        "print()\n",
        "\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.reshape(3, 4))           \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (3, 4)\n",
        "print(t5.reshape(3, 4).size())    \n",
        "print()\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.view(3, 4))              \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (3, 4)\n",
        "print(t5.view(3, 4).size())       \n",
        "print()\n",
        "\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.reshape(2, 6))           \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (2, 6)\n",
        "print(t5.reshape(2, 6).size())    \n",
        "print()\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.view(2, 6))              \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (2, 6)\n",
        "print(t5.view(2, 6).size())       \n",
        "print()\n",
        "\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.reshape(2, 3, 2))        \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (2, 3, 2)\n",
        "print(t5.reshape(2, 3, 2).size()) \n",
        "print()\n",
        "# é‡æ–°æ›´æ”¹ t5.size\n",
        "print(t5.view(2, 3, 2))           \n",
        "# è¼¸å‡ºæ›´æ”¹å¾Œçš„ç¶­åº¦ (2, 3, 2)\n",
        "print(t5.view(2, 3, 2).size())  \n",
        "# è‡ªå‹•è¨ˆç®—ç¬¬ä¸€å€‹ç¶­åº¦\n",
        "print(t5.view(-1, 3, 2).size())  \n",
        "print()\n",
        "\n",
        "# å° t5 é€²è¡Œè½‰ç½®\n",
        "print(t5.transpose(1, 0))\n",
        "# è¼¸å‡ºè½‰ç½®å¾Œçš„ç¶­åº¦ (3, 4) å…ƒç´ çš„é †åºæœƒæ”¹è®Š\n",
        "print(t5.transpose(1, 0).is_contiguous()) \n",
        "# reshape å¯ä»¥å°è½‰ç½®å¾Œçš„ Tensor é€²è¡Œæ“ä½œ\n",
        "print(t5.transpose(1, 0).reshape(6, 2))\n",
        "print()\n",
        "# view ä¸èƒ½å°è½‰ç½®å¾Œçš„ Tensor é€²è¡Œæ“ä½œ\n",
        "try:\n",
        "    print(t5.transpose(1, 0).view(6, 2))\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CaPUOTC7dhxd"
      },
      "source": [
        "## view å’Œ reshape \n",
        "- åƒè€ƒ[å®˜æ–¹ç¶²ç«™é€£çµ](https://pytorch.org/docs/stable/tensor_view.html)ï¼ŒPyTorch allows a tensor to be a View of an existing tensor. `View` tensor shares the same underlying data with its base tensor. Supporting View avoids explicit data copy, thus allows us to do fast and memory efficient reshaping, slicing and element-wise operations.\n",
        "\n",
        "- `torch.Tensor.view(*shape)-> Tensor`: \n",
        "Returns a **new tensor with the same data** as the self tensor but of a different shape. The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions $d,d+1,â€¦,d+k$ that satisfy the following contiguity-like condition that $\\forall i = d, ... d+k-1$\n",
        "$$\n",
        "stride[i] = stride[i+1] \\times size[i+1]\n",
        "$$\n",
        "\n",
        "- `*torch.Tensor.reshape(shape)->Tensor`: \n",
        "Returns a tensor with the same data and number of elements as self but with the specified shape. **This method returns a view if shape is compatible with the current shape. See `torch.Tensor.view()` on when it is possible to return a view.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy1L8FOqbr-K"
      },
      "source": [
        "## å¼µé‡å–å€¼\n",
        "\n",
        "èˆ‡ `numpy` èªæ³•æ¦‚å¿µç›¸ä¼¼ã€‚\n",
        "\n",
        "- ä½¿ç”¨ `torch.Tensor[ä½ç½®]` ä¾†å–å¾— `torch.Tensor` ä¸­æŒ‡å®šä½ç½®çš„å€¼\n",
        "    - è‹¥ç‚º**å¤šå€‹ç¶­åº¦**çš„å¼µé‡ï¼Œå‰‡ä½¿ç”¨ `tuple` ä¾†å–å¾—æŒ‡å®šä½ç½®çš„å€¼\n",
        "    - è‹¥ä½ç½®ç‚º**è² æ•¸**ï¼Œå‰‡ç­‰åŒæ–¼åå‘å–å¾—æŒ‡å®šä½ç½®çš„å€¼\n",
        "    - å–å‡ºçš„å€¼æœƒä»¥ `torch.Tensor.dtype` çš„å½¢å¼ä¿ç•™\n",
        "- ä½¿ç”¨ `torch.Tensor[èµ·å§‹ä½ç½®:çµæŸä½ç½®]` ä¾†å–å¾— `torch.Tensor` ä¸­çš„éƒ¨åˆ†**é€£çºŒ**å€¼\n",
        "    - **åŒ…å«èµ·å§‹ä½ç½®**çš„å€¼\n",
        "    - **ä¸åŒ…å«çµæŸä½ç½®**çš„å€¼\n",
        "    - å–å‡ºçš„å€¼æœƒä»¥ `torch.Tensor` çš„å½¢å¼ä¿ç•™\n",
        "- ä½¿ç”¨ `torch.Tensor[iterable]`ï¼ˆä¾‹å¦‚ `list`, `tuple` ç­‰ï¼‰ä¾†å–å¾—**å¤šå€‹** `torch.Tensor` ä¸­çš„å€¼\n",
        "    - å–å‡ºçš„å€¼æœƒä»¥ `torch.Tensor` çš„å½¢å¼ä¿ç•™\n",
        "- ä½¿ç”¨åˆ¤æ–·å¼ä¾†å–å¾— `torch.Tensor` ä¸­çš„éƒ¨ä»½è³‡æ–™\n",
        "    - ç¶“ç”±åˆ¤æ–·å¼æ‰€å¾—çµæœä¹Ÿç‚º `torch.Tensor`\n",
        "    - åˆ¤æ–·å¼æ‰€å¾—çµæœä¹‹ `torch.Tensor.dtype` ç‚º**å¸ƒæ—å€¼** `bool`ï¼ˆ`True` æˆ– `False`ï¼‰\n",
        "    - å–å‡ºçš„å€¼æœƒä»¥ `torch.Tensor` çš„å½¢å¼ä¿ç•™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214IwVJEbr-K",
        "outputId": "daaee408-eeb4-4836-92c5-31eb8a5ffa20"
      },
      "outputs": [],
      "source": [
        "# å¼µé‡å–å€¼\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t6 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ 0 å€‹ä½ç½®çš„å€¼ [0, 1, 2]\n",
        "print(t6[0])        \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ 1 å€‹ä½ç½®çš„å€¼ [3, 4, 5]\n",
        "print(t6[1])        \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ 1 å€‹ä½ç½®çš„å€¼ [6, 7, 8]\n",
        "print(t6[2])        \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ -2 å€‹ä½ç½®çš„å€¼ [6, 7, 8]\n",
        "print(t6[-2])       \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ -1 å€‹ä½ç½®çš„å€¼ [9, 10, 11]\n",
        "print(t6[-1])       \n",
        "print()\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [0, 0] å€‹ä½ç½®çš„å€¼ 0\n",
        "print(t6[0, 0])     \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [0, 1] å€‹ä½ç½®çš„å€¼ 1\n",
        "print(t6[0, 1])     \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [1, 1] å€‹ä½ç½®çš„å€¼ 4\n",
        "print(t6[1, 1])     \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [1, 2] å€‹ä½ç½®çš„å€¼ 5\n",
        "print(t6[1, 2])     \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [-1, -1] å€‹ä½ç½®çš„å€¼ 11\n",
        "print(t6[-1, -1])   \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [-1, -2] å€‹ä½ç½®çš„å€¼ 10\n",
        "print(t6[-1, -2])   \n",
        "# è¼¸å‡ºå¼µé‡ t6 ä¸­çš„ç¬¬ [-2, -1] å€‹ä½ç½®çš„å€¼ 8\n",
        "print(t6[-2, -1])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TTmmlRLbr-K",
        "outputId": "4e0a0eee-0766-44c6-badb-1432de18717d"
      },
      "outputs": [],
      "source": [
        "# å–é€£çºŒå€¼\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t7 = torch.tensor([ \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t7 ä½ç½® 0, 1, 2 ä½†æ˜¯ä¸å«ä½ç½® 3 çš„å€¼ [0, 10, 20]\n",
        "print(t7[0:3])      \n",
        "# è¼¸å‡ºå¼µé‡ t7 ä½ç½® 7, 8, 9 çš„å€¼ [70, 80, 90]\n",
        "print(t7[7:])       \n",
        "# è¼¸å‡ºå¼µé‡ t7 ä½ç½® 0, 1 ä½†æ˜¯ä¸å«ä½ç½® 2 çš„å€¼ [0, 10]\n",
        "print(t7[:2])       \n",
        "# è¼¸å‡ºå¼µé‡ t7 æ‰€æœ‰ä½ç½®çš„å€¼ [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "print(t7[:])        \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t8 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t8 ä½ç½® 0, 1, ä½†æ˜¯ä¸å«ä½ç½® 2 çš„å€¼ [[0, 1, 2], [3, 4, 5]]\n",
        "print(t8[0:2])      \n",
        "print()\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t8 ä½ç½® 1, 2, 3 çš„å€¼ [[3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[1:])       \n",
        "print()\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t8 ä½ç½® 0 ä½†æ˜¯ä¸å«ä½ç½® 1 çš„å€¼ [[0, 1, 2]]\n",
        "print(t8[:1])       \n",
        "print()\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t8 ä½ç½® 0 ä½†æ˜¯ä¸å«ä½ç½® 1 çš„å€¼ [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[:])        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5w2A_hbr-K",
        "outputId": "68f5efa5-01ab-4fd1-93b8-6eae16e59691"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ iterable å–å¾—å¤šå€‹å€¼\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t9 = torch.tensor([        \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t9 ä¸­å¶æ•¸ä½ç½®çš„å€¼ [0, 20, 40, 60, 80]\n",
        "print(t9[[0, 2, 4, 6, 8]]) \n",
        "print()\n",
        "# è¼¸å‡ºå¼µé‡ t9 ä¸­å¥‡æ•¸ä½ç½®çš„å€¼ [10, 30, 50, 70, 90]\n",
        "print(t9[[1, 3, 5, 7, 9]]) \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t10 = torch.tensor([       \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t10[0] èˆ‡ t10[1] çš„å€¼ [[1, 2, 3, 4] [5, 6, 7, 8]]\n",
        "print(t10[[0, 1]])         \n",
        "print()\n",
        "# è¼¸å‡ºå¼µé‡ t10[0, 2] èˆ‡ t10[1, 3] çš„å€¼ [3, 8]\n",
        "print(t10[[0, 1], [2, 3]]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBfUCkxbr-K",
        "outputId": "13257ce4-76d5-42cb-9b7f-7a45331e1c8d"
      },
      "outputs": [],
      "source": [
        "# åˆ¤æ–·å¼å–å€¼\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t11 = torch.tensor([      \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºæ¯å€‹å€¼æ˜¯å¦å¤§æ–¼ 50 çš„ `torch.Tensor`\n",
        "print(t11 > 50)           \n",
        "# è¼¸å‡º torch.bool\n",
        "print((t11 > 50).dtype)   \n",
        "# è¼¸å‡ºå¤§æ–¼ 50 çš„å€¼ [60, 70, 80, 90]\n",
        "print(t11[t11 > 50])      \n",
        "# è¼¸å‡ºé™¤ä»¥ 20 é¤˜æ•¸ç‚º 0 çš„å€¼ [0, 20, 40, 60, 80]\n",
        "print(t11[t11 % 20 == 0]) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x72LPvvtbr-K"
      },
      "source": [
        "## å¼µé‡é‹ç®—\n",
        "\n",
        "### ç´”é‡é‹ç®—ï¼ˆScalar Operationï¼‰\n",
        "\n",
        "å°å¼µé‡å…§æ‰€æœ‰æ•¸å€¼èˆ‡å–®ä¸€ç´”é‡ï¼ˆScalarï¼‰é€²è¡Œç›¸åŒè¨ˆç®—ã€‚\n",
        "\n",
        "|ç¬¦è™Ÿ|æ„ç¾©|\n",
        "|-|-|\n",
        "|`torch.Tensor + scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼åŠ ä¸Š `scalar`|\n",
        "|`torch.Tensor - scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼æ¸›å» `scalar`|\n",
        "|`torch.Tensor * scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ä¹˜ä¸Š `scalar`|\n",
        "|`torch.Tensor / scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥ `scalar`|\n",
        "|`torch.Tensor // scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥ `scalar` æ‰€å¾—ä¹‹å•†|\n",
        "|`torch.Tensor % scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥ `scalar` æ‰€å¾—ä¹‹é¤˜æ•¸|\n",
        "|`torch.Tensor ** scalar`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼å– `scalar` æ¬¡æ–¹|\n",
        "\n",
        "### å€‹åˆ¥æ•¸å€¼é‹ç®—ï¼ˆElement-wise Operationï¼‰\n",
        "\n",
        "è‹¥å…©å€‹å¼µé‡æƒ³è¦é€²è¡Œé‹ç®—ï¼Œå‰‡å…©å€‹å¼µé‡çš„**ç¶­åº¦å¿…é ˆç›¸åŒ**ï¼ˆå³å…©å¼µé‡ä¹‹ `torch.size()` ç›¸åŒï¼‰ã€‚\n",
        "\n",
        "|ç¬¦è™Ÿ|æ„ç¾©|\n",
        "|-|-|\n",
        "|`A + B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼åŠ ä¸Šå¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼|\n",
        "|`A - B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼æ¸›å»å¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼|\n",
        "|`A * B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼ä¹˜ä¸Šå¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼|\n",
        "|`A / B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥å¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼|\n",
        "|`A // B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥å¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼æ‰€å¾—ä¹‹å•†|\n",
        "|`A % B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼é™¤ä»¥å¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼æ‰€å¾—ä¹‹é¤˜æ•¸|\n",
        "|`A ** B`|å¼µé‡ `A` ä¸­çš„æ¯å€‹æ•¸å€¼å–å¼µé‡ `B` ä¸­ç›¸åŒä½ç½®çš„æ•¸å€¼ä¹‹æ¬¡æ–¹|\n",
        "\n",
        "### å€‹åˆ¥æ•¸å€¼å‡½æ•¸é‹ç®—ï¼ˆElement-wise Functional Operationï¼‰\n",
        "\n",
        "è‹¥æƒ³å°å¼µé‡ä¸­çš„**æ‰€æœ‰æ•¸å€¼**é€²è¡Œ**ç›¸åŒå‡½æ•¸é‹ç®—**ï¼Œå¿…é ˆé€é `torch` æä¾›çš„ä»‹é¢é€²è¡Œã€‚\n",
        "\n",
        "|å‡½æ•¸|æ„ç¾©|\n",
        "|-|-|\n",
        "|`torch.sin`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\sin(x)$|\n",
        "|`torch.cos`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\cos(x)$|\n",
        "|`torch.tan`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\tan(x)$|\n",
        "|`torch.exp`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $e^{x}$|\n",
        "|`torch.log`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\log x$\n",
        "|`torch.ceil`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\left\\lceil x \\right\\rceil$\n",
        "|`torch.floor`|å¼µé‡ä¸­çš„æ¯å€‹æ•¸å€¼ $x$ è¨ˆç®— $\\left\\lfloor x \\right\\rfloor$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR54kMUdbr-L",
        "outputId": "be0f0dd1-9f3c-46ea-f7b9-3b97415423e1"
      },
      "outputs": [],
      "source": [
        "# ç´”é‡é‹ç®—(Scalar Operation)\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t12 = torch.tensor([ \n",
        "    [0, 10, 20],\n",
        "    [30, 40, 50],\n",
        "    [60, 70, 80],\n",
        "    [90, 100, 110],\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t12\n",
        "print(t12)           \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼åŠ  5\n",
        "print(t12 + 5)       \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼æ¸› 4\n",
        "print(t12 - 4)       \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼ä¹˜ 3\n",
        "print(t12 * 3)       \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼é™¤ä»¥ 10\n",
        "print(t12 / 10)      \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼é™¤ä»¥ 10 æ‰€å¾—æ•´æ•¸éƒ¨ä»½\n",
        "print(t12 // 10)     \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼é™¤ä»¥ 7 å¾—åˆ°é¤˜æ•¸\n",
        "print(t12 % 7)       \n",
        "print()\n",
        "# å°å¼µé‡ t12 æ‰€æœ‰æ•¸å€¼å– 2 æ¬¡æ–¹\n",
        "print(t12 ** 2)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0xQnAE0br-L",
        "outputId": "15ee2e34-64e9-4f31-b6eb-145ce11aac74"
      },
      "outputs": [],
      "source": [
        "# å€‹åˆ¥æ•¸å€¼é‹ç®—\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t13 = torch.tensor([ \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t14 = torch.tensor([ \n",
        "    [6, 5, 4],\n",
        "    [3, 2, 1]\n",
        "])\n",
        "\n",
        "# å¼µé‡ç›¸åŠ \n",
        "print(t13 + t14)     \n",
        "print()\n",
        "# å¼µé‡ç›¸æ¸›\n",
        "print(t13 - t14)     \n",
        "print()\n",
        "# å¼µé‡ç›¸ä¹˜\n",
        "print(t13 * t14)     \n",
        "print()\n",
        "# å¼µé‡ç›¸é™¤\n",
        "print(t13 / t14)     \n",
        "print()\n",
        "# å¼µé‡ç›¸é™¤å–å•†\n",
        "print(t13 // t14)    \n",
        "print()\n",
        "# å¼µé‡ç›¸é™¤å–é¤˜æ•¸\n",
        "print(t13 % t14)     \n",
        "print()\n",
        "# å¼µé‡ A å–å¼µé‡ B æ¬¡æ–¹\n",
        "print(t13 ** t14)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GenMDYK4br-L",
        "outputId": "0c79e347-6861-4d68-af5d-12c23500b19d"
      },
      "outputs": [],
      "source": [
        "# å€‹åˆ¥æ•¸å€¼å‡½æ•¸é‹ç®—\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t15 = torch.tensor([               \n",
        "    [0,     np.pi / 4,     np.pi / 2,     np.pi / 4 * 3],\n",
        "    [np.pi, np.pi / 4 * 5, np.pi / 2 * 3, np.pi / 4 * 7]\n",
        "])\n",
        "\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼è¨ˆç®— sine\n",
        "print(torch.sin(t15))              \n",
        "print()\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼è¨ˆç®— cosine\n",
        "print(torch.cos(t15))              \n",
        "print()\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼è¨ˆç®— tangent\n",
        "print(torch.tan(t15))              \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t16 = torch.tensor([               \n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "])\n",
        "\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼å–æŒ‡æ•¸\n",
        "print(torch.exp(t16))              \n",
        "print()\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼å–å°æ•¸\n",
        "print(torch.log(t16))              \n",
        "print()\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼å–å°æ•¸å¾Œç„¡æ¢ä»¶é€²ä½\n",
        "print(torch.ceil(torch.log(t16)))  \n",
        "print()\n",
        "# å¼µé‡æ‰€æœ‰æ•¸å€¼å–å°æ•¸å¾Œç„¡æ¢ä»¶æ¨å»\n",
        "print(torch.floor(torch.log(t16))) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUbDIOiv4Uk"
      },
      "source": [
        "\n",
        "### ğŸš§ **å¼µé‡è‡ªå‹•æ“´å……ï¼ˆBroadcasting)**\n",
        "\n",
        "è‹¥å¼µé‡ `A` çš„ç¶­åº¦ç‚º `(a1, a2, ..., an)`ï¼ˆå³ `A.size() == (a1, a2, ..., an)`ï¼‰ï¼Œå‰‡å¼µé‡ `B` åœ¨æ»¿è¶³ä»¥ä¸‹å…¶ä¸­ä¸€ç¨®æ¢ä»¶æ™‚å³å¯èˆ‡å¼µé‡ `A` é€²è¡Œé‹ç®—ï¼š\n",
        "\n",
        "- å¼µé‡ `B` èˆ‡å¼µé‡ `A` ç¶­åº¦å®Œå…¨ç›¸åŒï¼ˆå³ `B.size() == (a1, a2, ..., an)`ï¼‰\n",
        "- å¼µé‡ `B` ç‚ºç´”é‡ï¼ˆå³ `B.size() == (1,)`ï¼‰\n",
        "- å¼µé‡ `B` çš„ç¶­åº¦ç‚º `(b1, b2, ..., bn)`ï¼Œè‹¥ `ai != bi`ï¼Œå‰‡ `ai == 1` æˆ– `bi == 1`\n",
        "    - å¾**æœ€å¾Œ**ä¸€å€‹ç¶­åº¦é–‹å§‹æ¯”è¼ƒ\n",
        "    - å¦‚æœæœ‰ä»»ä½•ä¸€å€‹ç¶­åº¦ç„¡æ³•æ»¿è¶³å‰è¿°éœ€æ±‚ï¼Œå‰‡æœƒå¾—åˆ° `ValueError`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¼µé‡è‡ªå‹•æ“´å……\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t17 = torch.tensor([ \n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "    ],\n",
        "    [\n",
        "        [7, 8],\n",
        "        [9 ,10],\n",
        "        [11, 12]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t18 = torch.tensor([ \n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]\n",
        "    ],\n",
        "    [\n",
        "        [2],\n",
        "        [2],\n",
        "        [2]\n",
        "    ],\n",
        "])\n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t17 ç¶­åº¦\n",
        "print(t17.size())    \n",
        "# è¼¸å‡ºå¼µé‡ t18 ç¶­åº¦\n",
        "print(t18.size())    \n",
        "print()\n",
        "# å¼µé‡ t17 èˆ‡å¼µé‡ t17 ç¶­åº¦ç›¸åŒï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥é‹ç®—\n",
        "print(t17 + t17)     \n",
        "print()\n",
        "# å¼µé‡ t17 èˆ‡å¼µé‡ t18 å¯ä»¥æ“´å……æˆç›¸åŒç¶­åº¦ï¼Œæ‰€ä»¥å¯ä»¥é‹ç®—\n",
        "print(t17 + t18) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ryiNnF9wDOr",
        "outputId": "49c0c912-b68d-4ac4-db99-6d22f6e7c9c5"
      },
      "outputs": [],
      "source": [
        "# å¼µé‡ t17 èˆ‡å¼µé‡ t18 å¯ä»¥æ“´å……æˆç›¸åŒç¶­åº¦ï¼Œæ‰€ä»¥å¯ä»¥é‹ç®—\n",
        "print(t17 + t18)  \n",
        "t18_like = torch.tensor([ \n",
        "    [\n",
        "        [1, 1],\n",
        "        [1, 1],\n",
        "        [1, 1]\n",
        "    ],\n",
        "    [\n",
        "        [2, 2],\n",
        "        [2, 2],\n",
        "        [2, 2]\n",
        "    ],\n",
        "])\n",
        "print()\n",
        "\n",
        "print(t18_like.size())\n",
        "print()\n",
        "\n",
        "# è¼¸å‡º Trueï¼Œå› ç‚º t18_like èˆ‡ t18 æ“´å……å¾Œç¶­åº¦ç›¸åŒ\n",
        "print(torch.equal(t18 + t17, t18_like + t17))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pdmIDslGbr-L"
      },
      "source": [
        "## å‰µé€ å¼µé‡\n",
        "\n",
        "### è³¦å€¼ï¼ˆAssignmentï¼‰\n",
        "\n",
        "ä½¿ç”¨ `=` è³¦èˆ‡æŒ‡å®šä½ç½®æ•¸å€¼ã€‚å¯ä»¥ä½¿ç”¨ `iterable` ä¸€æ¬¡æŒ‡å®šå¤šå€‹ä½ç½®ã€‚\n",
        "\n",
        "|ç¬¦è™Ÿ|æ„ç¾©|\n",
        "|-|-|\n",
        "|`=`|è³¦å€¼|\n",
        "|`+=`|é€²è¡ŒåŠ æ³•å¾Œè³¦å€¼|\n",
        "|`-=`|é€²è¡Œæ¸›æ³•å¾Œè³¦å€¼|\n",
        "|`*=`|é€²è¡Œä¹˜æ³•å¾Œè³¦å€¼|\n",
        "\n",
        "### éš¨æ©Ÿï¼ˆRandomï¼‰\n",
        "\n",
        "å‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼çš†ç‚º**éš¨æ©Ÿæ±ºå®š**ï¼Œå¿…é ˆ**äº‹å…ˆæŒ‡å®šå¼µé‡ç¶­åº¦**ã€‚\n",
        "\n",
        "|å‡½æ•¸|æ„ç¾©|ç”¨é€”|å‚™è¨»|\n",
        "|-|-|-|-|\n",
        "|`torch.empty`|å‰µé€ éš¨æ©Ÿæœªåˆå§‹åŒ–å¼µé‡|å·²ç¢ºèªç¶­åº¦ï¼Œå°šæœªç¢ºèªæ•¸å€¼|ç„¡æ³•æ§åˆ¶éš¨æ©Ÿ|\n",
        "|`torch.rand`|å‰µé€ éš¨æ©Ÿæµ®é»æ•¸å¼µé‡ï¼Œä¸¦ç¬¦åˆå‡å‹»åˆ†ä½ˆ|éœ€è¦éš¨æ©Ÿæµ®é»æ•¸æ™‚|é€éå‡å‹»åˆ†ä½ˆæ±ºå®šäº‚æ•¸ï¼Œç¯„åœä»‹æ–¼ 0 åˆ° 1ä¹‹é–“|\n",
        "|`torch.randn`|å‰µé€ éš¨æ©Ÿæµ®é»æ•¸å¼µé‡ï¼Œä¸¦ç¬¦åˆå¸¸æ…‹åˆ†ä½ˆ|éœ€è¦ç¬¦åˆå¸¸æ…‹åˆ†ä½ˆçš„éš¨æ©Ÿæµ®é»æ•¸æ™‚|é€éå¸¸æ…‹åˆ†ä½ˆæ±ºå®šäº‚æ•¸ï¼Œ$\\mu = 0$ ä¸” $\\sigma = 1$|\n",
        "|`torch.randint`|å‰µé€ éš¨æ©Ÿæ•´æ•¸å¼µé‡|éœ€è¦éš¨æ©Ÿæ•´æ•¸æ™‚|é€éå‡å‹»åˆ†ä½ˆæ±ºå®šäº‚æ•¸ï¼Œå¯ä»¥æ§åˆ¶éš¨æ©Ÿç¯„åœ|\n",
        "\n",
        "### æŒ‡å®šæ•¸å€¼ï¼ˆFilled Inï¼‰\n",
        "\n",
        "**å¿«é€Ÿå‰µé€ **æ“æœ‰ç‰¹å®šæ•¸å€¼çš„å¼µé‡ï¼Œå¿…é ˆ**äº‹å…ˆæŒ‡å®šå¼µé‡ç¶­åº¦**ã€‚\n",
        "\n",
        "|å‡½æ•¸|æ„ç¾©|ç”¨é€”|\n",
        "|-|-|-|\n",
        "|`torch.zeros`|å‰µé€ æŒ‡å®šç¶­åº¦å¤§å°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚º 0|å¿«é€Ÿåˆå§‹åŒ–|\n",
        "|`torch.zeros_like`|è¤‡è£½æŒ‡å®šå¼µé‡çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚º 0|è¤‡è£½å¼µé‡ä¸¦åˆå§‹åŒ–|\n",
        "|`torch.ones`|å‰µé€ æŒ‡å®šç¶­åº¦å¤§å°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚º 1|å¿«é€Ÿåˆå§‹åŒ–|\n",
        "|`torch.ones_like`|è¤‡è£½æŒ‡å®šå¼µé‡çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚º 1|è¤‡è£½å¼µé‡ä¸¦åˆå§‹åŒ–|\n",
        "|`torch.full`|å‰µé€ æŒ‡å®šç¶­åº¦å¤§å°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚ºæŒ‡å®šæ•¸å€¼|å¿«é€Ÿåˆå§‹åŒ–|\n",
        "|`torch.full_like`|è¤‡è£½æŒ‡å®šå¼µé‡çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œæ‰€æœ‰æ•¸å€¼åˆå§‹åŒ–ç‚ºæŒ‡å®šæ•¸å€¼|è¤‡è£½å¼µé‡ä¸¦åˆå§‹åŒ–|\n",
        "|`torch.eye`|å‰µé€ å–®ä½çŸ©é™£|çŸ©é™£å¾®åˆ†|\n",
        "|`torch.arange`|åˆ—èˆ‰æ•¸å­—|ç­‰åŒæ–¼ `list(range(value))`|\n",
        "\n",
        "### å¾ numpy è½‰æ›\n",
        "\n",
        "å¯ä»¥ä½¿ç”¨ `torch.tensor()` å°‡ `numpy.ndarray` è½‰æ›æˆ `torch.Tensor`ï¼›\n",
        "ä½¿ç”¨ `torch.numpy()` å°‡ `torch.Tensor` è½‰æ›æˆ `numpy.ndarray`ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvxSd3X1br-L",
        "outputId": "99dc0132-e0ca-4054-8228-691b67b01261"
      },
      "outputs": [],
      "source": [
        "# è³¦å€¼\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t19 = torch.tensor([     \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t19 ä½ç½® 0 çš„æ‰€æœ‰æ•¸å€¼æ”¹æˆ 1995\n",
        "t19[0] = 1995            \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t19 ä½ç½® [0, 1] çš„æ‰€æœ‰æ•¸å€¼æ”¹æˆ 10\n",
        "t19[0, 1] = 10           \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t19 ä½ç½® [2, 1] èˆ‡ [0, 2] çš„æ‰€æœ‰æ•¸å€¼æ”¹æˆ 12\n",
        "t19[[2, 0], [1, 2]] = 12 \n",
        "print(t19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LzdLlgbr-L",
        "outputId": "86617d59-d3f7-4d96-a078-62240a2313da"
      },
      "outputs": [],
      "source": [
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t20 = torch.tensor([      \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t20 ä½ç½® 0 çš„æ‰€æœ‰æ•¸å€¼åŠ ä¸Š 1995\n",
        "t20[0] += 1995            \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t20 ä½ç½® [0, 1] çš„æ‰€æœ‰æ•¸å€¼æ¸›æ‰ 10\n",
        "t20[0, 1] -= 10           \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# å°‡å¼µé‡ t20 ä½ç½® [2, 1] èˆ‡ [0, 2] çš„æ‰€æœ‰æ•¸å€¼ä¹˜ä¸Š 12\n",
        "t20[[2, 0], [1, 2]] *= 12\n",
        "print(t20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2p5aidybr-L",
        "outputId": "8c79bb15-c76b-44b0-f85d-ac06766fa457"
      },
      "outputs": [],
      "source": [
        "# éš¨æ©Ÿ\n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œæ•¸å€¼ç‚ºç„¡æ³•æ§åˆ¶ç¯„åœçš„æµ®é»\n",
        "print(torch.empty((2, 3)))               \n",
        "print()                                  \n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œæ•¸å€¼ç‚ºä»‹æ–¼ 0 åˆ° 1 ä¹‹é–“çš„æµ®é»\n",
        "print(torch.rand(2, 3))                  \n",
        "print()                                  \n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œæ•¸å€¼ç‚ºä»‹æ–¼ 0 åˆ° 10 ä¹‹é–“çš„æµ®é»\n",
        "print(torch.rand(2, 3) * 10)             \n",
        "print()                                  \n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œæ•¸å€¼ç‚ºä»‹æ–¼ -5 åˆ° 5 ä¹‹é–“çš„æµ®é»æ•¸\n",
        "print(torch.rand(2, 3) * 10 - 5)         \n",
        "print()                                  \n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œåˆ†ä½ˆç‚ºå¹³å‡å€¼ç‚º 0 æ¨™æº–å·®ç‚º 1 çš„å¸¸æ…‹åˆ†ä½ˆ\n",
        "print(torch.randn(2, 3))                 \n",
        "print()                                  \n",
        "\n",
        "# éš¨æ©Ÿå‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œæ•¸å€¼ç‚ºä»‹æ–¼ -5 åˆ° 5 ä¹‹é–“çš„æµ®é»æ•¸\n",
        "print(torch.randint(-5, 5, size=(2, 3))) \n",
        "                                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmziKBTmbr-L",
        "outputId": "e573b226-6f80-4367-e988-6473282df5f4"
      },
      "outputs": [],
      "source": [
        "# æŒ‡å®šæ•¸å€¼\n",
        "# å‰µé€ ç¶­åº¦ç‚º (2, 3) çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 0\n",
        "print(torch.zeros((2, 3)))      \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t21 = torch.tensor([            \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "# è¤‡è£½å¼µé‡ t21 çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 0\n",
        "print(torch.zeros_like(t21))    \n",
        "print()\n",
        "\n",
        "# å‰µé€ ç¶­åº¦ç‚º (3, 4) çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 1\n",
        "print(torch.ones((3, 4)))       \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t22 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "# è¤‡è£½å¼µé‡ t22 çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 1\n",
        "# like çš„æ¦‚å¿µå°±æ˜¯ã€Œæ¨¡ä»¿æˆ‘ä¸Ÿçµ¦ä½ çš„é€™å€‹ tensor çš„ç¶­åº¦ã€\n",
        "print(torch.ones_like(t22))     \n",
        "print()\n",
        "\n",
        "# å‰µé€ ç¶­åº¦ç‚º (5, 6) çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 420\n",
        "print(torch.full((5, 6), 420))  \n",
        "print()\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t23 = torch.tensor([            \n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "    [7, 8, 9, 10, 11, 12],\n",
        "    [13, 14, 15, 16, 17, 18],\n",
        "    [19, 20, 21, 22, 23, 24],\n",
        "    [25, 26, 27, 28, 29, 30]\n",
        "])\n",
        "# è¤‡è£½å¼µé‡ t23 çš„ç¶­åº¦ï¼Œå‰µé€ å‡ºæ–°çš„å¼µé‡ï¼Œä¸¦åˆå§‹åŒ–ç‚º 69\n",
        "print(torch.full_like(t23, 69)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJgdH-vabr-L",
        "outputId": "ffab6382-383b-4dde-cddb-b4cd1e29b8c6"
      },
      "outputs": [],
      "source": [
        "# å‰µé€  3x3 å–®ä½çŸ©é™£\n",
        "print(torch.eye(3))           \n",
        "print()\n",
        "\n",
        "# å¾ 0 åˆ—èˆ‰è‡³ 10ï¼Œä½†ä¸åŒ…å« 10\n",
        "print(torch.arange(10))       \n",
        "print()\n",
        "\n",
        "# å¾ 6 åˆ—èˆ‰è‡³ 9ï¼Œä½†ä¸åŒ…å« 9\n",
        "print(torch.arange(6, 9))     \n",
        "print()\n",
        "\n",
        "# å¾ 4 éå¢è‡³ 20ï¼Œä½†ä¸åŒ…å« 20ï¼Œæ¯æ¬¡éå¢ 7\n",
        "print(torch.arange(4, 20, 7)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkT3EX7br-L",
        "outputId": "16ae7f16-37a4-46b8-d714-99fa73b6999d"
      },
      "outputs": [],
      "source": [
        "# å¾ numpy è½‰æ›\n",
        "\n",
        "# å®£å‘Š ndarray è®Šæ•¸\n",
        "arr1 = np.array([1., 2., 3.]) \n",
        "# å°‡ numpy.ndarray è½‰æ›ç‚º torch.Tensor\n",
        "t24 = torch.tensor(arr1)      \n",
        "# å°‡ torch.Tensor è½‰æ›ç‚º numpy.ndarray\n",
        "arr2 = t24.numpy()            \n",
        "\n",
        "print((\n",
        "    f'original numpy.ndarray: {arr1}, dtype: {arr1.dtype}\\n' + \n",
        "    f'converted torch.Tensor: {t24}, dtype: {t24.dtype}\\n' +\n",
        "    f'converted numpy.ndarray: {arr2}, dtype: {arr2.dtype}'\n",
        "))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "STyE59Zgbr-M"
      },
      "source": [
        "## é«˜ç¶­å¼µé‡é‹ç®—\n",
        "\n",
        "çŸ©é™£ç­‰åŒæ–¼æ˜¯ç¶­åº¦ç‚º 2 çš„å¼µé‡ã€‚\n",
        "è€Œé«˜ç¶­åº¦çš„å¼µé‡é‹ç®—ç­‰åŒæ–¼**å›ºå®šå¤§éƒ¨åˆ†çš„ç¶­åº¦**ï¼Œåªä½¿ç”¨**å…¶ä¸­çš„å…©å€‹ç¶­åº¦é€²è¡Œè¨ˆç®—**ã€‚\n",
        "\n",
        "### å¼µé‡ä¹˜æ³•ï¼ˆTensor Multiplicationï¼‰\n",
        "\n",
        "ä»¤ $A$ èˆ‡ $B$ ç‚ºå…©å¼µé‡ï¼Œ$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$, $B.\\text{size}() = (b_1, b_2, ..., b_{n - 1}, b_n)$ã€‚å®šç¾© $A \\times B$ å¦‚ä¸‹ï¼š\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "a_i &= b_i \\forall i \\in \\{1, \\dots, n - 2\\} \\\\\n",
        "a_n &= b_{n - 1} \\\\\n",
        "(A \\times B).\\text{size}() &= (d_1, d_2, \\dots, d_{n - 2}, a_{n - 1}, b_n) \\\\\n",
        "&, \\text{where } d_i = a_i = b_i \\forall i \\in \\{1, 2, \\dots, n - 2\\} \\\\\n",
        "(A \\times B)_{d_1, d_2, \\dots, d_{n - 2}, i, j} &=\n",
        "\\begin{cases}\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{i, k} \\times B_{k, j} & \\text{if } n = 2 \\\\\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{d_1, d_2, \\dots, d_{n - 2}, i, k} \\times B_{d_1, d_2, \\dots, d_{n - 2}, k, j} & \\text{if } n > 2\n",
        "\\end{cases} \\\\\n",
        "&, \\forall i \\in \\{1, \\dots, a_1\\}, j \\in \\{1, \\dots, b_2\\}\n",
        "\\end{align*}\n",
        "$$\n",
        "ä¾‹å¦‚ï¼šä»¥ $A.\\text{size}() = (4, 3)$ èˆ‡ $B.\\text{size}() = (3, 2)$ ä¾†èªªï¼Œ$(A \\times B).\\text{size}() = (4, 2)$ã€‚\n",
        "\n",
        "ä¾‹å¦‚ï¼šä»¥ $A.\\text{size}() = (5, 4, 3)$ èˆ‡ $B.\\text{size}() = (5, 3, 2)$ ä¾†èªªï¼Œ$(A \\times B).\\text{size}() = (5, 4, 2)$ã€‚\n",
        "\n",
        "ä¾‹å¦‚ï¼šä»¥ $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ èˆ‡ $B.\\text{size}() = (1995, 10, 12, 5, 3, 2)$ ä¾†èªªï¼Œ$(A \\times B).\\text{size}() = (1995, 10, 12, 5, 4, 2)$ã€‚\n",
        "\n",
        "åœ¨ `torch` ä¸­å¼µé‡ä¹˜æ³•ç‚º `torch.matmul(A, B)`ã€‚\n",
        "\n",
        "### å¼µé‡è½‰ç½®ï¼ˆTensor Transposeï¼‰\n",
        "\n",
        "ä»¤ $A$ å…©å¼µé‡ï¼Œ$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$ã€‚å®šç¾© $A^{\\top}$ å¦‚ä¸‹ï¼š\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top} &= (A_{a_1, a_2, \\dots, a_{n - 2}, a_{n - 1}, a_n})^{\\top} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_{n - 2}, a_n, a_{n - 1}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "å³äº¤æ›å¼µé‡ $A$ çš„æœ€å¾Œå…©å€‹ç¶­åº¦ã€‚è‹¥æƒ³è¦æŒ‡å®šä¸åŒçš„ç¶­åº¦ $i, j$ é€²è¡Œè½‰ç½®ï¼Œå‰‡å®šç¾© $A^{\\top_{i, j}}$ å¦‚ä¸‹ï¼š\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top_{i, j}} &= (A_{a_1, a_2, \\dots, a_i, \\dots, a_j, \\dots, a_n})^{\\top_i, j} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_j, \\dots, a_i, \\dots, a_n}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "ä¾‹å¦‚ï¼šä»¥ $A.\\text{size}() = (5, 4, 3)$ ä¾†èªªï¼Œ$A^{\\top_{1, 2}}.\\text{size}() = (5, 3, 4)$ã€‚\n",
        "\n",
        "ä¾‹å¦‚ï¼šä»¥ $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ ä¾†èªªï¼Œ$A^{\\top_{3, 4}}.\\text{size}() = (1995, 10, 12, 4, 5, 3)$ã€‚\n",
        "\n",
        "åœ¨ `torch` ä¸­å¼µé‡è½‰ç½®ç‚º `torch.transpose(A, i, j)`ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ntJ0Jzbr-M",
        "outputId": "5faaf6fb-06c5-4cce-e0b8-49bc569ab0f8"
      },
      "outputs": [],
      "source": [
        "# å¼µé‡ä¹˜æ³•\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t25 = torch.ones(5, 4, 3)    \n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t26 = torch.ones(5, 3, 2)    \n",
        "# é€²è¡Œå¼µé‡ä¹˜æ³•\n",
        "t27 = torch.matmul(t25, t26) \n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t25 çš„ç¶­åº¦\n",
        "print(t25.size())            \n",
        "# è¼¸å‡ºå¼µé‡ t26 çš„ç¶­åº¦\n",
        "print(t26.size())            \n",
        "# è¼¸å‡ºå¼µé‡ t27 çš„ç¶­åº¦\n",
        "print(t27.size())            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iELV2wlbbr-M",
        "outputId": "c9c89622-150c-4b50-9273-c7ddd4265988"
      },
      "outputs": [],
      "source": [
        "# å¼µé‡è½‰ç½®\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t28 = torch.ones(5, 4, 3)                \n",
        "\n",
        "# è¼¸å‡ºè½‰ç½®ç¶­åº¦ 1 èˆ‡ 2 å¾Œçš„ç¶­åº¦\n",
        "print(torch.transpose(t28, 1, 2).size()) \n",
        "# è¼¸å‡ºè½‰ç½®ç¶­åº¦ 1 èˆ‡ 2 å¾Œçš„ç¶­åº¦\n",
        "print(t28.transpose(1, 2).size())        \n",
        "\n",
        "# è¼¸å‡ºè½‰ç½®ç¶­åº¦ 0 èˆ‡ 2 å¾Œçš„ç¶­åº¦\n",
        "print(torch.transpose(t28, 0, 2).size()) \n",
        "# è¼¸å‡ºè½‰ç½®ç¶­åº¦ 0 èˆ‡ 2 å¾Œçš„ç¶­åº¦\n",
        "print(t28.transpose(0, 2).size())        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uwt4npXsbr-M"
      },
      "source": [
        "## ç¶­åº¦é‹ç®—\n",
        "\n",
        "### é™ç¶­å‡½æ•¸ï¼ˆDimension Decreasing Functionï¼‰\n",
        "\n",
        "ä»¥ä¸‹å‡½æ•¸å°‡æœƒä½¿**è¼¸å‡º**å¼µé‡ç¶­åº¦**å°æ–¼è¼¸å…¥**å¼µé‡ç¶­åº¦ã€‚\n",
        "åœ¨æ©Ÿå™¨å­¸ç¿’ä¸­ä½ å¹¾ä¹å¿…å®šæœƒç”¨åˆ° `torch.argmax()`ã€‚\n",
        "\n",
        "|å‡½æ•¸|æ„ç¾©|\n",
        "|-|-|\n",
        "|`torch.sum`|å°‡æ‰€æœ‰æ•¸å€¼ç›¸åŠ |\n",
        "|`torch.max`|å–å‡ºæ‰€æœ‰æ•¸å€¼ä¸­æœ€å¤§è€…|\n",
        "|`torch.min`|å–å‡ºæ‰€æœ‰æ•¸å€¼ä¸­æœ€å°è€…|\n",
        "|`torch.argmax`|å–å‡ºæ‰€æœ‰æ•¸å€¼ä¸­æœ€å¤§è€…çš„ä½ç½®|\n",
        "|`torch.argmin`|å–å‡ºæ‰€æœ‰æ•¸å€¼ä¸­æœ€å°è€…çš„ä½ç½®|\n",
        "|`torch.mean`|å–å‡ºæ‰€æœ‰æ•¸å€¼çš„å¹³å‡å€¼|\n",
        "|`torch.var`|å–å‡ºæ‰€æœ‰æ•¸å€¼çš„è®Šç•°æ•¸|\n",
        "|`torch.std`|å–å‡ºæ‰€æœ‰æ•¸å€¼çš„æ¨™æº–å·®|\n",
        "|`torch.squeeze`|ç§»é™¤æ•¸å­—ç‚º 1 çš„ç¶­åº¦|\n",
        "\n",
        "### å¢ç¶­å‡½æ•¸ï¼ˆDimension Increasing Functionï¼‰\n",
        "\n",
        "ä»¥ä¸‹å‡½æ•¸å°‡æœƒä½¿**è¼¸å‡º**å¼µé‡ç¶­åº¦**å¤§æ–¼è¼¸å…¥**å¼µé‡ç¶­åº¦ã€‚\n",
        "\n",
        "|å‡½æ•¸|æ„ç¾©|\n",
        "|-|-|\n",
        "|`torch.cat`|ä¸²æ¥å¤šå€‹ç›¸åŒç¶­åº¦çš„å¼µé‡|\n",
        "|`torch.unsqueeze`|åœ¨æŒ‡å®šçš„ç¶­åº¦é–“å¢åŠ  1 ç¶­åº¦|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuN13HnNbr-M",
        "outputId": "c9c9fa52-3349-4cf1-f40e-a77be5b2befa"
      },
      "outputs": [],
      "source": [
        "# é™ç¶­å‡½æ•¸\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t29 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# å°‡å¼µé‡ t29 ä¸­æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(torch.sum(t29))           \n",
        "# å°‡å¼µé‡ t29 ä¸­æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(t29.sum())                \n",
        "\n",
        "# å°‡å¼µé‡ t29 ä¸­ä¾ç…§ç¶­åº¦ 0 å°‡æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(torch.sum(t29, dim=0))    \n",
        "# å°‡å¼µé‡ t29 ä¸­ä¾ç…§ç¶­åº¦ 0 å°‡æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(t29.sum(dim=0))           \n",
        "# å°‡å¼µé‡ t29 ä¸­ä¾ç…§ç¶­åº¦ 1 å°‡æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(torch.sum(t29, dim=1))    \n",
        "# å°‡å¼µé‡ t29 ä¸­ä¾ç…§ç¶­åº¦ 1 å°‡æ‰€æœ‰å€¼ç›¸åŠ \n",
        "print(t29.sum(dim=1))           \n",
        "\n",
        "# æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼\n",
        "print(torch.max(t29))          \n",
        "# æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼\n",
        "print(t29.max())                \n",
        "print()\n",
        "\n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼ï¼Œä¸¦å›å‚³æœ€å¤§å€¼èˆ‡å°æ‡‰ä½ç½®\n",
        "print(torch.max(t29, dim=0))    \n",
        "print()                         \n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼ï¼Œä¸¦å›å‚³æœ€å¤§å€¼èˆ‡å°æ‡‰ä½ç½®\n",
        "print(t29.max(dim=0))           \n",
        "print()                         \n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼\n",
        "print(torch.max(t29, dim=0)[0]) \n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å¤§å€¼ä½ç½®\n",
        "print(torch.max(t29, dim=0)[1]) \n",
        "print()\n",
        "\n",
        "# æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼\n",
        "print(torch.min(t29))           \n",
        "# æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼\n",
        "print(t29.min())                \n",
        "print()\n",
        "\n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼ï¼Œä¸¦å›å‚³æœ€å°å€¼èˆ‡å°æ‡‰ä½ç½®\n",
        "print(torch.min(t29, dim=1))    \n",
        "print()                         \n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼ï¼Œä¸¦å›å‚³æœ€å°å€¼èˆ‡å°æ‡‰ä½ç½®\n",
        "print(t29.min(dim=1))           \n",
        "print()                         \n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼\n",
        "print(torch.min(t29, dim=1)[0]) \n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t29 ä¸­æœ€å°å€¼ä½ç½®\n",
        "print(torch.min(t29, dim=1)[1]) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.argmax(input, dim, keepdim=False) â†’ LongTensor`\n",
        "[PyTorch Official Documentation](https://pytorch.org/docs/stable/generated/torch.argmax.html)\n",
        "- Parameters:\n",
        "    - input (Tensor) â€“ the input tensor.\n",
        "    - dim (int) â€“ the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
        "    - keepdim (bool) â€“ whether the output tensor has dim retained or not. Ignored if dim=None."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWn28FWbr-M",
        "outputId": "00eb6da5-fc1d-4366-92a9-955a6a11ac4f"
      },
      "outputs": [],
      "source": [
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t30 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "print('shape:', t30.shape)\n",
        "print('=== argmax ===')\n",
        "# æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®\n",
        "print('- flattened argmax:')\n",
        "print(torch.argmax(t30))        \n",
        "# æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®\n",
        "# dim (int) â€“ the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
        "print(t30.argmax())             \n",
        "print(\"- reduced along dim 0:\")\n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®ï¼Œ\n",
        "# ç¶­åº¦ 0: dimension TO REDUCEï¼Œä»£è¡¨æ²¿è‘—ç¶­åº¦ 0 æœƒè¢«æ”¤å¹³ï¼Œshape (3,4) çš„ tensor æœƒè®Šæˆ shape (4,) çš„ tensor\n",
        "# æ²¿è‘— [1,5,9], [2, 6, 10], ... æ‰¾æœ€å¤§å€¼çš„ indexã€‚\n",
        "print(torch.argmax(t30, dim=0)) \n",
        "# ä¾ç…§ç¶­åº¦ 0 æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®\n",
        "print(t30.argmax(dim=0))        \n",
        "\n",
        "print(\"- reduced along dim 1:\")\n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®\n",
        "print(torch.argmax(t30, dim=1)) \n",
        "# ä¾ç…§ç¶­åº¦ 1 æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å¤§å€¼çš„ä½ç½®\n",
        "print(t30.argmax(dim=1))        \n",
        "\n",
        "print('=== argmin ===')\n",
        "# æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å°å€¼çš„ä½ç½®\n",
        "print(torch.argmin(t30))        \n",
        "# æ‰¾å‡ºå¼µé‡ t30 ä¸­æœ€å°å€¼çš„ä½ç½®\n",
        "print(t30.argmin())                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJwYUYHgbr-M",
        "outputId": "1cb7e250-de49-49f5-bf82-7c5a950c23b5"
      },
      "outputs": [],
      "source": [
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t31 = torch.tensor([            \n",
        "    [1., 2., 3., 4.],\n",
        "    [5., 6., 7., 8.],\n",
        "    [9., 10., 11., 12.]\n",
        "])\n",
        "\n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(torch.mean(t31))         \n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(t31.mean())              \n",
        "\n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(torch.mean(t31, axis=0)) \n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(t31.mean(axis=0))        \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(torch.mean(t31, axis=1)) \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„å¹³å‡æ•¸\n",
        "print(t31.mean(axis=1))        \n",
        "\n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(torch.var(t31))          \n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(t31.var())               \n",
        "\n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(torch.var(t31, axis=0))  \n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(t31.var(axis=0))         \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(torch.var(t31, axis=1))  \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„è®Šç•°æ•¸\n",
        "print(t31.var(axis=1))         \n",
        "\n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(torch.std(t31))          \n",
        "# è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(t31.std())               \n",
        "\n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(torch.std(t31, axis=0))  \n",
        "# ä¾ç…§ç¶­åº¦ 0 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(t31.std(axis=0))         \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(torch.std(t31, axis=1))  \n",
        "# ä¾ç…§ç¶­åº¦ 1 è¨ˆç®—å¼µé‡ t31 ä¸­æ‰€æœ‰å€¼çš„æ¨™æº–å·®\n",
        "print(t31.std(axis=1))         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfXHwo9-br-M",
        "outputId": "bfaa7ffd-e9da-4a36-96f6-ffd3acfdfdac"
      },
      "outputs": [],
      "source": [
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t32 = torch.tensor([        \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# ç§»é™¤å¼µé‡ t32 ä¸­å¤šé¤˜çš„ç¶­åº¦(ç‚º 1 çš„ç¶­åº¦)\n",
        "t32_sq = torch.squeeze(t32) \n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t32\n",
        "print(t32)                  \n",
        "# è¼¸å‡ºå¼µé‡ t32 çš„ç¶­åº¦\n",
        "print('- before squeezing:', t32.size())           \n",
        "# è¼¸å‡ºç§»é™¤ç¶­åº¦å¾Œçš„å¼µé‡ t32\n",
        "print(t32_sq)               \n",
        "# è¼¸å‡ºç§»é™¤ç¶­åº¦å¾Œå¼µé‡ t32 çš„ç¶­åº¦\n",
        "print('- after squeezing:',t32_sq.size())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROt_wvYWbr-M",
        "outputId": "4a354c6d-1ba0-40b2-e3de-a27452320b0e"
      },
      "outputs": [],
      "source": [
        "# å¢ç¶­å‡½æ•¸\n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t33 = torch.tensor([                  \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# ä¸²æ¥å¤šå€‹å¼µé‡ t33\n",
        "t33_cat = torch.cat([                 \n",
        "    t33,\n",
        "    t33,\n",
        "    t33,\n",
        "    t33\n",
        "]) \n",
        "\n",
        "# è¼¸å‡ºä¸²æ¥å¾Œçš„å¼µé‡ t33_cat\n",
        "print(t33_cat)                        \n",
        "# è¼¸å‡ºä¸²æ¥å¾Œçš„å¼µé‡ t33_cat ç¶­åº¦\n",
        "print(t33_cat.size())                 \n",
        "\n",
        "# å®£å‘Š Tensor è®Šæ•¸\n",
        "t34 = torch.tensor([                  \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "print(t34)\n",
        "print(t34.size())\n",
        "\n",
        "# å°å¼µé‡ t34 ç¶­åº¦ 0 å¢åŠ  1 ç¶­\n",
        "t34_usq = torch.unsqueeze(t34, dim=0) \n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t34 ç¶­åº¦ 0 å¢åŠ  1 ç¶­å¾Œçš„çµæœ\n",
        "print(t34_usq)                        \n",
        "# è¼¸å‡ºå¼µé‡ t34 ç¶­åº¦ 0 å¢åŠ  1 ç¶­å¾Œçš„ç¶­åº¦\n",
        "print(t34_usq.size())                 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Torch Tensor\n",
        "ç¨‹å¼èªè¨€æ¡†æ¶é€šå¸¸æœ‰å…¶ä¸»è¦çš„è³‡æ–™å‹æ…‹ï¼Œåƒæ˜¯ numpy ä¸­çš„ ndarrayã€‚åœ¨ PyTorch å…§å‰‡æ˜¯å«åš tensorï¼ˆå¼µé‡ï¼‰çš„ä¸€ç¨®è³‡æ–™å‹æ…‹ã€‚PyTorch çš„æ‰€æœ‰æ“ä½œå’Œ numpy éƒ½å¾ˆç›¸ä¼¼ï¼Œä½†é‡è¦çš„æ˜¯ tensor æ”¯æ´ CUDA çš„ç¡¬é«”åŠ é€Ÿï¼ˆGPUï¼‰ï¼Œä½¿å¾— GPU æ·±åº¦å­¸ç¿’è®Šå¾—ç°¡å–®å¯è¡Œã€‚tensor å¯ä»¥åœ¨GPU/CPUä¸Šå‚³è¼¸ï¼šåªè¦ä½¿ç”¨ `tensor.cuda(device_id)`\n",
        "å³å¯ä»¥å°‡ tensor ç§»å‹•åˆ°ç¬¬ `device_id` å€‹ï¼ˆ0-indexedï¼‰çš„ GPU æ ¸å¿ƒä¸Šã€‚æˆ–è€… `tensor.cpu()`å¯ä»¥å°‡ tensor ç§»å‹•å›åˆ° CPU ä¸Šã€‚å¦å¤–ä¸€å€‹æ›´é€šç”¨çš„æ–¹æ³•æ˜¯ `tensor.to(device)`ã€‚\n",
        "\n",
        "--- \n",
        "### é¡å¤–è£œå……\n",
        "#### ä»€éº¼æ˜¯ GPU ï¼Ÿ\n",
        "GPUå…¨ç¨±ç‚ºåœ–å½¢è™•ç†å™¨ï¼ˆGraphics Processing Unitï¼‰ï¼Œæ˜¯ä¸€ç¨®å°ˆé–€é€²è¡Œç¹ªåœ–é‹ç®—å·¥ä½œçš„å¾®è™•ç†å™¨ã€‚å„˜ç®¡GPUåœ¨éŠæˆ²ä¸­ä»¥3Dæ¸²æŸ“è€Œèåï¼Œä½†GPUç›¸è¼ƒæ–¼ã€Œå‚³çµ±çš„å°ˆç‚ºé€šç”¨è¨ˆç®—è€Œè¨­è¨ˆçš„CPUï¼Œå…·æœ‰æ•¸ç™¾æˆ–æ•¸åƒå€‹æ ¸å¿ƒï¼Œç¶“éå„ªåŒ–ï¼Œå¯ä¸¦è¡Œé‹è¡Œå¤§é‡è¨ˆç®—ï¼Œå°é‹è¡Œæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’ç®—æ³•å°¤å…¶æœ‰ç”¨ã€‚GPUå…è¨±æŸäº›è¨ˆç®—æ©Ÿæ¯”å‚³çµ±CPUä¸Šé‹è¡Œç›¸åŒçš„è¨ˆç®—é€Ÿåº¦å¿«10-100å€ã€‚\n",
        "\n",
        "#### ä»€éº¼æ˜¯CUDAï¼Ÿ\n",
        "\n",
        "CUDAå…¨ç¨±ç‚ºè¨ˆç®—çµ±ä¸€è¨­å‚™æ¶æ§‹ï¼ˆCompute Unified Device Architectureï¼‰ï¼Œæ˜¯NVIDIAï¼ˆè¼é”ï¼‰å‰µå»ºçš„å¹³è¡Œè¨ˆç®—å¹³è‡ºå’Œæ‡‰ç”¨ç¨‹åºç·¨ç¨‹æ¥å£æ¨¡å‹ã€‚CUDA å¹³è‡ºæ˜¯ä¸€å€‹è»Ÿä»¶å±¤ï¼Œå¯ç›´æ¥è¨ªå•GPUçš„è™›æ“¬æŒ‡ä»¤é›†å’Œä¸¦è¡Œè¨ˆç®—å…ƒç´ ï¼Œä»¥åŸ·è¡Œè¨ˆç®—å…§æ ¸ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘å€‘æƒ³åˆ©ç”¨ GPU åŠ é€Ÿé‹è¡Œæ·±åº¦å­¸ç¿’ç®—æ³•ï¼Œé‚£éº¼ CUDA å°±æ˜¯ä¸€å€‹ä¸å¯æˆ–ç¼ºçš„ä¸­é–“å±¤ï¼Œå®ƒä»£æ›¿æˆ‘å€‘ç›´æ¥å’ŒGPUç¡¬é«”æ‰“äº¤é“ï¼Œä¸¦å°å¤–é–‹æ”¾æ¥å£ã€‚è€Œ PyTorch å‰‡å°é€™å±¤æ¥å£å†æ¬¡é€²è¡Œå°è£ï¼Œä»¥æ–¹ä¾¿ç¨‹å¼è¨­è¨ˆäººå“¡ä½¿ç”¨ã€‚\n",
        "\n",
        "#### ä»€éº¼æ˜¯cuDNNï¼Ÿ\n",
        "\n",
        "cuDNN å…¨ç¨±ç‚º CUDA æ·±åº¦ç¥ç¶“ç¶²çµ¡åº«ï¼ˆCUDA Deep Neural Network libraryï¼‰ï¼Œæ˜¯ NVIDIA æ‰“é€ çš„é‡å°æ·±åº¦ç¥ç¶“ç¶²çµ¡çš„åŠ é€Ÿåº«ï¼Œæ˜¯ä¸€å€‹ç”¨æ–¼æ·±å±¤ç¥ç¶“ç¶²çµ¡çš„ GPU åŠ é€Ÿåº«ã€‚å¦‚æœä½ è¦ä½¿ç”¨ GPU è¨“ç·´æ¨¡å‹ï¼ŒcuDNN ä¸æ˜¯å¿…é ˆçš„ï¼Œä½†ä¸€èˆ¬æœƒæ¡ç”¨é€™å€‹åŠ é€Ÿåº«ã€‚\n",
        "\n",
        "### åƒè€ƒè³‡æ–™\n",
        "- [çŸ¥ä¹ï¼šä»€éº¼æ˜¯å¼µé‡ï¼Ÿ& æ·±åº¦å­¸ç¿’](https://zhuanlan.zhihu.com/p/48982978)\n",
        "- [CUDA å…¥é–€, nvidia å…¬å¸å®˜æ–¹ç¶²ç«™](https://blogs.nvidia.com.tw/2020/10/27/cuda-refresher-getting-started-with-cuda/)\n",
        "- [CUDAã€cuDNNã€pytorch å®‰è£…åˆ†æ](https://blog.csdn.net/weixin_38481963/article/details/105313471) \n",
        "- [NQU Tensor ä»‹ç´¹ slides](https://www.nqu.edu.tw/upload/educsie/attachment/529fa35c91b055e7da3c8dc7a9bc975e.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpkIiN9Vbr-M"
      },
      "source": [
        "## ä½¿ç”¨ GPU é‹ç®—\n",
        "\n",
        "ä¸Šè¿°çš„æ‰€æœ‰æ•™å­¸éƒ½æ˜¯åœ¨ CPU ä¸Šé€²è¡Œé‹ç®—ï¼Œè€Œå¤§å¤šæ•¸çš„æ·±åº¦å­¸ç¿’æ¡†æ¶éƒ½æœƒæä¾›æ“ä½œ GPU çš„ä»‹é¢å¹«åŠ©å¹³å‹åŒ–é‹ç®—ã€‚\n",
        "è€Œ `torch` èˆ‡å¤§éƒ¨åˆ†çš„æ·±åº¦å­¸ç¿’æ¡†æ¶ç›¸åŒï¼Œä½¿ç”¨ Nvidia é–‹ç™¼çš„ CUDAï¼ˆCompute Unified Device Architectureï¼‰å¹«åŠ©ä½¿ç”¨ GPU é€²è¡Œæ·±åº¦å­¸ç¿’çš„é‹ç®—ï¼ˆcuDNNï¼‰ã€‚\n",
        "\n",
        "ä½¿ç”¨ CUDA æ“ä½œå¹³å‹åŒ–é‹ç®—çš„æµç¨‹ç‚ºï¼š\n",
        "\n",
        "1. å®£å‘Š GPU é‹ç®—æ‰€éœ€è¦ä½”ç”¨çš„è¨˜æ†¶é«”ï¼ˆ`cudaMalloc`ï¼‰\n",
        "2. å®šç¾©æ¯å€‹å¹³å‹åŒ–é‹ç®—ç¯€é»çš„é‹ç®—å…§å®¹\n",
        "3. åœ¨ä¸»è¨˜æ†¶é«”ä¸Šå‰µé€ è³‡æ–™ï¼ˆ`malloc`ï¼‰\n",
        "4. å°‡è³‡æ–™æ¬ç§»è‡³ GPU çš„è¨˜æ†¶é«”ï¼ˆ`cudaMemcpy`ï¼‰\n",
        "5. æ¯å€‹ç¯€é»ç¨ç«‹é‹ç®—\n",
        "6. å°‡è¨ˆç®—çµæœæ¬å›è‡³ä¸»è¨˜æ†¶é«”ï¼ˆ`memcpy`ï¼‰\n",
        "7. é‡‹æ”¾ GPU çš„è¨˜æ†¶é«”ï¼ˆ`cudaFree`ï¼‰\n",
        "\n",
        "è€Œåœ¨ `torch` ä¸­å°‡ä»¥ä¸Šæµç¨‹ç°¡åŒ–æˆä»¥ä¸‹å…©ç¨®æ–¹æ³•\n",
        "\n",
        "- å®£å‘Š `torch.Tensor` è®Šæ•¸æ™‚ä½¿ç”¨ `device='cuda:0'` åƒæ•¸å°‡è®Šæ•¸å®£å‘Šæ–¼ GPU è¨˜æ†¶é«”ç¬¬0é¡†ï¼ˆ0-indexedï¼‰ã€‚\n",
        "- å°å·²ç¶“å‰µé€ æ–¼ä¸»è¨˜æ†¶é«”çš„ `torch.Tensor` è®Šæ•¸ä½¿ç”¨ `torch.to('cuda:0')` æ¬ç§»è‡³ GPU è¨˜æ†¶é«”ç¬¬0é¡†ï¼ˆ0-indexedï¼‰ã€‚\n",
        "```python\n",
        "torch.tensor([1., 2., 3.], device='cuda:0') # ä½¿ç”¨ device åƒæ•¸å°‡è®Šæ•¸å®£å‘Šæ–¼ GPU è¨˜æ†¶é«”\n",
        "torch.tensor([1., 2., 3.]).to('cuda:0')     # ä½¿ç”¨ to å°‡è®Šæ•¸æ¬ç§»è‡³ GPU è¨˜æ†¶é«”\n",
        "```\n",
        "\n",
        "å®£å‘Šæ–¼ GPU æˆ–æ¬ç§»è‡³ GPU å¾Œï¼Œä¹‹å¾Œæ‰€æœ‰çš„é‹ç®—ä¾¿æœƒåœ¨ GPU ä¸Šé€²è¡Œã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djuqIr7vbr-M",
        "outputId": "9c908a0d-17f7-4119-eba8-2b31a63bc5ae"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ GPU é‹ç®—\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # ä½¿ç”¨ device åƒæ•¸å‰µé€ å¼µé‡æ–¼ GPU ä¸Š\n",
        "    t35 = torch.tensor([1., 2., 3.], device='cuda:0') \n",
        "else:\n",
        "    # å¦‚æœä¸æ”¯æ´ cuda å‰‡å‡ºç¾ error\n",
        "    print('torch not compiled with CUDA enabled')     \n",
        "    t35 = None\n",
        "    \n",
        "# è¼¸å‡ºå¼µé‡ t35\n",
        "print(t35)                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKtEO_4Nbr-M",
        "outputId": "bc81130a-0364-46f8-f285-4e9dc15e71c7"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    # ä½¿ç”¨ to å°‡å¼µé‡æ¬ç§»è‡³ GPU ä¸Š\n",
        "    t36 = torch.tensor([1., 2., 3.]).to('cuda:0') \n",
        "else:\n",
        "    # å¦‚æœä¸æ”¯æ´ cuda å‰‡å‡ºç¾ error\n",
        "    print('torch not compiled with CUDA enabled') \n",
        "    t36 = None\n",
        "    \n",
        "# è¼¸å‡ºå¼µé‡ t36\n",
        "print(t36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dZ9N1Ybr-M",
        "outputId": "cfbd5e50-4101-4edb-8ed4-4f57532f2ad0"
      },
      "outputs": [],
      "source": [
        "# å¦‚æœæœ‰å¯ç”¨ GPU æ™‚æ¡ç”¨ GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# è‹¥ç„¡ GPU å¯ç”¨å‰‡ä½¿ç”¨ CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "\n",
        "# æ ¹æ“š device å‰µé€ å¼µé‡\n",
        "t37 = torch.tensor([1., 2., 3.], device=device) \n",
        "# ä½¿ç”¨ to æ¬ç§»å¼µé‡è‡³æŒ‡å®šçš„è£ç½®\n",
        "t38 = torch.tensor([1., 2., 3.]).to(device)     \n",
        "\n",
        "# è¼¸å‡ºå¼µé‡ t37\n",
        "print(t37)                                      \n",
        "# è¼¸å‡ºå¼µé‡ t38\n",
        "print(t38)                                      "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLKGH_vbr-M"
      },
      "source": [
        "## æ·±åº¦å­¸ç¿’\n",
        "\n",
        "![Deep Learning](https://miro.medium.com/max/1000/1*51D0MqtqHu3h2vTE5oJ-7g.png)\n",
        "![Deep Learning vs. Machine Learning](https://learn.microsoft.com/zh-tw/azure/machine-learning/media/concept-deep-learning-vs-machine-learning/ai-vs-machine-learning-vs-deep-learning.png)\n",
        "### æ·±åº¦å­¸ç¿’è¦å¹¹å˜›ï¼Ÿ\n",
        "ä¸Šèª²æ•™çš„ SVM, Bayes ç­‰ç­‰çš„æ¨¡å‹ç®—æ˜¯ ï¼ˆå‚³çµ±ï¼‰Machine Learning çš„ç¯„ç–‡ï¼Œæ¯”è¼ƒåå‘å»ºç«‹æ–¼çµ±è¨ˆçš„å‡è¨­çš„æ•¸å­¸çµ±è¨ˆæ¨¡å‹ã€‚è€Œæ·±åº¦å­¸ç¿’å‰‡æ˜¯æ©Ÿå™¨å­¸ç¿’å…§çš„ä¸€å€‹å­é›†åˆï¼ˆsubsetï¼‰ï¼Œä»–æ˜¯ä»¥é¡ç¥ç¶“ç¶²è·¯ä¾†æ¨¡æ“¬äººé¡å¤§è…¦çš„ç¥ç¶“å…ƒä¹‹é–“çš„äº’å‹•ã€‚\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "ä½¿ç”¨ `torch` é€²è¡Œæ·±åº¦å­¸ç¿’ä¸»è¦åŒ…å«ä»¥ä¸‹æ­¥é©Ÿï¼š\n",
        "1. å°‡è³‡æ–™è½‰æ›æˆ `torch.Tensor`ï¼Œä½¿ç”¨ Dataset å’Œ Dataloader åŒ…è£ç®¡ç†è³‡æ–™ã€‚\n",
        "2. ä½¿ç”¨ `torch.nn` å»ºç«‹æ·±åº¦å­¸ç¿’æ¨¡å‹æ¶æ§‹ã€‚\n",
        "3. å¾ `torch.optim` é¸æ“‡æœ€ä½³åŒ–å·¥å…·ã€‚\n",
        "4. é¸æ“‡ç›®æ¨™å‡½æ•¸ã€‚\n",
        "5. è¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼ˆtrainï¼‰ã€‚\n",
        "6. æ¸¬è©¦æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼ˆtest, inferenceï¼‰ã€‚\n",
        "ä»¥ä¸‹ç¯„ä¾‹ï¼šä½¿ç”¨å…©å±¤å…¨é€£æ¥å±¤åš Polynomial Regression ä»»å‹™ã€‚"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### è³‡æ–™é›†\n",
        "1. ä½¿ç”¨ `torch.utils.data.Dataset` å°‡è³‡æ–™é›†è½‰æ›æˆ `torch.Tensor`\n",
        "2. ä½¿ç”¨ `torch.utils.data.DataLoader` å°‡è³‡æ–™é›†ä»¥æ‰¹æ¬¡ï¼ˆmini-batchï¼‰å–å‡º\n",
        "3. ï¼ˆOptionalï¼‰é¡å¤–å®šç¾© `collate_fn` å°‡æŠ½æ¨£çš„è³‡æ–™æ•´ç†æˆå›ºå®šçš„æ ¼å¼\n",
        "\n",
        "\n",
        "æˆ‘å€‘çš„è³‡æ–™é•·é€™æ¨£ï¼š$$y = 2x^2 + 3x + 17$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFiFnsh5br-N",
        "outputId": "912e0668-6434-4d31-8111-bb111208753d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "(tensor(0.7652), tensor(20.4665))\n"
          ]
        }
      ],
      "source": [
        "# è³‡æ–™é›†\n",
        "\n",
        "# åŒ¯å…¥è³‡æ–™é›† base class\n",
        "from torch.utils.data import Dataset \n",
        "\n",
        "# ç¹¼æ‰¿ base class å‰µé€ è³‡æ–™é›†\n",
        "class MyDataset(Dataset):            \n",
        "    # çµ¦äºˆè³‡æ–™é›†å¤§å°ï¼Œä¸¦éš¨æ©Ÿå‰µé€ è³‡æ–™\n",
        "    def __init__(self, size:int):        \n",
        "        self.x = torch.rand(size) \n",
        "        self.y = 2 * self.x ** 2 + 3 * self.x + 17\n",
        "        \n",
        "    # å®šç¾©ç¸½è³‡æ–™æ•¸\n",
        "    def __len__(self):               \n",
        "        return len(self.x)\n",
        "    \n",
        "    # å®šç¾©å–å‡ºå–®ä¸€è³‡æ–™çš„æ–¹æ³•\n",
        "    def __getitem__(self, index):    \n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "# å‰µé€ è³‡æ–™é›†\n",
        "my_dataset = MyDataset(10)           \n",
        "# å–å¾—ç¸½è³‡æ–™æ•¸\n",
        "print(len(my_dataset))               \n",
        "# å–å‡ºå–®ä¸€è³‡æ–™\n",
        "print(my_dataset[0])                 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### batch (mini-batch)\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:825/0*FKi8Z3JT-Y2C1yiw\"  width=\"400\">\n",
        "\n",
        "æ¯ä¸€æ¬¡æ›´æ–°åƒæ•¸æ™‚ï¼Œæ¨¡å‹ä»¥æ•´å€‹ batch ä¸­`batch_size` ç­†çš„è³‡æ–™ï¼Œçœ‹éä¸€éï¼Œç„¶å¾Œæ›´æ–°ä¸€æ¬¡åƒæ•¸ã€‚ä¸€å€‹ epoch ä»£è¡¨æ¨¡å‹çœ‹éæ•´å€‹è³‡æ–™é›†ä¸€æ¬¡ã€‚\n",
        "æœ€æ¥µç«¯çš„å…©å€‹ç‹€æ³ï¼šbatch_size = 1, batch_size = è³‡æ–™é›†å¤§å°\n",
        "- batch_size å°ï¼šè¨ˆç®—æˆæœ¬æ˜‚è²´ï¼Œgradient å™ªéŸ³å¤šï¼Œä½†å°æœ€ä½³åŒ–çš„æ–¹å‘è¼ƒç‚ºæº–ç¢ºã€‚\n",
        "- batch_size å¤§ï¼šè¨ˆç®—æˆæœ¬ä½ï¼Œgradient å™ªéŸ³å°‘ï¼Œä½†ç¥å¥‡çš„æ˜¯ï¼ˆï¼Ÿï¼‰å¯¦é©—çµæœèªªå°æœ€ä½³åŒ–çš„æ–¹å‘è¼ƒä¸æº–ç¢ºã€‚\n",
        "- batch_size æ€éº¼è¨­ï¼Ÿçœ‹ä»»å‹™å…§å®¹ï¼ˆèª¿åƒæŠ€è¡“ä¹‹ä¸€ï¼‰ã€‚\n",
        "ç›¸é—œåƒè€ƒå½±ç‰‡:\n",
        "[ã€æ©Ÿå™¨å­¸ç¿’2021ã€‘é¡ç¥ç¶“ç¶²è·¯è¨“ç·´ä¸èµ·ä¾†æ€éº¼è¾¦ (äºŒ)ï¼š æ‰¹æ¬¡ (batch) èˆ‡å‹•é‡ (momentum)](https://www.youtube.com/watch?v=zzbr1h9sF54)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWP1moMObr-N",
        "outputId": "703e9283-8e0f-4f81-e5c4-8e008071aed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([1, 1]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "# åŒ¯å…¥è³‡æ–™é›†æŠ½æ¨£å·¥å…·\n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "# å®šç¾©æ ¼å¼åŒ–çš„æ–¹æ³•\n",
        "def collate_fn(batch):                  \n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    \n",
        "    for x, y in batch:\n",
        "        x_list.append([x])              \n",
        "        y_list.append([y])              \n",
        "    # æœ€çµ‚å›å‚³çš„ç¶­åº¦ç‚º [(batch_size, 1), (batch_size, 1)]\n",
        "    # æœ€çµ‚å›å‚³çš„ç¶­åº¦ç‚º [(batch_size, n_features), (batch_size, label_dim)]\n",
        "    return [torch.tensor(x_list), torch.tensor(y_list)] \n",
        "\n",
        "# å‰µé€  DataLoader å¯¦ä¾‹\n",
        "batch_size = 3\n",
        "my_data_loader = DataLoader(            \n",
        "    my_dataset,                 # å°è³‡æ–™é›† my_dataset é€²è¡ŒæŠ½æ¨£\n",
        "    batch_size=batch_size,      # è¨­å®šæ¯æ¬¡æŠ½æ¨£çš„æ•¸é‡                 \n",
        "    shuffle=True,               # è¨­å®šéš¨æ©ŸæŠ½æ¨£                  \n",
        "    collate_fn=collate_fn       # æŒ‡å®šæ ¼å¼åŒ–çš„æ–¹æ³•    \n",
        ")\n",
        "\n",
        "# é€é my_data_loader å°è³‡æ–™é›† my_dataset é€²è¡ŒæŠ½æ¨£\n",
        "for x, y in my_data_loader:             \n",
        "    print(x.size(), y.size())\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Q. ç‚ºä»€éº¼è¦å°‡æ¯å€‹ `x` è½‰æ›æˆ `[x]`ï¼Ÿ\n",
        "åœ¨æ­¤æ–¹æ³•ä¸­ï¼Œå°‡æ¯å€‹ `x` è½‰æ›æˆ `[x]` çš„å½¢å¼æ˜¯å› ç‚ºæˆ‘å€‘å¸Œæœ›æ¯å€‹ `x` åœ¨ tensor ä¸­éƒ½æœ‰ä¸€å€‹å–®ç¨çš„ç¶­åº¦ï¼Œä»¥ä¾¿å¾ŒçºŒèƒ½å¤ é€²è¡Œæ‰¹æ¬¡é‹ç®—ã€‚\n",
        "å¦‚æœç›´æ¥å°‡æ¯å€‹ `x` append åˆ°åˆ—è¡¨ä¸­ï¼Œå‰‡æœƒç”¢ç”Ÿä¸€å€‹æ²’æœ‰é¡å¤–ç¶­åº¦çš„åˆ—è¡¨ï¼Œ\n",
        "é€™æ¨£åœ¨å¾ŒçºŒæ‰¹æ¬¡è™•ç†æ™‚æœƒå‡ºç¾ç¶­åº¦ä¸ä¸€è‡´çš„å•é¡Œï¼Œç„¡æ³•é€²è¡Œé‹ç®—ã€‚\n",
        "Try append x, y alone and you will see `RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x3 and 1x10)` in `model.forward()`ã€‚\n",
        "#### Q. ç‚ºä»€éº¼æœ€å¾Œä¸€å€‹ batch å…§çš„å½¢ç‹€æ˜¯ `torch.Size([1, 1]) torch.Size([1, 1])`? `batch_size` ä¸æ˜¯ 3 å—ï¼Ÿ\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqeXVb2e0tlT"
      },
      "source": [
        "### å»ºç«‹æ¨¡å‹\n",
        "\n",
        "å¯ä»¥ä½¿ç”¨ `torch.nn` ç¾æˆçš„æ¨¡å‹é€²è¡Œæ·±åº¦å­¸ç¿’ï¼Œ``torch`` æä¾›å¾ˆå¤šã€Œç¥ç¶“å±¤ã€ï¼ˆlayerï¼‰ï¼Œå¯ä»¥ç”¨ä¾†å»ºç«‹æ¨¡å‹çš„æ¶æ§‹ï¼ˆarchitectureï¼‰ã€‚\n",
        "- é¢å°å“ªå€‹ä»»å‹™æ‡‰è©²ç”¨ä»€éº¼æ¨¡å‹ï¼Ÿ\n",
        "- æ¨¡å‹çš„è¼¸å…¥è¼¸å‡ºçš„å½¢å¼è¦å¦‚ä½•å®šç¾©ï¼Ÿ\n",
        "- æ¨¡å‹è¦æ€éº¼æ¶æ§‹ï¼Ÿ\n",
        "- æ²’è¾¦æ³•ä¸€ä¸€çš„è¬›ï¼Œåœ¨[NNä¸­æ–‡æ–‡æœ¬åˆ†é¡](NN-ä¸­æ–‡æ–‡æœ¬åˆ†é¡.ipynb)æœƒè¬›æ€éº¼æ¶æ§‹ä¸€é¡† RNN ä¾†åšæ–‡æœ¬åˆ†é¡ä»»å‹™ã€‚å…¶ä»–ç¥ç¶“å±¤å¯ä»¥å»[torch.nn](https://pytorch.org/docs/stable/nn.html)çœ‹çœ‹ï¼Œæ€éº¼æ¶æ§‹åªèƒ½å…ˆäº†è§£åŸç†ç„¶å¾Œå¤šæŸ¥å¤šç·´ç¿’ï¼š[PyTorch Tutorial](https://pytorch.org/tutorials/)ã€‚\n",
        "\n",
        "|æ¨¡å‹ä»‹é¢|åç¨±|å¸¸è¦‹ç”¨é€”|\n",
        "|-|-|-|\n",
        "|`torch.nn.Linear`|ç·šæ€§å±¤ï¼ˆLinear Layerï¼‰|è½‰æ›ç‰¹å¾µ|\n",
        "|`torch.nn.Embedding`|åµŒå…¥å±¤ï¼ˆEmbedding Layerï¼‰|å­¸ç¿’ç‰¹å¾µå‘é‡è¡¨é”æ³•|\n",
        "|`torch.nn.Conv1d`|1 ç¶­å·ç©å±¤ï¼ˆ1-Dimensional Convolution Layerï¼‰|æŠ½å–é€£çºŒè³‡æ–™å€åŸŸç‰¹å¾µ|\n",
        "|`torch.nn.Conv2d`|2 ç¶­å·ç©å±¤ï¼ˆ2-Dimensional Convolution Layerï¼‰|æŠ½å–å¹³é¢åœ–ç‰‡å€åŸŸç‰¹å¾µ|\n",
        "|`torch.nn.Conv3d`|3 ç¶­å·ç©å±¤ï¼ˆ3-Dimensional Convolution Layerï¼‰|æŠ½å–ç«‹é«”åœ–ç‰‡å€åŸŸç‰¹å¾µ|\n",
        "|`torch.nn.RNN`|å¾ªç’°ç¥ç¶“ç¶²è·¯ï¼ˆRecurrent Neural Networkï¼‰|å£“ç¸®å‹•æ…‹é•·åº¦æ–‡å­—|\n",
        "|`torch.nn.LSTM`|é•·çŸ­æœŸè¨˜æ†¶ç¥ç¶“ç¶²è·¯ï¼ˆLong Short-Term Memoryï¼‰|æœ‰æ•ˆå£“ç¸®å‹•æ…‹é•·åº¦æ–‡å­—|\n",
        "|`torch.nn.Transformer`|å¤šé¢å‘è‡ªæˆ‘æ³¨æ„åŠ›æ©Ÿåˆ¶æ¨¡å‹ï¼ˆMulti-Head Self-Attentionï¼‰|æ©Ÿå™¨ç¿»è­¯|\n",
        "\n",
        "å¦‚æœéœ€è¦ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œå¿…é ˆé€éç¹¼æ‰¿ `torch.nn.Module` ä¾†å®šç¾©**æ¨¡å‹çµæ§‹**èˆ‡**é‹ç®—æµç¨‹**ï¼š\n",
        "ä½¿ç”¨ `nn.Module` å®šç¾©æ¨¡å‹æ™‚å¿…é ˆè¦è¨˜å¾—ä»¥ä¸‹è¦å‰‡ï¼š\n",
        "\n",
        "- åœ¨é¡åˆ¥æ–¹æ³• `__init__` ä¸­å®šç¾©æ¨¡å‹çµæ§‹\n",
        "    - å¿…é ˆè¦åŸ·è¡Œ `super(MyModel, self).__init__()`\n",
        "    - ç‚ºä»€éº¼éœ€è¦ï¼š[colab link](https://colab.research.google.com/drive/1LL1RVaoGoGYE68HCaMOEVSCR8bEPgqqc?usp=sharing)\n",
        "- å¿…é ˆé€éå®šç¾©é¡åˆ¥æ–¹æ³• `forward` æ‰èƒ½å®šç¾©è¨ˆç®—æµç¨‹"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QWrkuLw005aB"
      },
      "source": [
        "\n",
        "### å•Ÿå‹•å‡½æ•¸ï¼ˆActivation Functionsï¼‰\n",
        "\n",
        "è‹¥æ¨¡å‹éœ€è¦å•Ÿå‹•å‡½æ•¸ï¼Œå¯ä»¥ä½¿ç”¨ `torch.nn.functional` ä¸­äº‹å…ˆå®šç¾©å¥½çš„å•Ÿå‹•å‡½æ•¸ï¼š\n",
        "å¸¸è¦‹çš„å•Ÿå‹•å‡½æ•¸åŒ…å«ï¼š\n",
        "\n",
        "|å•Ÿå‹•å‡½æ•¸|åç¨±|å®šç¾©|æ•¸å€¼ç¯„åœ|\n",
        "|-|-|-|-|\n",
        "|`torch.nn.functional.relu`|ReLU|$$f(x_i) = \\max(0, x_i)$$|$$\\mathbb{R}^+$$|\n",
        "|`torch.nn.functional.softmax`|Softmax|$$f(x_i) = \\frac{e^{x_i}}{\\sum_{j = 0}^n e^{x_j}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.sigmoid`|Sigmoid|$$f(x_i) = \\frac{1}{1 + e^{-x_i}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.tanh`|Hyperbolic Tangent|$$f(x_i) = \\frac{e^{x_i} - e^{-x_i}}{e^{x_i} + e^{-x_i}}$$|$$[-1, 1]$$|\n",
        "\n",
        "<img src=\"https://i.imgur.com/2T2K61V.png\"  width=\"600\" height=\"300\">\n",
        "\n",
        "#### Why do we need Activation Functions? \n",
        "æ‰€æœ‰ Activation functions çš„å¤§ç•¥æ¦‚å¿µéƒ½æ˜¯ \"creates a non-linearity in your output\"ï¼Œå®ƒå€‘çš„å­˜åœ¨ä½¿æ¨¡å‹\n",
        "èƒ½å¤  fit åœ¨éç·šæ€§æ›´ç‚ºè¤‡é›œçš„è³‡æ–™ä¸Šã€‚Sigmoid æ˜¯æœ€åˆå§‹çš„ï¼Œä½†æ˜¯å› ç‚ºå®ƒçš„æ•¸å€¼ç¯„åœè½åœ¨ 0 åˆ° 0.25ï¼Œgradient åœ¨å¾Œå‘å‚³æ’­æ™‚æœƒæ¶ˆå¤±ï¼Œå› æ­¤æ¼¸æ¼¸å°‘ç”¨ï¼ˆç›¸é—œå½±ç‰‡ï¼š[Sigmoid and Vanishing Gradient](https://www.youtube.com/watch?v=kGAo32JgY48)ï¼‰ã€‚ReLU (Rectified Linear Units) å‰‡å–è€Œä»£ä¹‹ï¼Œå®ƒæ˜¯æŠŠè² æ•¸å…ˆè½‰ç‚ºé›¶ï¼Œæ­£æ•¸å°±ä»€éº¼éƒ½ä¸åšç›´æ¥é›¢é–‹ nodeã€‚ç”¨æ„æ˜¯æŠŠè² å€¼é—œä¿‚æ’é™¤æ‰ï¼Œå¯ä»¥æŠµæŠ— gradient vanishingã€‚ReLU æœ‰å„ç¨®è®Šå½¢ï¼šLeakyReLUã€alpha ReLU ç­‰ç­‰ã€‚Tanh æ˜¯ Sigmoid çš„è®Šå½¢ï¼Œå®ƒçš„æ•¸å€¼ç¯„åœæ˜¯ -1 åˆ° 1ï¼Œå› æ­¤å®ƒçš„ gradient ä¸æœƒæ¶ˆå¤±ï¼Œä½†æ˜¯å®ƒçš„è¼¸å‡ºæ˜¯ zero-centeredï¼Œå› æ­¤åœ¨è¨“ç·´æ™‚æœƒæ¯”è¼ƒé›£æ”¶æ–‚ã€‚Softmax $softmax(\\overrightarrow{a}) = \\frac{e^{a_i}}{\\sum_k{e^{a_k}}}$æ˜¯ç”¨ä¾†æŠŠè¼¸å‡ºè½‰ç‚ºæ©Ÿç‡åˆ†ä½ˆï¼Œè®“è¼¸å‡ºçš„æ•¸å€¼ç¸½å’Œç‚º 1ï¼Œå¯ä»¥ç”¨ä¾†åšï¼ˆå–®ä¸€/å¤šï¼‰åˆ†é¡çš„æ©Ÿç‡é æ¸¬ã€‚\n",
        "\n",
        "#### The reasons we need `torch.argmax()`.\n",
        "<img src=\"https://img-blog.csdn.net/20180902220822202?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JpdGNhcm1hbmxlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"  width=\"400\">\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### `torch.nn.Linear`\n",
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/Screenshot-from-2020-02-03-22-14-21-300x195.png)\n",
        "- $X$: input \n",
        "- $W, b$: the parameters we would like to fit. \n",
        "- $Z$: the output we would like to get. \n",
        "- If multiple layers are stacked, $Z$ will be the input of the next layer. In general, we would like the FINAL layer's output to be close \n",
        "to the ground truth $Y$. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmmUqpKLbr-N",
        "outputId": "8c4252de-75a9-4bac-e425-84fb8e3e4017"
      },
      "outputs": [],
      "source": [
        "# å»ºç«‹æ¨¡å‹\n",
        "\n",
        "# åŒ¯å…¥ç¥ç¶“ç¶²è·¯æ¨¡å‹\n",
        "import torch.nn as nn                   \n",
        "# åŒ¯å…¥å•Ÿå‹•å‡½æ•¸\n",
        "import torch.nn.functional as F         \n",
        "\n",
        "# æ¨¡å‹éœ€è¦ç¹¼æ‰¿è‡ª nn.Module\n",
        "class MyModel(nn.Module):               \n",
        "    # å®šç¾©æ¨¡å‹çµæ§‹, è¼¸å…¥å±¤ç¶­åº¦, éš±è—å±¤ç¶­åº¦, è¼¸å‡ºå±¤ç¶­åº¦\n",
        "    def __init__(self,                  \n",
        "                 in_dim,                \n",
        "                 hid_dim,               \n",
        "                 out_dim):              \n",
        "\n",
        "        # ç¹¼æ‰¿ nn.Module æ‰€æœ‰å±¬æ€§\n",
        "        super(MyModel, self).__init__() \n",
        "        \n",
        "        # å‰µé€ ç·šæ€§å±¤ self.layer1\n",
        "        self.layer1 = nn.Linear(        \n",
        "            # è¨­å®šç·šæ€§å±¤è¼¸å…¥ç¶­åº¦\n",
        "            in_features=in_dim,         \n",
        "            # è¨­å®šç·šæ€§å±¤è¼¸å‡ºç¶­åº¦\n",
        "            out_features=hid_dim        \n",
        "        )\n",
        "        # å‰µé€ ç·šæ€§å±¤ self.layer2\n",
        "        self.layer2 = nn.Linear(        \n",
        "            # è¨­å®šç·šæ€§å±¤è¼¸å…¥ç¶­åº¦\n",
        "            in_features=hid_dim,        \n",
        "            # è¨­å®šç·šæ€§å±¤è¼¸å‡ºç¶­åº¦\n",
        "            out_features=out_dim      \n",
        "        )\n",
        "        \n",
        "    # [Important] å®šç¾©é‹ç®—æµç¨‹\n",
        "    def forward(self, batch_x): \n",
        "        # Why use ReLU?       \n",
        "        # ä½¿ç”¨ç·šæ€§å±¤ self.layer1 è¼¸å…¥ batch_x è¨ˆç®—å¾—åˆ° h\n",
        "                                     # batch_x's shape: (batch_size, in_dim)\n",
        "        h = self.layer1(batch_x)     # h = Wx + b, h's shape: (batch_size, hid_dim)   \n",
        "                                    # ä½¿ç”¨ ReLU å•Ÿå‹•å‡½æ•¸è¼¸å…¥ h å¾—åˆ° a\n",
        "        a = F.relu(h)                # a = ReLU(h), a's shape: (batch_size, hid_dim)        \n",
        "                                    # ä½¿ç”¨ç·šæ€§å±¤ self.layer2 è¼¸å…¥ a è¨ˆç®—å¾—åˆ° y\n",
        "        y = self.layer2(a)           # y = Wa + b, y's shape: (batch_size, out_dim) \n",
        "        \n",
        "        \n",
        "        # è¼¸å‡º y\n",
        "        return y                        \n",
        "    \n",
        "# å‰µé€  MyModel æ¨¡å‹å¯¦ä¾‹\n",
        "my_model = MyModel(                     \n",
        "    # è¨­å®šè¼¸å…¥å±¤ç¶­åº¦\n",
        "    in_dim=1,                           \n",
        "    # è¨­å®šéš±è—å±¤ç¶­åº¦\n",
        "    hid_dim=10,                         \n",
        "    # è¨­å®šè¼¸å‡ºå±¤ç¶­åº¦\n",
        "    out_dim=1                           \n",
        ")\n",
        "\n",
        "# é€é my_data_loader å°è³‡æ–™é›† my_dataset é€²è¡ŒæŠ½æ¨£\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    print('batch_x shape:', batch_x.shape)\n",
        "    print('batch_y shape:', batch_y.shape) \n",
        "    pred_y = my_model(batch_x)   # this part calls my_model.forward(batch_x)       \n",
        "    print('pred_y shape:', pred_y.shape) # should be the same as batch_y in most of the cases, sometimes this should be postprocessed \n",
        "    # to match the shape of batch_y, HERE is the simplest case that the shape of pred_y is the same as batch_y\n",
        "    break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOTX8Jw1Ci2"
      },
      "source": [
        "### ç›®æ¨™å‡½æ•¸ï¼ˆObjective Functionsï¼‰\n",
        "\n",
        "ä½¿ç”¨ `torch.nn` ä¸­äº‹å…ˆå®šç¾©å¥½çš„ç›®æ¨™å‡½æ•¸é€²è¡Œæ¨¡å‹æœ€ä½³åŒ–ï¼Œè¨ˆç®—æ¨¡å‹é æ¸¬çµæœèˆ‡æ¨™è¨˜è¨“ç·´è³‡æ–™çš„èª¤å·®å€¼ï¼Œä¸¦é€éå‘å¾Œå‚³æ’­ï¼ˆBack Propagationï¼‰æ¼”ç®—æ³•å–å¾—ç›¸å°æ–¼èª¤å·®å€¼çš„æ¢¯åº¦ï¼ˆGradientï¼‰ã€‚\n",
        "- åŸºæœ¬ä¸Šå°±æ˜¯å»è¨ˆç®—æ¯å€‹åƒæ•¸çš„åå¾®åˆ†ã€‚\n",
        "- å’Œ gradient descent æ˜¯å®Œå…¨ç›¸åŒçš„æ¦‚å¿µï¼Œåªæ˜¯åœ¨ç¥ç¶“ç¶²è·¯ä¸­ neurons æ•¸é‡é¾å¤§ï¼Œå› æ­¤éœ€è¦æœ‰æœ‰æ•ˆç‡çš„æ¼”ç®—æ³•å»è¨ˆç®— gradientã€‚é€™å€‹æ¼”ç®—æ³•å°±æ˜¯ back propagationã€‚\n",
        "- ä½¿ç”¨äº† Chain Rule çš„æ¦‚å¿µã€‚è¨ˆç®—æ¯å€‹åƒæ•¸å…§å° cost function çš„åå¾®åˆ†ã€‚é€™å€‹ cost function å°±æ˜¯ã€Œæ­£ç¢ºç­”æ¡ˆèˆ‡é æ¸¬ç­”æ¡ˆçš„è·é›¢ã€ï¼Œæ›´é©ç•¶çš„åå­—æ˜¯ loss functionã€‚\n",
        "- å°ä¸€å€‹ weight matrix $W \\in R^{a \\times b}$ å…§ï¼Œ$W_{ij}$ æ˜¯ $l$å±¤$i$ ç¥ç¶“å…ƒèˆ‡ $l-1$ å±¤ $j$ ç¥ç¶“å…ƒä¹‹é–“çš„æ¬Šé‡ã€‚\n",
        "    - ![](https://i.imgur.com/fk5HCm4.png)\n",
        "- æƒ³æ›´æ–°é€™å€‹æ¬Šé‡å€¼ï¼Œå°±è¦è¨ˆç®— $\\frac{\\partial C}{\\partial W_{ij}}$ï¼Œå…¶ä¸­ $C$ æ˜¯ loss functionã€‚ä½¿ç”¨ Chain Ruleï¼Œå¯ä»¥æ‹†è§£æˆ $\\frac{\\partial C}{\\partial W_{ij}} =  \\frac{\\partial C}{\\partial Z_{i}} \\frac{\\partial Z_{i}}{\\partial W_{ij}}$ï¼Œ$Z_i$ æ˜¯ $i$ æ‰€åœ¨çš„ç¥ç¶“å…ƒçš„è¼¸å…¥å€¼ï¼Œ$a^i$ æ˜¯ $i$ ç¥ç¶“å…ƒçš„è¼¸å‡ºå€¼ã€‚ï¼ˆä¸‹åœ–ä¸Šæ¨™æ„ç¾©è§£é‡‹ï¼šä¸Šæ¨™ $l$ æ˜¯ä½ çš„å±¤æ•¸ï¼ˆä½ ç¾åœ¨æ›´æ–°çš„æ˜¯å“ªä¸€å±¤çš„æ¬Šé‡çŸ©é™£ï¼Ÿå¯¦éš›ä¸Šæ¯ä¸€å±¤éƒ½éœ€è¦ç®—ï¼‰ï¼Œ$r$ æ˜¯ç¬¬$r$çµ„è³‡æ–™ï¼‰ã€‚æ‰€ä»¥é€™å…©å€‹ terms åˆ†åˆ¥è¦æ€éº¼è¨ˆç®—ï¼Ÿè«‹å»çœ‹ä¸‹é¢ç¬¬ä¸€å€‹å½±ç‰‡ã€‚\n",
        "    - ![](https://i.imgur.com/3EihDh7.png)\n",
        "- Resources (a lot of maths): \n",
        "    - [DNN Back propagation](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/index.html)\n",
        "    - [Computational Graph çš„è§’åº¦å»çœ‹ Back propagation](https://www.youtube.com/watch?v=-yhm3WdGFok)\n",
        "\n",
        "```python\n",
        "# åŒ¯å…¥ç¥ç¶“ç¶²è·¯æ¨¡å‹\n",
        "import torch.nn as nn             \n",
        "\n",
        "# å‰µé€ å‡æ–¹èª¤å·®è¨ˆç®—å·¥å…·\n",
        "criterion = nn.MSELoss()          \n",
        "\n",
        "# è¨ˆç®— batch_x å¾—åˆ° pred_y\n",
        "pred_y = my_model(batch_x)        \n",
        "# è¨ˆç®— pred_y èˆ‡ batch_y çš„å‡æ–¹èª¤å·®\n",
        "loss = criterion(pred_y, batch_y) \n",
        "\n",
        "# ä½¿ç”¨å‘å¾Œå‚³æ’­è¨ˆç®—æ¢¯åº¦\n",
        "loss.backward()                   \n",
        "```\n",
        "\n",
        "å¸¸è¦‹çš„ç›®æ¨™å‡½æ•¸åŒ…å«ï¼š\n",
        "\n",
        "|ç›®æ¨™å‡½æ•¸|åç¨±|\n",
        "|-|-|\n",
        "|`torch.nn.MSELoss`|å‡æ–¹èª¤å·®ï¼ˆMean Square Errorï¼‰|\n",
        "|`torch.nn.CrossEntropyLoss`|äº¤å‰ç†µï¼ˆCross Entropyï¼‰|\n",
        "|`torch.nn.BCELoss`|äºŒå…ƒäº¤å‰ç†µï¼ˆBinary Cross Entropyï¼‰|\n",
        "|`torch.nn.NLLLoss`|è² å°æ•¸ä¼¼ç„¶ï¼ˆNegative Log Likelihoodï¼‰|\n",
        "\n",
        "## MSELoss \n",
        "- [PyTorch Documentation](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
        "<img src=\"https://i.imgur.com/dqKaK25.png\"  width=\"400\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LdZoW-abr-N",
        "outputId": "cbd3f16c-31cd-4ced-f4c4-1772b491c74f"
      },
      "outputs": [],
      "source": [
        "# ç›®æ¨™å‡½æ•¸\n",
        "\n",
        "# å‰µé€ å‡æ–¹èª¤å·®è¨ˆç®—å·¥å…·\n",
        "criterion = nn.MSELoss()                \n",
        "# é€é my_data_loader å°è³‡æ–™é›† my_dataset é€²è¡ŒæŠ½æ¨£\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # è‡ªå‹•å‘¼å« forward è¨ˆç®— batch_x å¾—åˆ° pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # è¨ˆç®— pred_y èˆ‡ batch_y çš„å‡æ–¹èª¤å·®\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    print(loss)\n",
        "    \n",
        "    # ä½¿ç”¨å‘å¾Œå‚³æ’­è¨ˆç®—æ¢¯åº¦\n",
        "    loss.backward()                     "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "igh-yFNr1K3o"
      },
      "source": [
        "### æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰\n",
        "\n",
        "![Gradient Descent](https://img-blog.csdnimg.cn/20181110102438617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpX2tfeQ==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "ä½¿ç”¨ `torch.optim` ä¸­çš„ä¸åŒçš„æœ€ä½³åŒ–ç­–ç•¥é€²è¡Œæ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰æ¼”ç®—æ³•ï¼š\n",
        "\n",
        "$$\n",
        "\\theta_t = \\theta_{t - 1} - \\text{lr} \\cdot \\nabla \\mathcal{L}(x)\n",
        "$$\n",
        "\n",
        "é€²è¡Œæœ€ä½³åŒ–æ™‚éœ€è¦æ³¨æ„ä»¥ä¸‹äº‹é …ï¼š\n",
        "\n",
        "- å‰µé€ æœ€ä½³åŒ–å·¥å…·æ™‚å¿…é ˆæŒ‡å®šå“ªäº›åƒæ•¸è¢«æ›´æ–°\n",
        "    - ä½¿ç”¨ `model.parameters()` å–å¾—æ¨¡å‹ä¸­æ‰€æœ‰å¯ä»¥è¢«æ›´æ–°çš„åƒæ•¸\n",
        "    - å­¸ç¿’ç‡ï¼ˆLearning Rateï¼‰è² è²¬æ±ºå®šæ¨¡å‹åƒæ•¸æ›´æ–°çš„å¹…åº¦ï¼Œå¯ä»¥é€é `lr` åƒæ•¸è¨­å®š\n",
        "- å¿…é ˆå…ˆè¨ˆç®—èª¤å·®ä¸¦ä¸”é€éèª¤å·®å‘å¾Œå‚³æ’­ï¼ˆ`loss.backward()`ï¼‰ï¼Œæ‰èƒ½åŸ·è¡Œæ¢¯åº¦ä¸‹é™æ›´æ–°åƒæ•¸ï¼ˆ`optimizer.step()`ï¼‰\n",
        "\n",
        "#### Stochastic Gradient Descent (SGD)\n",
        "<img src=\"https://www.samvitjain.com/blog/assets/gradient-descent/comparison.png\"  width=\"350\">\n",
        "\n",
        "- SGD çš„æ ¸å¿ƒæ¦‚å¿µå°±æ˜¯ç”¨ å°batch è¨“ç·´ï¼Œ GD å¯ä»¥èªªå°±æ˜¯ batch_size = dataset_size çš„ç‹€æ…‹ã€‚\n",
        "- SGD æ¯” GD æ›´é©åˆç”¨æ–¼æ·±åº¦å­¸ç¿’æ¨¡å‹çš„è¨“ç·´ï¼Œå› ç‚ºå®ƒå¯ä»¥æ›´å¿«åœ°æ”¶æ–‚ã€æ›´æœ‰æ•ˆåœ°è™•ç†å¤§è³‡æ–™é›†ï¼Œä¸¦ä¸”å› ç‚ºå…·æœ‰æ›´å¤§çš„éš¨æ©Ÿæ€§æ›´å®¹æ˜“è·³å‡º local minimaã€‚ä¸éï¼ŒSGD ä¹Ÿæœ‰ä¸€äº›ç¼ºé»ï¼Œä¾‹å¦‚å¯èƒ½æœƒå‡ºç¾æ”¶æ–‚ä¸ç©©å®šã€éœ‡ç›ªç­‰å•é¡Œã€‚ç‚ºäº†è§£æ±ºé€™äº›å•é¡Œï¼Œæœ‰è¨±å¤šåŸºæ–¼SGDçš„æ”¹é€²ç®—æ³•è¢«æå‡ºï¼Œä¾‹å¦‚ Momentumã€Adagradã€RMSpropã€Adam ç­‰ã€‚\n",
        "- [(PyTorch Documentation) Stochastic Gradient Descent](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)\n",
        "- [NTU EE ML Lecture 3-1: Gradient Descent](https://www.youtube.com/watch?v=yKKNr-QKz2Q&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqC3vN9gbr-N"
      },
      "outputs": [],
      "source": [
        "# æœ€ä½³åŒ–\n",
        "\n",
        "# åŒ¯å…¥è¨ˆç®—æ¢¯åº¦ä¸‹é™æ¼”ç®—æ³•çš„å·¥å…·\n",
        "from torch.optim import SGD             \n",
        "\n",
        "# å‰µé€ è¨ˆç®—éš¨æ©Ÿæ¢¯åº¦ä¸‹é™çš„å·¥å…·\n",
        "optimizer = SGD(                        \n",
        "    # è¨­å®šè¨ˆç®—æ¢¯åº¦ä¸‹é™çš„ç›®æ¨™\n",
        "    my_model.parameters(),              \n",
        "    # è¨­å®šå­¸ç¿’ç‡\n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# é€é my_data_loader å°è³‡æ–™é›† my_dataset é€²è¡ŒæŠ½æ¨£\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # è‡ªå‹•å‘¼å« forward è¨ˆç®— batch_x å¾—åˆ° pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # è¨ˆç®— pred_y èˆ‡ batch_y çš„å‡æ–¹èª¤å·®\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    # ä½¿ç”¨å‘å¾Œå‚³æ’­è¨ˆç®—æ¢¯åº¦\n",
        "    loss.backward()\n",
        "    \n",
        "    # ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°æ¨¡å‹åƒæ•¸\n",
        "    optimizer.step()\n",
        "    \n",
        "    # æ¸…ç©ºè¨ˆç®—éå¾Œçš„æ¢¯åº¦å€¼\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1tspVHbr-N",
        "outputId": "51d33a4c-331e-4c32-82bc-471739c4065b"
      },
      "outputs": [],
      "source": [
        "# é©—è­‰\n",
        "\n",
        "# å¦‚æœæœ‰å¯ç”¨ GPU æ™‚æ¡ç”¨ GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# è‹¥ç„¡ GPU å¯ç”¨å‰‡ä½¿ç”¨ CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# å‰µé€ è¨“ç·´è³‡æ–™é›†\n",
        "train_dataset = MyDataset(1000)         \n",
        "# å‰µé€ æ¸¬è©¦è³‡æ–™é›†\n",
        "test_dataset = MyDataset(500)           \n",
        "\n",
        "# è¨­å®šè¶…åƒæ•¸\n",
        "\n",
        "# è¨­å®šæ¯æ¬¡æŠ½æ¨£çš„æ•¸é‡\n",
        "batch_size = 50                         \n",
        "# è¨­å®šè³‡æ–™é›†ç¸½è¨“ç·´æ¬¡æ•¸\n",
        "n_epoch = 5                          \n",
        "# è¨­å®šéš±è—å±¤ç¶­åº¦\n",
        "hid_dim = 100                            \n",
        "\n",
        "# å‰µé€  DataLoader å¯¦ä¾‹\n",
        "train_data_loader = DataLoader(         \n",
        "    # å°è³‡æ–™é›† train_dataset é€²è¡ŒæŠ½æ¨£\n",
        "    train_dataset,                      \n",
        "    # è¨­å®šæ¯æ¬¡æŠ½æ¨£çš„æ•¸é‡\n",
        "    batch_size=batch_size,              \n",
        "    # è¨­å®šéš¨æ©ŸæŠ½æ¨£\n",
        "    shuffle=True,                       \n",
        "    # æŒ‡å®šæ ¼å¼åŒ–çš„æ–¹æ³•\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "# å‰µé€  DataLoader å¯¦ä¾‹\n",
        "test_data_loader = DataLoader(          \n",
        "    test_dataset,                       \n",
        "    batch_size=batch_size,              \n",
        "    shuffle=True,                       \n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# å‰µé€  MyModel æ¨¡å‹å¯¦ä¾‹\n",
        "model = MyModel(                        \n",
        "    # è¨­å®šè¼¸å…¥å±¤ç¶­åº¦\n",
        "    in_dim=1,                           \n",
        "    # è¨­å®šéš±è—å±¤ç¶­åº¦\n",
        "    hid_dim=hid_dim,                    \n",
        "    # è¨­å®šè¼¸å‡ºå±¤ç¶­åº¦\n",
        "    out_dim=1                           \n",
        ")\n",
        "# å°‡æ¨¡å‹æ¬ç§»è‡³ GPU\n",
        "model = model.to(device)                \n",
        "\n",
        "# å‰µé€ å‡æ–¹èª¤å·®è¨ˆç®—å·¥å…·\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# å‰µé€ è¨ˆç®—éš¨æ©Ÿæ¢¯åº¦ä¸‹é™çš„å·¥å…·\n",
        "optimizer = SGD(                        \n",
        "    model.parameters(),                 \n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# ç¸½å…±è¨“ç·´ n_epoch æ¬¡\n",
        "for epoch in range(n_epoch):            \n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        # å°‡è¨“ç·´è³‡æ–™æ¬ç§»è‡³ GPU\n",
        "        batch_x = batch_x.to(device)    \n",
        "        # å°‡è¨“ç·´è³‡æ–™æ¨™è¨˜æ¬ç§»è‡³ GPU\n",
        "        batch_y = batch_y.to(device)    \n",
        "        \n",
        "        # è‡ªå‹•å‘¼å« forward è¨ˆç®— batch_x å¾—åˆ° pred_y\n",
        "        pred_y = model(batch_x)  # shape: (batch_size, 1)      \n",
        "        # è¨ˆç®— pred_y (é æ¸¬æ¨™è¨˜ï¼‰èˆ‡ batch_y ï¼ˆçœŸå¯¦æ¨™è¨˜ï¼‰çš„å‡æ–¹èª¤å·®\n",
        "        loss = criterion(pred_y, batch_y) \n",
        "        \n",
        "        # ä½¿ç”¨å‘å¾Œå‚³æ’­è¨ˆç®—æ¢¯åº¦\n",
        "        loss.backward()                 \n",
        "        # ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°æ¨¡å‹åƒæ•¸\n",
        "        optimizer.step()\n",
        "        # æ¸…ç©ºè¨ˆç®—éå¾Œçš„æ¢¯åº¦å€¼\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # æ­¤å€å¡Šä¸æœƒè¨ˆç®—æ¢¯åº¦\n",
        "    with torch.no_grad():               \n",
        "        # çµ±è¨ˆè¨“ç·´è³‡æ–™èª¤å·®\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in train_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(train_data_loader)\n",
        "        \n",
        "        print('Epoch {}, training loss: {}'.format(epoch, total_loss))\n",
        "        \n",
        "        # çµ±è¨ˆæ¸¬è©¦è³‡æ–™èª¤å·®\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in test_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(test_data_loader)\n",
        "            \n",
        "        print('Epoch {}, testing loss: {}'.format(epoch, total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "JkmZGlVEbr-O",
        "outputId": "cdebfe36-079d-4e4f-a458-0b29bd72d253"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # ç•«å‡ºè¨“ç·´è³‡æ–™ç­”æ¡ˆåˆ†ä½ˆ\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # ç•«å‡ºè¨“ç·´è³‡æ–™é æ¸¬åˆ†ä½ˆ\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "        \n",
        "    plt.title('Training data performance')\n",
        "    plt.show()\n",
        "    \n",
        "    for batch_x, batch_y in test_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # ç•«å‡ºæ¸¬è©¦è³‡æ–™ç­”æ¡ˆåˆ†ä½ˆ\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # ç•«å‡ºæ¸¬è©¦è³‡æ–™é æ¸¬åˆ†ä½ˆ\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "    \n",
        "    plt.title('Testing data performance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMbkzFUU1S2K"
      },
      "source": [
        "### æ¸¬è©¦\n",
        "\n",
        "æ·±åº¦å­¸ç¿’æ¨¡å‹åœ¨è¨“ç·´æ™‚æœƒè‡ªå‹•è¨ˆç®—æ¢¯åº¦ï¼Œè‹¥æ–¼åˆ†ææ¨¡å‹åœ¨ç›®æ¨™å‡½æ•¸çš„è¡¨ç¾æ™‚ä¸æƒ³èŠ±å¤šé¤˜è³‡æºè¨ˆç®—æ¢¯åº¦å¯ä»¥ä½¿ç”¨ `with torch.no_grad():`ï¼š\n",
        "\n",
        "### å„²å­˜ & è¼‰å…¥æ¨¡å‹\n",
        "\n",
        "ä½¿ç”¨ `torch.save()` é…åˆ `model.state_dict()` å„²å­˜è¨“ç·´å¾Œçš„æ¨¡å‹åƒæ•¸ï¼›\n",
        "ä½¿ç”¨ `model.load_state_dict()` é…åˆ `torch.load()` è¼‰å…¥å„²å­˜çš„è¨“ç·´éçš„æ¨¡å‹åƒæ•¸ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnq25QSFbr-O"
      },
      "outputs": [],
      "source": [
        "# å„²å­˜ & è¼‰å…¥æ¨¡å‹\n",
        "\n",
        "# å„²å­˜æ¨¡å‹åƒæ•¸\n",
        "# torch.save(model.state_dict(), './data/model.ckpt')    \n",
        "# è¼‰å…¥æ¨¡å‹åƒæ•¸\n",
        "# model.load_state_dict(torch.load('./data/model.ckpt')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VHNeeFnbr-O"
      },
      "source": [
        "## ç·´ç¿’\n",
        "\n",
        "### ç·´ç¿’ 1ï¼šèª¿æ•´è¶…åƒæ•¸\n",
        "\n",
        "è«‹è©¦è‘—æ›´æ”¹å‰è¿°ç¯„ä¾‹ä¸­çš„è¶…åƒæ•¸è®“æ¨¡å‹è¡¨ç¾è®Šå¥½ï¼š\n",
        "\n",
        "- å¢åŠ è¨“ç·´æ¬¡æ•¸ `n_epoch`\n",
        "- å¢å¤§å–®ä¸€è¨“ç·´è³‡æ–™æ¬¡æ•¸ `batch_size`\n",
        "- å¢å¤§éš±è—å±¤çš„ç¶­åº¦ `hid_dim`\n",
        "- æ›´æ”¹å•Ÿå‹•å‡½æ•¸ `F.relu`\n",
        "\n",
        "### ç·´ç¿’ 2ï¼šåŠ æ·±æ¨¡å‹\n",
        "\n",
        "è«‹è©¦è‘—æ›´æ”¹å‰è¿°ç¯„ä¾‹ä¸­çš„æ¨¡å‹æ·±åº¦è®“æ¨¡å‹è¡¨ç¾è®Šå¥½ï¼š\n",
        "\n",
        "- å¢åŠ  1 å€‹æˆ–å¤šå€‹ `nn.Linear`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ç°¡å–®çš„æ©Ÿå™¨å­¸ç¿’ä»»å‹™ç·´ç¿’\n",
        "- MNIST è³‡æ–™é›†ï¼šæ‰‹å¯«æ•¸å­—åœ–åƒåˆ†é¡ä»»å‹™ (Image Classification)\n",
        "  - ![](https://thumbs.gfycat.com/AdorableJoyfulLemming-max-1mb.gif)\n",
        "  - MNIST ä¸€ç­† data $\\in \\mathbb{R}^{784}$ ï¼ˆ784 ç¶­çš„ feature vectorï¼‰\n",
        "  - [datahacker/cnn/#005 PyTorch - Convolutional Neural Network on MNIST Handwritten Digit Recognition in PyTorch 1.3.ipynb](https://github.com/maticvl/dataHacker/blob/master/CNN/%23005%20PyTorch%20-%20Convolutional%20Neural%20Network%20on%20MNIST%20Handwritten%20Digit%20Recognition%20in%20PyTorch%201.3.ipynb)\n",
        "- Kaggle Titanic Survival Prediction (Feature Classification)\n",
        "    - [Example Notebook: Introduction to Pytorch (a very gentle start)](https://www.kaggle.com/code/frtgnn/introduction-to-pytorch-a-very-gentle-start)\n",
        "- Real-and-Fake Text Classification (Text Classifcation)\n",
        "    - [A step-by-step guide: LSTM Text Classification Using Pytorch](https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0)\n",
        "- åˆ†é¡å•é¡Œæ˜¯æœ€ç°¡å–®ä¹Ÿæ˜¯æœ€æ ¸å¿ƒçš„ï¼Œæ‰€æœ‰ä»»å‹™ï¼ˆæ–‡å­—ç”Ÿæˆ text-generationï¼Œæ–‡å­—ç¿»è­¯ translationï¼Œå•ç­” QAï¼Œåºåˆ—æ¨™æ³¨ sequence labeling ç­‰ç­‰ï¼‰å…¨éƒ½æ˜¯åˆ†é¡å•é¡Œçš„è®Šå½¢è€Œå·²ï¼Œåªæ˜¯å› ç‚ºè³‡æ–™å½¢å¼ä¸åŒï¼Œé€™äº›ä»»å‹™çš„è³‡æ–™å‰è™•ç†èˆ‡æ¨¡å‹é æ¸¬å¾Œè™•ç†æœƒæ¯”åˆ†é¡å•é¡Œæ›´åŠ è¤‡é›œå’Œä¸ç›´è¦ºã€‚å»ºè­°å¾æœ€ç›´è§€çš„åˆ†é¡å•é¡Œä¸‹æ‰‹ç·´ç¿’ã€‚\n",
        "- ä¾‹å­éƒ½æ˜¯æä¾› PyTorch æ¶æ§‹çš„ç¯„ä¾‹ã€‚\n",
        "\n",
        "### æ¨è–¦æ·±åº¦å­¸ç¿’æˆ–è‡ªç„¶èªè¨€è™•ç†å­¸ç¿’è³‡æº\n",
        "  - æ¯”è¼ƒè¼•é¬†å…¥é–€æ·±åº¦å­¸ç¿’çš„æ–¹å¼(è€å¸«å¾ˆå¥½ç¬‘ï¼Œæ•¸å­¸å¾ˆç¡¬ï¼‰ï¼š\n",
        "    - [Hung-Yi Lee 's NTU ML Course Website](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)\n",
        "      - å¦‚æœæƒ³è¦æ›´åŠ ç†Ÿæ‚‰ï¼Œå¯ä»¥å¯«è£¡é¢çš„ä½œæ¥­ï¼ˆå¤§æ¦‚å¯« Regression, Classifcation, CNN, Self-attention, Transformer, BERT å°±èƒ½å¤  cover é€™å ‚èª²éœ€è¦çš„æ‰€æœ‰æŠ€èƒ½ï¼Œæ¯”è¼ƒæœ‰è¶£çš„ä½œæ¥­å¯ä»¥å¯«çœ‹çœ‹ Explainable AIï¼‰ã€‚\n",
        "    - [Hung Yi Lee's Youtube Channel](https://www.youtube.com/@HungyiLeeNTU)\n",
        "  - å²ä¸¹ä½›çš„æ•™ç§‘æ›¸/NTU è³‡è¨Šæ‰€ NLP èª²ç¨‹ç”¨æ›¸ï¼š[Stanford Textbook: Speech & language Processing](https://web.stanford.edu/~jurafsky/slp3/) \n",
        "é€™æœ¬æ›¸å¯«å¾ˆä»”ç´°ï¼Œå¾ sequence models å’Œ word embeddings é–‹å§‹è¬›ï¼Œå¾Œé¢çš„ç« ç¯€æ˜¯åˆ†æˆå¤šå€‹ä¸åŒ NLP ä»»å‹™è¬›è§£ã€‚æƒ³è¦çŸ¥é“ä¸€äº› NLP çš„åŸºç¤ï¼Œè©³è®€ä»¥ä¸‹ç« ç¯€æ‡‰è©²å¯ä»¥æ”¶ç©«è‰¯å¤šï¼š\n",
        "    - 6:\tVector Semantics and Embeddings\t6: Vector Semantics\t[new in this edition]\n",
        "    - 7:\tNeural Networks and Neural Language Models\t7: Neural Networks [new in this edition]\n",
        "    - 9:\tRNNs and LSTMs\t\t[new in this edition]\n",
        "    - 10:\tTransformers and Pretrained Language Models\n",
        "  - Andrew Ng's Machine Learning Resources\n",
        "    - [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models)\n",
        "  - [PyTorch Introduction by NTU EE](https://colab.research.google.com/drive/1Xed5YSpLsLfkn66OhhyNzr05VE89enng#scrollTo=jifMOIcNMTh5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5d79344b50f250bbd6ad2de2adfaeedd1b2740d625477f4cf63f23f68cf7a998"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
