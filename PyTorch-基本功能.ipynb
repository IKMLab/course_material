{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohBsx6xbr-H"
      },
      "source": [
        "# PyTorch-基本功能\n",
        "\n",
        "## 教學目標\n",
        "\n",
        "這份教學的目標是介紹 PyTorch，撰寫深度學習模型的函式庫。\n",
        "\n",
        "## 適用對象\n",
        "\n",
        "已經有基本的機器學習知識，且擁有 python、`numpy`、`matplotlib` 基礎的學生。\n",
        "\n",
        "若沒有先學過 python，請參考 [python-入門語法](./python-入門語法.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `numpy`，請參考 [numpy-基本功能](./numpy-基本功能.ipynb) 教學。\n",
        "\n",
        "若沒有先學過 `matplotlib`，請參考 [matplotlib-資料視覺化](./matplotlib-資料視覺化.ipynb) 教學。\n",
        "\n",
        "## 執行時間\n",
        "\n",
        "本教學全部執行時間約為 4.376506090164185 秒。\n",
        "\n",
        "|測試環境|名稱|\n",
        "|-|-|\n",
        "|主機板|X570 AORUS ELITE|\n",
        "|處理器|AMD Ryzen 7 3700X 8-Core Processor|\n",
        "|記憶體|Kingston KHX3200C16D4/16GX|\n",
        "|硬碟|Seagate ST1000DM003-1ER1|\n",
        "|顯示卡|GeForce RTX 2080|\n",
        "|作業系統|Ubuntu 18.04 LTS|"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDTx3HZbr-I"
      },
      "source": [
        "## 大綱\n",
        "\n",
        "- [簡介](#簡介)\n",
        "- [安裝](#安裝)\n",
        "- 🍓 [張量宣告](#張量宣告)\n",
        "- [張量取值](#張量取值)\n",
        "- [張量運算](#張量運算)\n",
        "- 🍓 [創造張量](#創造張量)\n",
        "- 🍓[高維張量運算](#高維張量運算)\n",
        "- 🍓[維度運算](#維度運算)\n",
        "- 🍓🍓 [使用 GPU 運算](#使用-GPU-運算)\n",
        "- 🍓🍓🍓 [深度學習](#深度學習)\n",
        "- [練習](#練習)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Hk28KHbr-I"
      },
      "source": [
        "## 簡介\n",
        "\n",
        "根據 [PyTorch 官方網站](https://pytorch.org/)（v1.4）：\n",
        "\n",
        "> PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "> \n",
        "> PyTorch 是一個開源的機器學習框架，能夠幫助加速從研究原型到商業應用的轉換過程。\n",
        "\n",
        "![PyTorch usage statistics](https://thegradient.pub/content/images/2019/10/ratio_medium-1.png)\n",
        "\n",
        "根據[統計](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)，PyTorch 在各大機器學習會議使用率逐年上升，使用者選擇 PyTorch 的原因為：\n",
        "\n",
        "- 簡單（Simplicity）\n",
        "    - 使用 `python` 作為介面\n",
        "    - 操作方法與 `numpy` 相似\n",
        "- 好用的介面（Great API）\n",
        "    - 沒有過多的抽象化\n",
        "- 效能（Performance）"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OwS9cuvXbr-I"
      },
      "source": [
        "## 安裝\n",
        "\n",
        "請參考 [PyTorch 官方網站](https://pytorch.org/get-started/locally/#start-locally)，並選擇適合的環境選項與安裝方法。\n",
        "有 GPU 的人請用 `nvidia-smi` 檢查一下 cuda driver 版本，因為最重要的是裝對符合你 cuda driver 的 PyTorch，你才能用 GPU 加速。\n",
        "\n",
        "本教學使用 `pip` 安裝 `torch`，選項如下。\n",
        "|選項|描述|選擇|\n",
        "|-|-|-|\n",
        "|PyTorch Build|請選**穩定版**避免未知錯誤|`Stable(1.4)`|\n",
        "|Your OS|依照**作業系統**來選擇|`Ubuntu`|\n",
        "|Package|安裝 **PyTorch** 使用的方法|`Pip`|\n",
        "|Language|當前執行 **Python** 版本|`Python 3.8.16`|\n",
        "|CUDA|電腦上是否有 **GPU** 且支援 **CUDA 架構**|`12.1`|\n",
        "|GPU|型號|`Nvidia GeForce RTX 3060`|\n",
        "\n",
        "得到以下安裝指令：\n",
        "\n",
        "```sh\n",
        "pip install torch torchvision\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gQuDZD9cKaG",
        "outputId": "fbbfd3d6-78d8-4a37-e9c7-6e3ee556ed23"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8q-VOUcbr-J",
        "outputId": "4ec36342-b15b-44a4-9e43-056826034819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version 2.0.0+cu117\n",
            "GPU-enabled installation? True\n"
          ]
        }
      ],
      "source": [
        "# 匯入 PyTorch 套件\n",
        "# 在 python 中的介面名稱為 torch\n",
        "import torch\n",
        "# 匯入 numpy 與 matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print((\n",
        "    'PyTorch version {}\\n' +\n",
        "    'GPU-enabled installation? {}'\n",
        ").format(\n",
        "    # 確認 torch 的版本\n",
        "    torch.__version__,        \n",
        "    # 確認是否有 GPU 裝置\n",
        "    torch.cuda.is_available() \n",
        "))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOYX-sffjQN"
      },
      "source": [
        "## Torch Tensor\n",
        "程式語言框架通常有其主要的資料型態，像是 numpy 中的 ndarray。在 PyTorch 內則是叫做 tensor（張量）的一種資料型態。PyTorch 的所有操作和 numpy 都很相似，但重要的是 tensor 支援 CUDA 的硬體加速（GPU），使得 GPU 深度學習變得簡單可行。tensor 可以在GPU/CPU上傳輸：只要使用 `tensor.cuda(device_id)`\n",
        "即可以將 tensor 移動到第 `device_id` 個（0-indexed）的 GPU 核心上。或者 `tensor.cpu()`可以將 tensor 移動回到 CPU 上。另外一個更通用的方法是 `tensor.to(device)`。\n",
        "\n",
        "--- \n",
        "### 額外補充\n",
        "#### 什麼是 GPU ？\n",
        "GPU全稱為圖形處理器（Graphics Processing Unit），是一種專門進行繪圖運算工作的微處理器。儘管GPU在遊戲中以3D渲染而聞名，但GPU相較於「傳統的專為通用計算而設計的CPU，具有數百或數千個核心，經過優化，可並行運行大量計算，對運行深度學習和機器學習算法尤其有用。GPU允許某些計算機比傳統CPU上運行相同的計算速度快10-100倍。\n",
        "\n",
        "#### 什麼是CUDA？\n",
        "\n",
        "CUDA全稱為計算統一設備架構（Compute Unified Device Architecture），是NVIDIA（輝達）創建的平行計算平臺和應用程序編程接口模型。CUDA 平臺是一個軟件層，可直接訪問GPU的虛擬指令集和並行計算元素，以執行計算內核。因此，如果我們想利用 GPU 加速運行深度學習算法，那麼 CUDA 就是一個不可或缺的中間層，它代替我們直接和GPU硬體打交道，並對外開放接口。而 PyTorch 則對這層接口再次進行封裝，以方便程式設計人員使用。\n",
        "\n",
        "#### 什麼是cuDNN？\n",
        "\n",
        "cuDNN 全稱為 CUDA 深度神經網絡庫（CUDA Deep Neural Network library），是 NVIDIA 打造的針對深度神經網絡的加速庫，是一個用於深層神經網絡的 GPU 加速庫。如果你要使用 GPU 訓練模型，cuDNN 不是必須的，但一般會採用這個加速庫。\n",
        "\n",
        "### 參考資料\n",
        "- [知乎：什麼是張量？& 深度學習](https://zhuanlan.zhihu.com/p/48982978)\n",
        "- [CUDA 入門, nvidia 公司官方網站](https://blogs.nvidia.com.tw/2020/10/27/cuda-refresher-getting-started-with-cuda/)\n",
        "- [CUDA、cuDNN、pytorch 安装分析](https://blog.csdn.net/weixin_38481963/article/details/105313471) \n",
        "- [NQU Tensor 介紹 slides](https://www.nqu.edu.tw/upload/educsie/attachment/529fa35c91b055e7da3c8dc7a9bc975e.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okJuKPxbr-J"
      },
      "source": [
        "## 張量宣告\n",
        "\n",
        "在 `torch` 中陣列稱為張量（Tensor），創造張量的語法為 `torch.tensor([value1, value2, ...])`。\n",
        "\n",
        "- 每個 `torch.Tensor` 都有不同的**數值型態屬性** `torch.Tensor.dtype`\n",
        "    - 必須透過 `torch.Tensor.dtype` 取得，無法透過 `type()` 取得\n",
        "- 可以指定型態\n",
        "    - 透過參數 `dtype` 指定型態\n",
        "    - 透過 `torch.LongTensor` 創造整數，預設為 `torch.int64`\n",
        "    - 透過 `torch.FloatTensor` 創造浮點數，預設為 `torch.float32`\n",
        "\n",
        "|`torch` 型態|`numpy` 型態|C 型態|範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.int8`|`numpy.int8`|`int_8`|-128~127|\n",
        "|`torch.int16`|`numpy.int16`|`int_16`|-32768~32767|\n",
        "|`torch.int32`|`numpy.int32`|`int_32`|-2147483648~2147483647|\n",
        "|`torch.int64`|`numpy.int64`|`int_64`|-9223372036854775808~9223372036854775807|\n",
        "|`torch.float32`|`numpy.float32`|`float`||\n",
        "|`torch.float64`|`numpy.float64`|`double`||\n",
        "\n",
        "- 每個 `torch.Tensor` 都有**維度屬性** `torch.Size`\n",
        "    - 呼叫 `torch.Tensor.size()` 來取得維度屬性\n",
        "    - `torch.Tensor.size` 本質是 `tuple`\n",
        "    - 張量維度愈高，`len(torch.Tensor.size)` 數字愈大\n",
        "- 可以使用 `torch.Tensor.reshape` 或 `torch.Tensor.view` 進行維度變更\n",
        "    - 變更後的維度必須要與變更前的維度乘積相同\n",
        "    - 變更後的內容為 **shallow copy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KGb8WQKbr-J",
        "outputId": "a05f52cc-4cf6-4ce6-baa0-73ce6a7ce6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n",
            "True\n",
            "torch.int64\n",
            "\n",
            "tensor([1., 2., 3.])\n",
            "True\n",
            "torch.float32\n",
            "\n",
            "torch.int8\n",
            "torch.float64\n",
            "\n",
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# 張量宣告\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t1 = torch.tensor([1, 2, 3])                           \n",
        "# 輸出 Tensor\n",
        "print(t1)                                              \n",
        "# 輸出 True\n",
        "print(type(t1) == torch.Tensor)                        \n",
        "# 輸出 torch.int64\n",
        "print(t1.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t2 = torch.tensor([1., 2., 3.])                        \n",
        "# 輸出 Tensor\n",
        "print(t2)                                              \n",
        "# 輸出 True\n",
        "print(type(t2) == torch.Tensor)                        \n",
        "# 輸出 torch.float32\n",
        "print(t2.dtype)                                        \n",
        "print()\n",
        "\n",
        "# 各種 dtype\n",
        "# 輸出 torch.int8\n",
        "print(torch.tensor([1, 2], dtype=torch.int8).dtype)    \n",
        "# 輸出 torch.int16\n",
        "# ... \n",
        "# 輸出 torch.float64\n",
        "print(torch.tensor([1, 2], dtype=torch.float64).dtype) \n",
        "print()\n",
        "\n",
        "# 宣告 LongTensor 變數 -> 通常 label 會使用這種型態，因為 label 通常是整數，在 torch 訓練的錯誤時可能會看到類似這種錯誤：\n",
        "# RuntimeError: Expected object of scalar type Long but got scalar type Float for argument #2 'target' \n",
        "# 此時就要記得檢查是否有使用到 LongTensor\n",
        "\n",
        "t3 = torch.LongTensor([1, 2, 3])                       \n",
        "# 輸出 torch.int64\n",
        "print(t3.dtype)                                        \n",
        "\n",
        "# 宣告 FloatTensor 變數\n",
        "t4 = torch.FloatTensor([1, 2, 3])                      \n",
        "# 輸出 torch.float32\n",
        "print(t4.dtype)                                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G-IX1n6ckRw",
        "outputId": "fc8560d1-33a5-43da-ac6c-921b87b192da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3.])\n",
            "tensor([[0., 1.],\n",
            "        [2., 3.]])\n"
          ]
        }
      ],
      "source": [
        "# 定義一段 range \n",
        "a = torch.arange(4.)\n",
        "print(a)\n",
        "resa = torch.reshape(a, (2, 2))\n",
        "print(resa)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CaPUOTC7dhxd"
      },
      "source": [
        "## view 和 reshape \n",
        "- 參考[官方網站連結](https://pytorch.org/docs/stable/tensor_view.html)，PyTorch allows a tensor to be a View of an existing tensor. `View` tensor shares the same underlying data with its base tensor. Supporting View avoids explicit data copy, thus allows us to do fast and memory efficient reshaping, slicing and element-wise operations.\n",
        "- ``torch.view(*shape)->Tensor``: Returns a **new tensor** with the same data as the self tensor but of a different shape. The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions $d,d+1,…,d+k$ that satisfy the following contiguity-like condition that $\\forall i = d, ... d+k-1$\n",
        "$$\n",
        "stride[i] = stride[i+1] \\times size[i+1]\n",
        "$$\n",
        "\n",
        "- ``torch.reshape(*shape)->Tensor``: \n",
        "Returns a tensor with the same data and number of elements as self but with the specified shape. This method returns a view if shape is compatible with the current shape. See ``torch.Tensor.view()`` on when it is possible to return a view.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg9RgMObbr-K",
        "outputId": "7ce67e53-f074-4cad-f00f-3958a192bef4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "original shape: torch.Size([4, 3])\n",
            "reshaped to (3,4): tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "Automatic inference that 1st dim is 2: torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "# size 屬性\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t5 = torch.tensor([               \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12],\n",
        "])\n",
        "\n",
        "# 輸出 Tensor\n",
        "print(t5)                         \n",
        "# 輸出 t5.size (4, 3)\n",
        "print(\"original shape:\", t5.size())                  \n",
        "\n",
        "# 重新更改 t5.size\n",
        "print(\"reshaped to (3,4):\", t5.reshape(3, 4))           \n",
        "\n",
        "# automatic inference the 1st dimension\n",
        "print('Automatic inference that 1st dim is 2:', t5.view(-1, 3, 2).size())    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy1L8FOqbr-K"
      },
      "source": [
        "## 張量取值\n",
        "\n",
        "與 `numpy` 語法概念相似。\n",
        "\n",
        "- 使用 `torch.Tensor[位置]` 來取得 `torch.Tensor` 中指定位置的值\n",
        "    - 若為**多個維度**的張量，則使用 `tuple` 來取得指定位置的值\n",
        "    - 若位置為**負數**，則等同於反向取得指定位置的值\n",
        "    - 取出的值會以 `torch.Tensor.dtype` 的形式保留\n",
        "- 使用 `torch.Tensor[起始位置:結束位置]` 來取得 `torch.Tensor` 中的部分**連續**值\n",
        "    - **包含起始位置**的值\n",
        "    - **不包含結束位置**的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用 `torch.Tensor[iterable]`（例如 `list`, `tuple` 等）來取得**多個** `torch.Tensor` 中的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用判斷式來取得 `torch.Tensor` 中的部份資料\n",
        "    - 經由判斷式所得結果也為 `torch.Tensor`\n",
        "    - 判斷式所得結果之 `torch.Tensor.dtype` 為**布林值** `bool`（`True` 或 `False`）\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214IwVJEbr-K",
        "outputId": "daaee408-eeb4-4836-92c5-31eb8a5ffa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2])\n",
            "tensor([3, 4, 5])\n",
            "tensor([6, 7, 8])\n",
            "tensor([6, 7, 8])\n",
            "tensor([ 9, 10, 11])\n",
            "\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor(5)\n",
            "tensor(11)\n",
            "tensor(10)\n",
            "tensor(8)\n"
          ]
        }
      ],
      "source": [
        "# 張量取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t6 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t6 中的第 0 個位置的值 [0, 1, 2]\n",
        "print(t6[0])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [3, 4, 5]\n",
        "print(t6[1])        \n",
        "# 輸出張量 t6 中的第 1 個位置的值 [6, 7, 8]\n",
        "print(t6[2])        \n",
        "# 輸出張量 t6 中的第 -2 個位置的值 [6, 7, 8]\n",
        "print(t6[-2])       \n",
        "# 輸出張量 t6 中的第 -1 個位置的值 [9, 10, 11]\n",
        "print(t6[-1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t6 中的第 [0, 0] 個位置的值 0\n",
        "print(t6[0, 0])     \n",
        "# 輸出張量 t6 中的第 [0, 1] 個位置的值 1\n",
        "print(t6[0, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 1] 個位置的值 4\n",
        "print(t6[1, 1])     \n",
        "# 輸出張量 t6 中的第 [1, 2] 個位置的值 5\n",
        "print(t6[1, 2])     \n",
        "# 輸出張量 t6 中的第 [-1, -1] 個位置的值 11\n",
        "print(t6[-1, -1])   \n",
        "# 輸出張量 t6 中的第 [-1, -2] 個位置的值 10\n",
        "print(t6[-1, -2])   \n",
        "# 輸出張量 t6 中的第 [-2, -1] 個位置的值 8\n",
        "print(t6[-2, -1])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TTmmlRLbr-K",
        "outputId": "4e0a0eee-0766-44c6-badb-1432de18717d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0, 10, 20])\n",
            "tensor([70, 80, 90])\n",
            "tensor([ 0, 10])\n",
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "\n",
            "tensor([[ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 1, 2]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "# 取連續值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t7 = torch.tensor([ \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t7 位置 0, 1, 2 但是不含位置 3 的值 [0, 10, 20]\n",
        "print(t7[0:3])      \n",
        "# 輸出張量 t7 位置 7, 8, 9 的值 [70, 80, 90]\n",
        "print(t7[7:])       \n",
        "# 輸出張量 t7 位置 0, 1 但是不含位置 2 的值 [0, 10]\n",
        "print(t7[:2])       \n",
        "# 輸出張量 t7 所有位置的值 [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "print(t7[:])        \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t8 = torch.tensor([ \n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t8 位置 0, 1, 但是不含位置 2 的值 [[0, 1, 2], [3, 4, 5]]\n",
        "print(t8[0:2])      \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 1, 2, 3 的值 [[3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[1:])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2]]\n",
        "print(t8[:1])       \n",
        "print()\n",
        "\n",
        "# 輸出張量 t8 位置 0 但是不含位置 1 的值 [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t8[:])        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5w2A_hbr-K",
        "outputId": "68f5efa5-01ab-4fd1-93b8-6eae16e59691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0, 20, 40, 60, 80])\n",
            "\n",
            "tensor([10, 30, 50, 70, 90])\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "\n",
            "tensor([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# 使用 iterable 取得多個值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t9 = torch.tensor([        \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t9 中偶數位置的值 [0, 20, 40, 60, 80]\n",
        "print(t9[[0, 2, 4, 6, 8]]) \n",
        "print()\n",
        "# 輸出張量 t9 中奇數位置的值 [10, 30, 50, 70, 90]\n",
        "print(t9[[1, 3, 5, 7, 9]]) \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t10 = torch.tensor([       \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 輸出張量 t10[0] 與 t10[1] 的值 [[1, 2, 3, 4] [5, 6, 7, 8]]\n",
        "print(t10[[0, 1]])         \n",
        "print()\n",
        "# 輸出張量 t10[0, 2] 與 t10[1, 3] 的值 [3, 8]\n",
        "print(t10[[0, 1], [2, 3]]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBfUCkxbr-K",
        "outputId": "13257ce4-76d5-42cb-9b7f-7a45331e1c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([False, False, False, False, False, False,  True,  True,  True,  True])\n",
            "torch.bool\n",
            "tensor([60, 70, 80, 90])\n",
            "tensor([ 0, 20, 40, 60, 80])\n"
          ]
        }
      ],
      "source": [
        "# 判斷式取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t11 = torch.tensor([      \n",
        "    0, 10, 20, 30, 40, \n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出每個值是否大於 50 的 `torch.Tensor`\n",
        "print(t11 > 50)           \n",
        "# 輸出 torch.bool\n",
        "print((t11 > 50).dtype)   \n",
        "# 輸出大於 50 的值 [60, 70, 80, 90]\n",
        "print(t11[t11 > 50])      \n",
        "# 輸出除以 20 餘數為 0 的值 [0, 20, 40, 60, 80]\n",
        "print(t11[t11 % 20 == 0]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x72LPvvtbr-K"
      },
      "source": [
        "## 張量運算\n",
        "\n",
        "### 純量運算（Scalar Operation）\n",
        "\n",
        "對張量內所有數值與單一純量（Scalar）進行相同計算。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`torch.Tensor + scalar`|張量中的每個數值加上 `scalar`|\n",
        "|`torch.Tensor - scalar`|張量中的每個數值減去 `scalar`|\n",
        "|`torch.Tensor * scalar`|張量中的每個數值乘上 `scalar`|\n",
        "|`torch.Tensor / scalar`|張量中的每個數值除以 `scalar`|\n",
        "|`torch.Tensor // scalar`|張量中的每個數值除以 `scalar` 所得之商|\n",
        "|`torch.Tensor % scalar`|張量中的每個數值除以 `scalar` 所得之餘數|\n",
        "|`torch.Tensor ** scalar`|張量中的每個數值取 `scalar` 次方|\n",
        "\n",
        "### 個別數值運算（Element-wise Operation）\n",
        "\n",
        "若兩個張量想要進行運算，則兩個張量的**維度必須相同**（即兩張量之 `torch.size()` 相同）。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`A + B`|張量 `A` 中的每個數值加上張量 `B` 中相同位置的數值|\n",
        "|`A - B`|張量 `A` 中的每個數值減去張量 `B` 中相同位置的數值|\n",
        "|`A * B`|張量 `A` 中的每個數值乘上張量 `B` 中相同位置的數值|\n",
        "|`A / B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值|\n",
        "|`A // B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之商|\n",
        "|`A % B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之餘數|\n",
        "|`A ** B`|張量 `A` 中的每個數值取張量 `B` 中相同位置的數值之次方|\n",
        "\n",
        "### 個別數值函數運算（Element-wise Functional Operation）\n",
        "\n",
        "若想對張量中的**所有數值**進行**相同函數運算**，必須透過 `torch` 提供的介面進行。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sin`|張量中的每個數值 $x$ 計算 $\\sin(x)$|\n",
        "|`torch.cos`|張量中的每個數值 $x$ 計算 $\\cos(x)$|\n",
        "|`torch.tan`|張量中的每個數值 $x$ 計算 $\\tan(x)$|\n",
        "|`torch.exp`|張量中的每個數值 $x$ 計算 $e^{x}$|\n",
        "|`torch.log`|張量中的每個數值 $x$ 計算 $\\log x$\n",
        "|`torch.ceil`|張量中的每個數值 $x$ 計算 $\\left\\lceil x \\right\\rceil$\n",
        "|`torch.floor`|張量中的每個數值 $x$ 計算 $\\left\\lfloor x \\right\\rfloor$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR54kMUdbr-L",
        "outputId": "be0f0dd1-9f3c-46ea-f7b9-3b97415423e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  0,  10,  20],\n",
            "        [ 30,  40,  50],\n",
            "        [ 60,  70,  80],\n",
            "        [ 90, 100, 110]])\n",
            "\n",
            "tensor([[  5,  15,  25],\n",
            "        [ 35,  45,  55],\n",
            "        [ 65,  75,  85],\n",
            "        [ 95, 105, 115]])\n",
            "\n",
            "tensor([[ -4,   6,  16],\n",
            "        [ 26,  36,  46],\n",
            "        [ 56,  66,  76],\n",
            "        [ 86,  96, 106]])\n",
            "\n",
            "tensor([[  0,  30,  60],\n",
            "        [ 90, 120, 150],\n",
            "        [180, 210, 240],\n",
            "        [270, 300, 330]])\n",
            "\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "tensor([[0, 3, 6],\n",
            "        [2, 5, 1],\n",
            "        [4, 0, 3],\n",
            "        [6, 2, 5]])\n",
            "\n",
            "tensor([[    0,   100,   400],\n",
            "        [  900,  1600,  2500],\n",
            "        [ 3600,  4900,  6400],\n",
            "        [ 8100, 10000, 12100]])\n"
          ]
        }
      ],
      "source": [
        "# 純量運算(Scalar Operation)\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t12 = torch.tensor([ \n",
        "    [0, 10, 20],\n",
        "    [30, 40, 50],\n",
        "    [60, 70, 80],\n",
        "    [90, 100, 110],\n",
        "])\n",
        "\n",
        "# 輸出張量 t12\n",
        "print(t12)           \n",
        "print()\n",
        "# 對張量 t12 所有數值加 5\n",
        "print(t12 + 5)       \n",
        "print()\n",
        "# 對張量 t12 所有數值減 4\n",
        "print(t12 - 4)       \n",
        "print()\n",
        "# 對張量 t12 所有數值乘 3\n",
        "print(t12 * 3)       \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10\n",
        "print(t12 / 10)      \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 10 所得整數部份\n",
        "print(t12 // 10)     \n",
        "print()\n",
        "# 對張量 t12 所有數值除以 7 得到餘數\n",
        "print(t12 % 7)       \n",
        "print()\n",
        "# 對張量 t12 所有數值取 2 次方\n",
        "print(t12 ** 2)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0xQnAE0br-L",
        "outputId": "15ee2e34-64e9-4f31-b6eb-145ce11aac74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7, 7, 7],\n",
            "        [7, 7, 7]])\n",
            "\n",
            "tensor([[-5, -3, -1],\n",
            "        [ 1,  3,  5]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 個別數值運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t13 = torch.tensor([ \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t14 = torch.tensor([ \n",
        "    [6, 5, 4],\n",
        "    [3, 2, 1]\n",
        "])\n",
        "\n",
        "# 張量相加\n",
        "print(t13 + t14)     \n",
        "print()\n",
        "# 張量相減\n",
        "print(t13 - t14)     \n",
        "print()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9af-M7xux8i"
      },
      "source": [
        "\n",
        "**Q: 有辦法做這個效果嗎？**\n",
        "\n",
        "```\n",
        "F(v) = (f(v_1),f(v_2),f(v_3),…,f(v_n))\n",
        "```\n",
        "Ans: 沒辦法提供一個可以直接輸入 f() 的函數，如果 f 能夠被 rewritten into torch.cos(), torch.sin() 等函數的組合就可以平行做 element-wise operation。\n",
        "- [Can we do an element-wise any function similar to map()](https://discuss.pytorch.org/t/apply-a-function-similar-to-map-on-a-tensor/51088)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GenMDYK4br-L",
        "outputId": "0c79e347-6861-4d68-af5d-12c23500b19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  7.0711e-01,  1.0000e+00,  7.0711e-01],\n",
            "        [-8.7423e-08, -7.0711e-01, -1.0000e+00, -7.0711e-01]])\n",
            "\n",
            "tensor([[ 1.0000e+00,  7.0711e-01, -4.3711e-08, -7.0711e-01],\n",
            "        [-1.0000e+00, -7.0711e-01,  1.1925e-08,  7.0711e-01]])\n",
            "\n",
            "tensor([[ 0.0000e+00,  1.0000e+00, -2.2877e+07, -1.0000e+00],\n",
            "        [ 8.7423e-08,  1.0000e+00, -8.3858e+07, -1.0000e+00]])\n",
            "\n",
            "tensor([[  2.7183,   7.3891,  20.0855],\n",
            "        [ 54.5981, 148.4132, 403.4288]])\n",
            "\n",
            "tensor([[0.0000, 0.6931, 1.0986],\n",
            "        [1.3863, 1.6094, 1.7918]])\n",
            "\n",
            "tensor([[0., 1., 2.],\n",
            "        [2., 2., 2.]])\n",
            "\n",
            "tensor([[0., 0., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# 個別數值函數運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t15 = torch.tensor([               \n",
        "    [0,     np.pi / 4,     np.pi / 2,     np.pi / 4 * 3],\n",
        "    [np.pi, np.pi / 4 * 5, np.pi / 2 * 3, np.pi / 4 * 7]\n",
        "])\n",
        "\n",
        "# 張量所有數值計算 sine\n",
        "print(torch.sin(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 cosine\n",
        "print(torch.cos(t15))              \n",
        "print()\n",
        "# 張量所有數值計算 tangent\n",
        "print(torch.tan(t15))              \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t16 = torch.tensor([               \n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "])\n",
        "\n",
        "# 張量所有數值取指數\n",
        "print(torch.exp(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數\n",
        "print(torch.log(t16))              \n",
        "print()\n",
        "# 張量所有數值取對數後無條件進位\n",
        "print(torch.ceil(torch.log(t16)))  \n",
        "print()\n",
        "# 張量所有數值取對數後無條件捨去\n",
        "print(torch.floor(torch.log(t16))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqQy9aOrdyw",
        "outputId": "51511ac1-3fa5-4f21-865a-f15de0cd19c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 6, 10, 12],\n",
            "        [12, 10,  6]])\n",
            "\n",
            "tensor([[0.1667, 0.4000, 0.7500],\n",
            "        [1.3333, 2.5000, 6.0000]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [1, 2, 6]])\n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 1, 0]])\n",
            "\n",
            "tensor([[ 1, 32, 81],\n",
            "        [64, 25,  6]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t13 = torch.tensor([ \n",
        "#     [1, 2, 3],\n",
        "#     [4, 5, 6]\n",
        "# ])\n",
        "\n",
        "# # 宣告 Tensor 變數\n",
        "# t14 = torch.tensor([ \n",
        "#     [6, 5, 4],\n",
        "#     [3, 2, 1]\n",
        "# ])\n",
        "\n",
        "\n",
        "# 張量相乘\n",
        "print(t13 * t14)     \n",
        "print()\n",
        "# 張量相除\n",
        "print(t13 / t14)     \n",
        "print()\n",
        "# 張量相除取商\n",
        "print(t13 // t14)    \n",
        "print()\n",
        "# 張量相除取餘數\n",
        "print(t13 % t14)     \n",
        "print()\n",
        "# 張量 A 取張量 B 次方\n",
        "print(t13 ** t14)\n",
        "# res[0][0] = A[0][0]**B[0][0]\n",
        "# res[0][1] = A[0][1]**B[0][1]\n",
        "# ...\n",
        "# res[i][j] = A[i][j]**B[i][j]\n",
        "# 0 <= i < 2\n",
        "# 0 <= j < 3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnh-f7nOXZsV",
        "outputId": "92323936-2bf9-4ee4-f137-85a73bfa45d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1])\n",
            "tensor([[0.4265, 2.2785, 1.5132, 7.3427, 2.6684],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
            "torch.Size([2, 5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[2], [1]])\n",
        "print(a.size())         # a shape: (2, 1) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "\n",
        "try:\n",
        "  print(y:=a**b)\n",
        "  # a, b 雖然 size mismatch，但適用張量自動擴充的條件3\n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8zfKUqcdHjO",
        "outputId": "65f69658-9077-47d8-af76-59011d53735d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 5])\n",
            "Error Message: The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[2,5], [1,4]])\n",
        "print(a.size())         # a shape: (2, 2) \n",
        "b = torch.randn((2,5))  # b shape: (2, 5)\n",
        "print(b.size())\n",
        "try:\n",
        "  print(y:=a**b) \n",
        "  print(y.shape)\n",
        "except Exception as e:\n",
        "  print('Error Message:', e)\n",
        "  # 從最後一個維度開始比較，如果有任何維度無法滿足條件，則得到 error "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUbDIOiv4Uk"
      },
      "source": [
        "\n",
        "### 🚧 **張量自動擴充（Broadcasting)**\n",
        "\n",
        "若張量 `A` 的維度為 `(a1, a2, ..., an)`（即 `A.size() == (a1, a2, ..., an)`），則張量 `B` 在滿足以下其中一種條件時即可與張量 `A` 進行運算：\n",
        "\n",
        "- 張量 `B` 與張量 `A` 維度完全相同（即 `B.size() == (a1, a2, ..., an)`）\n",
        "- 張量 `B` 為純量（即 `B.size() == (1,)`）\n",
        "- 張量 `B` 的維度為 `(b1, b2, ..., bn)`，若 `ai != bi`，則 `ai == 1` 或 `bi == 1`\n",
        "    - 從**最後**一個維度開始比較\n",
        "    - 如果有任何一個維度無法滿足前述需求，則會得到 `ValueError`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6pu71GVbr-L",
        "outputId": "379f17c1-8e58-416b-a124-534eb3604055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 2])\n",
            "torch.Size([2, 3, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 張量自動擴充\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t17 = torch.tensor([ \n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "    ],\n",
        "    [\n",
        "        [7, 8],\n",
        "        [9 ,10],\n",
        "        [11, 12]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t18 = torch.tensor([ \n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]\n",
        "    ],\n",
        "    [\n",
        "        [2],\n",
        "        [2],\n",
        "        [2]\n",
        "    ],\n",
        "])\n",
        "\n",
        "# 輸出張量 t17 維度\n",
        "print(t17.size())    \n",
        "# 輸出張量 t18 維度\n",
        "print(t18.size())    \n",
        "print()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ryiNnF9wDOr",
        "outputId": "49c0c912-b68d-4ac4-db99-6d22f6e7c9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2,  4],\n",
            "         [ 6,  8],\n",
            "         [10, 12]],\n",
            "\n",
            "        [[14, 16],\n",
            "         [18, 20],\n",
            "         [22, 24]]])\n",
            "\n",
            "tensor([[[ 2,  3],\n",
            "         [ 4,  5],\n",
            "         [ 6,  7]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [11, 12],\n",
            "         [13, 14]]])\n"
          ]
        }
      ],
      "source": [
        "# 張量 t17 與張量 t17 維度相同，所以可以直接運算\n",
        "print(t17 + t17)     \n",
        "print()\n",
        "# 張量 t17 與張量 t18 可以擴充成相同維度，所以可以運算\n",
        "print(t17 + t18)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdmIDslGbr-L"
      },
      "source": [
        "## 創造張量\n",
        "\n",
        "### 賦值（Assignment）\n",
        "\n",
        "使用 `=` 賦與指定位置數值。可以使用 `iterable` 一次指定多個位置。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`=`|賦值|\n",
        "|`+=`|進行加法後賦值|\n",
        "|`-=`|進行減法後賦值|\n",
        "|`*=`|進行乘法後賦值|\n",
        "\n",
        "### 隨機（Random）\n",
        "\n",
        "創造出新的張量，所有數值皆為**隨機決定**，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|備註|\n",
        "|-|-|-|-|\n",
        "|`torch.empty`|創造隨機未初始化張量|已確認維度，尚未確認數值|無法控制隨機|\n",
        "|`torch.rand`|創造隨機浮點數張量，並符合均勻分佈|需要隨機浮點數時|透過均勻分佈決定亂數，範圍介於 0 到 1之間|\n",
        "|`torch.randn`|創造隨機浮點數張量，並符合常態分佈|需要符合常態分佈的隨機浮點數時|透過常態分佈決定亂數，$\\mu = 0$ 且 $\\sigma = 1$|\n",
        "|`torch.randint`|創造隨機整數張量|需要隨機整數時|透過均勻分佈決定亂數，可以控制隨機範圍|\n",
        "\n",
        "### 指定數值（Filled In）\n",
        "\n",
        "**快速創造**擁有特定數值的張量，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|\n",
        "|-|-|-|\n",
        "|`torch.zeros`|創造指定維度大小的張量，所有數值初始化為 0|快速初始化|\n",
        "|`torch.zeros_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 0|複製張量並初始化|\n",
        "|`torch.ones`|創造指定維度大小的張量，所有數值初始化為 1|快速初始化|\n",
        "|`torch.ones_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 1|複製張量並初始化|\n",
        "|`torch.full`|創造指定維度大小的張量，所有數值初始化為指定數值|快速初始化|\n",
        "|`torch.full_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為指定數值|複製張量並初始化|\n",
        "|`torch.eye`|創造單位矩陣|矩陣微分|\n",
        "|`torch.arange`|列舉數字|等同於 `list(range(value))`|\n",
        "\n",
        "### 從 numpy 轉換\n",
        "\n",
        "可以使用 `torch.tensor()` 將 `numpy.ndarray` 轉換成 `torch.Tensor`；\n",
        "使用 `torch.numpy()` 將 `torch.Tensor` 轉換成 `numpy.ndarray`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvxSd3X1br-L",
        "outputId": "99dc0132-e0ca-4054-8228-691b67b01261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1995, 1995, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10, 1995],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1995,   10,   12],\n",
            "        [   4,    5,    6],\n",
            "        [   7,   12,    9],\n",
            "        [  10,   11,   12]])\n"
          ]
        }
      ],
      "source": [
        "# 賦值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t19 = torch.tensor([     \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 0 的所有數值改成 1995\n",
        "t19[0] = 1995            \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [0, 1] 的所有數值改成 10\n",
        "t19[0, 1] = 10           \n",
        "print(t19)\n",
        "print()\n",
        "\n",
        "# 將張量 t19 位置 [2, 1] 與 [0, 2] 的所有數值改成 12\n",
        "t19[[2, 0], [1, 2]] = 12 \n",
        "print(t19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LzdLlgbr-L",
        "outputId": "86617d59-d3f7-4d96-a078-62240a2313da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[1996, 1997, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n",
            "tensor([[1996, 1987, 1998],\n",
            "        [   4,    5,    6],\n",
            "        [   7,    8,    9],\n",
            "        [  10,   11,   12]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t20 = torch.tensor([      \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 0 的所有數值加上 1995\n",
        "t20[0] += 1995            \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [0, 1] 的所有數值減掉 10\n",
        "t20[0, 1] -= 10           \n",
        "print(t20)\n",
        "print()\n",
        "\n",
        "# 將張量 t20 位置 [2, 1] 與 [0, 2] 的所有數值乘上 12\n",
        "t20[[2, 0], [1, 2]] *= 12 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2p5aidybr-L",
        "outputId": "8c79bb15-c76b-44b0-f85d-ac06766fa457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0774e+01,  3.0936e-41, -8.1773e+18],\n",
            "        [ 3.0936e-41,  8.6837e-13,  1.3464e+22]])\n",
            "\n",
            "tensor([[0.9734, 0.6480, 0.8377],\n",
            "        [0.5819, 0.6156, 0.7434]])\n",
            "\n",
            "tensor([[5.7088, 5.8234, 2.8850],\n",
            "        [0.0815, 9.0137, 6.7561]])\n",
            "\n",
            "tensor([[ 2.4650, -3.2128, -0.5493],\n",
            "        [ 1.5079, -3.5061,  2.0633]])\n",
            "\n",
            "tensor([[0.3261, 0.1548, 0.4862],\n",
            "        [0.1406, 0.3409, 0.0135]])\n",
            "\n",
            "tensor([[ 0, -5, -4],\n",
            "        [ 1, -3,  0]])\n"
          ]
        }
      ],
      "source": [
        "# 隨機\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為無法控制範圍的浮點\n",
        "print(torch.empty((2, 3)))               \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 1 之間的浮點\n",
        "print(torch.rand(2, 3))                  \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 10 之間的浮點\n",
        "print(torch.rand(2, 3) * 10)             \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.rand(2, 3) * 10 - 5)         \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，分佈為平均值為 0 標準差為 1 的常態分佈\n",
        "print(torch.randn(2, 3))                 \n",
        "print()                                  \n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.randint(-5, 5, size=(2, 3))) \n",
        "                                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmziKBTmbr-L",
        "outputId": "e573b226-6f80-4367-e988-6473282df5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "tensor([[1, 1, 1, 1],\n",
            "        [1, 1, 1, 1],\n",
            "        [1, 1, 1, 1]])\n",
            "\n",
            "tensor([[420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420],\n",
            "        [420, 420, 420, 420, 420, 420]])\n",
            "\n",
            "tensor([[69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69],\n",
            "        [69, 69, 69, 69, 69, 69]])\n"
          ]
        }
      ],
      "source": [
        "# 指定數值\n",
        "# 創造維度為 (2, 3) 的張量，並初始化為 0\n",
        "print(torch.zeros((2, 3)))      \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t21 = torch.tensor([            \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "# 複製張量 t21 的維度，創造出新的張量，並初始化為 0\n",
        "print(torch.zeros_like(t21))    \n",
        "print()\n",
        "\n",
        "# 創造維度為 (3, 4) 的張量，並初始化為 1\n",
        "print(torch.ones((3, 4)))       \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t22 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "# 複製張量 t22 的維度，創造出新的張量，並初始化為 1\n",
        "# like 的概念就是「模仿我丟給你的這個 tensor 的維度」\n",
        "print(torch.ones_like(t22))     \n",
        "print()\n",
        "\n",
        "# 創造維度為 (5, 6) 的張量，並初始化為 420\n",
        "print(torch.full((5, 6), 420))  \n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t23 = torch.tensor([            \n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "    [7, 8, 9, 10, 11, 12],\n",
        "    [13, 14, 15, 16, 17, 18],\n",
        "    [19, 20, 21, 22, 23, 24],\n",
        "    [25, 26, 27, 28, 29, 30]\n",
        "])\n",
        "# 複製張量 t23 的維度，創造出新的張量，並初始化為 69\n",
        "print(torch.full_like(t23, 69)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJgdH-vabr-L",
        "outputId": "ffab6382-383b-4dde-cddb-b4cd1e29b8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "tensor([6, 7, 8])\n",
            "\n",
            "tensor([ 4, 11, 18])\n"
          ]
        }
      ],
      "source": [
        "# 創造 3x3 單位矩陣\n",
        "print(torch.eye(3))           \n",
        "print()\n",
        "\n",
        "# 從 0 列舉至 10，但不包含 10\n",
        "print(torch.arange(10))       \n",
        "print()\n",
        "\n",
        "# 從 6 列舉至 9，但不包含 9\n",
        "print(torch.arange(6, 9))     \n",
        "print()\n",
        "\n",
        "# 從 4 遞增至 20，但不包含 20，每次遞增 7\n",
        "print(torch.arange(4, 20, 7)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkT3EX7br-L",
        "outputId": "16ae7f16-37a4-46b8-d714-99fa73b6999d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original numpy.ndarray: [1. 2. 3.], dtype: float64\n",
            "converted torch.Tensor: tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n",
            "converted numpy.ndarray: [1. 2. 3.], dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 從 numpy 轉換\n",
        "\n",
        "# 宣告 ndarray 變數\n",
        "arr1 = np.array([1., 2., 3.]) \n",
        "# 將 numpy.ndarray 轉換為 torch.Tensor\n",
        "t24 = torch.tensor(arr1)      \n",
        "# 將 torch.Tensor 轉換為 numpy.ndarray\n",
        "arr2 = t24.numpy()            \n",
        "\n",
        "print((\n",
        "    'original numpy.ndarray: {}, dtype: {}\\n' + \n",
        "    'converted torch.Tensor: {}, dtype: {}\\n' +\n",
        "    'converted numpy.ndarray: {}, dtype: {}'\n",
        ").format(\n",
        "    arr1, arr1.dtype,\n",
        "    t24, t24.dtype,\n",
        "    arr2, arr2.dtype\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STyE59Zgbr-M"
      },
      "source": [
        "## 高維張量運算\n",
        "\n",
        "矩陣等同於是維度為 2 的張量。\n",
        "而高維度的張量運算等同於**固定大部分的維度**，只使用**其中的兩個維度進行計算**。\n",
        "\n",
        "### 張量乘法（Tensor Multiplication）\n",
        "\n",
        "令 $A$ 與 $B$ 為兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$, $B.\\text{size}() = (b_1, b_2, ..., b_{n - 1}, b_n)$。定義 $A \\times B$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "a_i &= b_i \\forall i \\in \\{1, \\dots, n - 2\\} \\\\\n",
        "a_n &= b_{n - 1} \\\\\n",
        "(A \\times B).\\text{size}() &= (d_1, d_2, \\dots, d_{n - 2}, a_{n - 1}, b_n) \\\\\n",
        "&, \\text{where } d_i = a_i = b_i \\forall i \\in \\{1, 2, \\dots, n - 2\\} \\\\\n",
        "(A \\times B)_{d_1, d_2, \\dots, d_{n - 2}, i, j} &=\n",
        "\\begin{cases}\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{i, k} \\times B_{k, j} & \\text{if } n = 2 \\\\\n",
        "\\sum_{k = 1}^{b_{n - 1}} A_{d_1, d_2, \\dots, d_{n - 2}, i, k} \\times B_{d_1, d_2, \\dots, d_{n - 2}, k, j} & \\text{if } n > 2\n",
        "\\end{cases} \\\\\n",
        "&, \\forall i \\in \\{1, \\dots, a_1\\}, j \\in \\{1, \\dots, b_2\\}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 與 $B.\\text{size}() = (5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (5, 4, 2)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 與 $B.\\text{size}() = (1995, 10, 12, 5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (1995, 10, 12, 5, 4, 2)$。\n",
        "\n",
        "在 `torch` 中張量乘法為 `torch.matmul(A, B)`。\n",
        "\n",
        "### 張量轉置（Tensor Transpose）\n",
        "\n",
        "令 $A$ 兩張量，$A.\\text{size}() = (a_1, a_2, ..., a_{n - 1}, a_n)$。定義 $A^{\\top}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top} &= (A_{a_1, a_2, \\dots, a_{n - 2}, a_{n - 1}, a_n})^{\\top} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_{n - 2}, a_n, a_{n - 1}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "即交換張量 $A$ 的最後兩個維度。若想要指定不同的維度 $i, j$ 進行轉置，則定義 $A^{\\top_{i, j}}$ 如下：\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^{\\top_{i, j}} &= (A_{a_1, a_2, \\dots, a_i, \\dots, a_j, \\dots, a_n})^{\\top_i, j} \\\\\n",
        "&= A_{a_1, a_2, \\dots, a_j, \\dots, a_i, \\dots, a_n}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 來說，$A^{\\top_{1, 2}}.\\text{size}() = (5, 3, 4)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 來說，$A^{\\top_{3, 4}}.\\text{size}() = (1995, 10, 12, 4, 5, 3)$。\n",
        "\n",
        "在 `torch` 中張量轉置為 `torch.transpose(A, i, j)`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ntJ0Jzbr-M",
        "outputId": "5faaf6fb-06c5-4cce-e0b8-49bc569ab0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 4, 3])\n",
            "torch.Size([5, 3, 2])\n",
            "torch.Size([5, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "# 張量乘法\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t25 = torch.ones(5, 4, 3)    \n",
        "# 宣告 Tensor 變數\n",
        "t26 = torch.ones(5, 3, 2)    \n",
        "# 進行張量乘法\n",
        "t27 = torch.matmul(t25, t26) \n",
        "\n",
        "# 輸出張量 t25 的維度\n",
        "print(t25.size())            \n",
        "# 輸出張量 t26 的維度\n",
        "print(t26.size())            \n",
        "# 輸出張量 t27 的維度\n",
        "print(t27.size())            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iELV2wlbbr-M",
        "outputId": "c9c89622-150c-4b50-9273-c7ddd4265988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 4])\n",
            "torch.Size([5, 3, 4])\n",
            "torch.Size([3, 4, 5])\n",
            "torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "# 張量轉置\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t28 = torch.ones(5, 4, 3)                \n",
        "\n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(torch.transpose(t28, 1, 2).size()) \n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(t28.transpose(1, 2).size())        \n",
        "\n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(torch.transpose(t28, 0, 2).size()) \n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(t28.transpose(0, 2).size())        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uwt4npXsbr-M"
      },
      "source": [
        "## 維度運算\n",
        "\n",
        "### 降維函數（Dimension Decreasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**小於輸入**張量維度。\n",
        "在機器學習中你幾乎必定會用到 `torch.argmax()`。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sum`|將所有數值相加|\n",
        "|`torch.max`|取出所有數值中最大者|\n",
        "|`torch.min`|取出所有數值中最小者|\n",
        "|`torch.argmax`|取出所有數值中最大者的位置|\n",
        "|`torch.argmin`|取出所有數值中最小者的位置|\n",
        "|`torch.mean`|取出所有數值的平均值|\n",
        "|`torch.var`|取出所有數值的變異數|\n",
        "|`torch.std`|取出所有數值的標準差|\n",
        "|`torch.squeeze`|移除數字為 1 的維度|\n",
        "\n",
        "### 增維函數（Dimension Increasing Function）\n",
        "\n",
        "以下函數將會使**輸出**張量維度**大於輸入**張量維度。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.cat`|串接多個相同維度的張量|\n",
        "|`torch.unsqueeze`|在指定的維度間增加 1 維度|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuN13HnNbr-M",
        "outputId": "c9c9fa52-3349-4cf1-f40e-a77be5b2befa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(78)\n",
            "tensor(78)\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([15, 18, 21, 24])\n",
            "tensor([10, 26, 42])\n",
            "tensor([10, 26, 42])\n",
            "tensor(12)\n",
            "tensor(12)\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([ 9, 10, 11, 12]),\n",
            "indices=tensor([2, 2, 2, 2]))\n",
            "\n",
            "tensor([ 9, 10, 11, 12])\n",
            "tensor([2, 2, 2, 2])\n",
            "\n",
            "tensor(1)\n",
            "tensor(1)\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "torch.return_types.min(\n",
            "values=tensor([1, 5, 9]),\n",
            "indices=tensor([0, 0, 0]))\n",
            "\n",
            "tensor([1, 5, 9])\n",
            "tensor([0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# 降維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t29 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 將張量 t29 中所有值相加\n",
        "print(torch.sum(t29))           \n",
        "# 將張量 t29 中所有值相加\n",
        "print(t29.sum())                \n",
        "\n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(torch.sum(t29, dim=0))    \n",
        "# 將張量 t29 中依照維度 0 將所有值相加\n",
        "print(t29.sum(dim=0))           \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(torch.sum(t29, dim=1))    \n",
        "# 將張量 t29 中依照維度 1 將所有值相加\n",
        "print(t29.sum(dim=1))           \n",
        "\n",
        "# 找出張量 t29 中最大值\n",
        "print(torch.max(t29))          \n",
        "# 找出張量 t29 中最大值\n",
        "print(t29.max())                \n",
        "print()\n",
        "\n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(torch.max(t29, dim=0))    \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值，並回傳最大值與對應位置\n",
        "print(t29.max(dim=0))           \n",
        "print()                         \n",
        "# 依照維度 0 找出張量 t29 中最大值\n",
        "print(torch.max(t29, dim=0)[0]) \n",
        "# 依照維度 0 找出張量 t29 中最大值位置\n",
        "print(torch.max(t29, dim=0)[1]) \n",
        "print()\n",
        "\n",
        "# 找出張量 t29 中最小值\n",
        "print(torch.min(t29))           \n",
        "# 找出張量 t29 中最小值\n",
        "print(t29.min())                \n",
        "print()\n",
        "\n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(torch.min(t29, dim=1))    \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值，並回傳最小值與對應位置\n",
        "print(t29.min(dim=1))           \n",
        "print()                         \n",
        "# 依照維度 1 找出張量 t29 中最小值\n",
        "print(torch.min(t29, dim=1)[0]) \n",
        "# 依照維度 1 找出張量 t29 中最小值位置\n",
        "print(torch.min(t29, dim=1)[1]) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.argmax(input, dim, keepdim=False) → LongTensor`\n",
        "[PyTorch Official Documentation](https://pytorch.org/docs/stable/generated/torch.argmax.html)\n",
        "- Parameters:\n",
        "    - input (Tensor) – the input tensor.\n",
        "    - dim (int) – the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
        "    - keepdim (bool) – whether the output tensor has dim retained or not. Ignored if dim=None."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWn28FWbr-M",
        "outputId": "00eb6da5-fc1d-4366-92a9-955a6a11ac4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: torch.Size([3, 4])\n",
            "=== argmax ===\n",
            "- flattened argmax:\n",
            "tensor(11)\n",
            "tensor(11)\n",
            "- reduced along dim 0:\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([2, 2, 2, 2])\n",
            "- reduced along dim 0:\n",
            "tensor([3, 3, 3])\n",
            "tensor([3, 3, 3])\n",
            "=== argmin ===\n",
            "tensor(0)\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t30 = torch.tensor([            \n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "print('shape:', t30.shape)\n",
        "print('=== argmax ===')\n",
        "# 找出張量 t30 中最大值的位置\n",
        "print('- flattened argmax:')\n",
        "print(torch.argmax(t30))        \n",
        "# 找出張量 t30 中最大值的位置\n",
        "# dim (int) – the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
        "print(t30.argmax())             \n",
        "print(\"- reduced along dim 0:\")\n",
        "# 依照維度 0 找出張量 t30 中最大值的位置，\n",
        "# 維度 0: dimension TO REDUCE，代表沿著維度 0 會被攤平，shape (3,4) 的 tensor 會變成 shape (4,) 的 tensor\n",
        "# 沿著 [1,5,9], [2, 6, 10], ... 找最大值的 index。\n",
        "print(torch.argmax(t30, dim=0)) \n",
        "# 依照維度 0 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=0))        \n",
        "\n",
        "print(\"- reduced along dim 0:\")\n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(torch.argmax(t30, dim=1)) \n",
        "# 依照維度 1 找出張量 t30 中最大值的位置\n",
        "print(t30.argmax(dim=1))        \n",
        "\n",
        "print('=== argmin ===')\n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(torch.argmin(t30))        \n",
        "# 找出張量 t30 中最小值的位置\n",
        "print(t30.argmin())                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJwYUYHgbr-M",
        "outputId": "1cb7e250-de49-49f5-bf82-7c5a950c23b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5000)\n",
            "tensor(6.5000)\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([5., 6., 7., 8.])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor([ 2.5000,  6.5000, 10.5000])\n",
            "tensor(13.)\n",
            "tensor(13.)\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([16., 16., 16., 16.])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor([1.6667, 1.6667, 1.6667])\n",
            "tensor(3.6056)\n",
            "tensor(3.6056)\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([4., 4., 4., 4.])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n",
            "tensor([1.2910, 1.2910, 1.2910])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t31 = torch.tensor([            \n",
        "    [1., 2., 3., 4.],\n",
        "    [5., 6., 7., 8.],\n",
        "    [9., 10., 11., 12.]\n",
        "])\n",
        "\n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31))         \n",
        "# 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean())              \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=0)) \n",
        "# 依照維度 0 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=0))        \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(torch.mean(t31, axis=1)) \n",
        "# 依照維度 1 計算張量 t31 中所有值的平均數\n",
        "print(t31.mean(axis=1))        \n",
        "\n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31))          \n",
        "# 計算張量 t31 中所有值的變異數\n",
        "print(t31.var())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(torch.var(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的變異數\n",
        "print(t31.var(axis=1))         \n",
        "\n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31))          \n",
        "# 計算張量 t31 中所有值的標準差\n",
        "print(t31.std())               \n",
        "\n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=0))  \n",
        "# 依照維度 0 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=0))         \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(torch.std(t31, axis=1))  \n",
        "# 依照維度 1 計算張量 t31 中所有值的標準差\n",
        "print(t31.std(axis=1))         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfXHwo9-br-M",
        "outputId": "bfaa7ffd-e9da-4a36-96f6-ffd3acfdfdac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "- before squeezing: torch.Size([1, 3])\n",
            "tensor([1, 2, 3])\n",
            "- after squeezing: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "# 宣告 Tensor 變數\n",
        "t32 = torch.tensor([        \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 移除張量 t32 中多餘的維度(為 1 的維度)\n",
        "t32_sq = torch.squeeze(t32) \n",
        "\n",
        "# 輸出張量 t32\n",
        "print(t32)                  \n",
        "# 輸出張量 t32 的維度\n",
        "print('- before squeezing:', t32.size())           \n",
        "# 輸出移除維度後的張量 t32\n",
        "print(t32_sq)               \n",
        "# 輸出移除維度後張量 t32 的維度\n",
        "print('- after squeezing:',t32_sq.size())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROt_wvYWbr-M",
        "outputId": "4a354c6d-1ba0-40b2-e3de-a27452320b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "torch.Size([4, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# 增維函數\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t33 = torch.tensor([                  \n",
        "    [1, 2, 3]\n",
        "])\n",
        "\n",
        "# 串接多個張量 t33\n",
        "t33_cat = torch.cat([                 \n",
        "    t33,\n",
        "    t33,\n",
        "    t33,\n",
        "    t33\n",
        "]) \n",
        "\n",
        "# 輸出串接後的張量 t33_cat\n",
        "print(t33_cat)                        \n",
        "# 輸出串接後的張量 t33_cat 維度\n",
        "print(t33_cat.size())                 \n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t34 = torch.tensor([                  \n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "print(t34)\n",
        "print(t34.size())\n",
        "\n",
        "# 對張量 t34 維度 0 增加 1 維\n",
        "t34_usq = torch.unsqueeze(t34, dim=0) \n",
        "\n",
        "# 輸出張量 t34 維度 0 增加 1 維後的結果\n",
        "print(t34_usq)                        \n",
        "# 輸出張量 t34 維度 0 增加 1 維後的維度\n",
        "print(t34_usq.size())                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpkIiN9Vbr-M"
      },
      "source": [
        "## 使用 GPU 運算\n",
        "\n",
        "上述的所有教學都是在 CPU 上進行運算，而大多數的深度學習框架都會提供操作 GPU 的介面幫助平型化運算。\n",
        "而 `torch` 與大部分的深度學習框架相同，使用 Nvidia 開發的 CUDA（Compute Unified Device Architecture）幫助使用 GPU 進行深度學習的運算（cuDNN）。\n",
        "\n",
        "使用 CUDA 操作平型化運算的流程為：\n",
        "\n",
        "1. 宣告 GPU 運算所需要佔用的記憶體（`cudaMalloc`）\n",
        "2. 定義每個平型化運算節點的運算內容\n",
        "3. 在主記憶體上創造資料（`malloc`）\n",
        "4. 將資料搬移至 GPU 的記憶體（`cudaMemcpy`）\n",
        "5. 每個節點獨立運算\n",
        "6. 將計算結果搬回至主記憶體（`memcpy`）\n",
        "7. 釋放 GPU 的記憶體（`cudaFree`）\n",
        "\n",
        "而在 `torch` 中將以上流程簡化成以下兩種方法\n",
        "\n",
        "- 宣告 `torch.Tensor` 變數時使用 `device='cuda:0'` 參數將變數宣告於 GPU 記憶體第0顆（0-indexed）。\n",
        "- 對已經創造於主記憶體的 `torch.Tensor` 變數使用 `torch.to('cuda:0')` 搬移至 GPU 記憶體第0顆（0-indexed）。\n",
        "```python\n",
        "torch.tensor([1., 2., 3.], device='cuda:0') # 使用 device 參數將變數宣告於 GPU 記憶體\n",
        "torch.tensor([1., 2., 3.]).to('cuda:0')     # 使用 to 將變數搬移至 GPU 記憶體\n",
        "```\n",
        "\n",
        "宣告於 GPU 或搬移至 GPU 後，之後所有的運算便會在 GPU 上進行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djuqIr7vbr-M",
        "outputId": "9c908a0d-17f7-4119-eba8-2b31a63bc5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 使用 GPU 運算\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # 使用 device 參數創造張量於 GPU 上\n",
        "    t35 = torch.tensor([1., 2., 3.], device='cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled')     \n",
        "    t35 = None\n",
        "    \n",
        "# 輸出張量 t35\n",
        "print(t35)                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKtEO_4Nbr-M",
        "outputId": "bc81130a-0364-46f8-f285-4e9dc15e71c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    # 使用 to 將張量搬移至 GPU 上\n",
        "    t36 = torch.tensor([1., 2., 3.]).to('cuda:0') \n",
        "else:\n",
        "    # 如果不支援 cuda 則出現 error\n",
        "    print('torch not compiled with CUDA enabled') \n",
        "    t36 = None\n",
        "    \n",
        "# 輸出張量 t36\n",
        "print(t36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dZ9N1Ybr-M",
        "outputId": "cfbd5e50-4101-4edb-8ed4-4f57532f2ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "tensor([1., 2., 3.], device='cuda:0')\n",
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "\n",
        "# 根據 device 創造張量\n",
        "t37 = torch.tensor([1., 2., 3.], device=device) \n",
        "# 使用 to 搬移張量至指定的裝置\n",
        "t38 = torch.tensor([1., 2., 3.]).to(device)     \n",
        "\n",
        "# 輸出張量 t37\n",
        "print(t37)                                      \n",
        "# 輸出張量 t38\n",
        "print(t38)                                      "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLKGH_vbr-M"
      },
      "source": [
        "## 深度學習\n",
        "\n",
        "![Deep Learning](https://miro.medium.com/max/1000/1*51D0MqtqHu3h2vTE5oJ-7g.png)\n",
        "![Deep Learning vs. Machine Learning](https://learn.microsoft.com/zh-tw/azure/machine-learning/media/concept-deep-learning-vs-machine-learning/ai-vs-machine-learning-vs-deep-learning.png)\n",
        "### 深度學習要幹嘛？\n",
        "上課教的 SVM, Bayes 等等的模型算是 （傳統）Machine Learning 的範疇，比較偏向建立於統計的假設的數學統計模型。而深度學習則是機器學習內的一個子集合（subset），他是以類神經網路來模擬人類大腦的神經元之間的互動。\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "使用 `torch` 進行深度學習主要包含以下步驟：\n",
        "1. 將資料轉換成 `torch.Tensor`，使用 Dataset 和 Dataloader 包裝管理資料。\n",
        "2. 使用 `torch.nn` 建立深度學習模型架構。\n",
        "3. 從 `torch.optim` 選擇最佳化工具。\n",
        "4. 選擇目標函數。\n",
        "5. 訓練深度學習模型（train）。\n",
        "6. 測試深度學習模型（test, inference）。\n",
        "以下範例：使用兩層全連接層做 Polynomial Regression 任務。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 資料集\n",
        "1. 使用 `torch.utils.data.Dataset` 將資料集轉換成 `torch.Tensor`\n",
        "2. 使用 `torch.utils.data.DataLoader` 將資料集以批次（mini-batch）取出\n",
        "3. （Optional）額外定義 `collate_fn` 將抽樣的資料整理成固定的格式\n",
        "#### batch (mini-batch)\n",
        "每一次更新參數時，模型以整個 batch 中`batch_size` 筆的資料，看過一遍，然後更新一次參數。一個 epoch 代表模型看過整個資料集一次。\n",
        "最極端的兩個狀況：batch_size = 1, batch_size = 資料集大小\n",
        "- batch_size 小：計算成本昂貴，gradient 噪音多，但對最佳化的方向較為準確。\n",
        "- batch_size 大：計算成本低，gradient 噪音少，但神奇的是（？）實驗結果說對最佳化的方向較不準確。\n",
        "- batch_size 怎麼設？看任務內容（調參技術之一）。\n",
        "相關參考影片:\n",
        "[【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)](https://www.youtube.com/watch?v=zzbr1h9sF54)\n",
        "\n",
        "我們的資料長這樣：$$y = 2x^2 + 3x + 17$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFiFnsh5br-N",
        "outputId": "912e0668-6434-4d31-8111-bb111208753d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "(tensor(0.6526), tensor(19.8095))\n"
          ]
        }
      ],
      "source": [
        "# 資料集\n",
        "\n",
        "# 匯入資料集 base class\n",
        "from torch.utils.data import Dataset \n",
        "\n",
        "# 繼承 base class 創造資料集\n",
        "class MyDataset(Dataset):            \n",
        "    # 給予資料集大小，並隨機創造資料\n",
        "    def __init__(self, size):        \n",
        "        self.x = torch.rand(size) \n",
        "        self.y = 2 * self.x ** 2 + 3 * self.x + 17\n",
        "        \n",
        "    # 定義總資料數\n",
        "    def __len__(self):               \n",
        "        return len(self.x)\n",
        "    \n",
        "    # 定義取出單一資料的方法\n",
        "    def __getitem__(self, index):    \n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "# 創造資料集\n",
        "my_dataset = MyDataset(10)           \n",
        "\n",
        "# 取得總資料數\n",
        "print(len(my_dataset))               \n",
        "# 取出單一資料\n",
        "print(my_dataset[0])                 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWP1moMObr-N",
        "outputId": "703e9283-8e0f-4f81-e5c4-8e008071aed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([3, 1]) torch.Size([3, 1])\n",
            "torch.Size([1, 1]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 匯入資料集抽樣工具\n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "# 定義格式化的方法\n",
        "def collate_fn(batch):                  \n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    \n",
        "    for x, y in batch:\n",
        "        x_list.append([x])              \n",
        "        y_list.append([y])              \n",
        "    # 最終回傳的維度為 [(batch_size, n_features), (batch_size, label_dim)]\n",
        "    return [torch.tensor(x_list), torch.tensor(y_list)] \n",
        "\n",
        "# 創造 DataLoader 實例\n",
        "batch_size = 3\n",
        "my_data_loader = DataLoader(            \n",
        "    my_dataset,                 # 對資料集 my_dataset 進行抽樣\n",
        "    batch_size=batch_size,      # 設定每次抽樣的數量                 \n",
        "    shuffle=True,               # 設定隨機抽樣                  \n",
        "    collate_fn=collate_fn       # 指定格式化的方法    \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for data in my_data_loader:             \n",
        "    # 輸出抽樣結果\n",
        "    assert len(data) == 2\n",
        "    print(data[0].size(), data[1].size())\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Q. 為什麼要將每個 `x` 轉換成 `[x]`？\n",
        "在此方法中，將每個 `x` 轉換成 `[x]` 的形式是因為我們希望每個 `x` 在 tensor 中都有一個單獨的維度，以便後續能夠進行批次運算。\n",
        "如果直接將每個 `x` append 到列表中，則會產生一個沒有額外維度的列表，\n",
        "這樣在後續批次處理時會出現維度不一致的問題，無法進行運算。\n",
        "Try append x, y alone and you will see `RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x3 and 1x10)` in `model.forward()`。\n",
        "#### Q. 為什麼最後一個 batch 內的形狀是 `torch.Size([1, 1]) torch.Size([1, 1])`? `batch_size` 不是 3 嗎？\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqeXVb2e0tlT"
      },
      "source": [
        "### 建立模型\n",
        "\n",
        "可以使用 `torch.nn` 現成的模型進行深度學習，``torch`` 提供很多「神經層」（layer），可以用來建立模型的架構（architecture）。\n",
        "- 面對哪個任務應該用什麼模型？\n",
        "- 模型的輸入輸出的形式要如何定義？\n",
        "- 模型要怎麼架構？\n",
        "- 沒辦法一一的講，在[NN中文文本分類](NN-中文文本分類.ipynb)會講怎麼架構一顆 RNN 來做文本分類任務。其他神經層可以去[torch.nn](https://pytorch.org/docs/stable/nn.html)看看，怎麼架構只能先了解原理然後多查多練習：[PyTorch Tutorial](https://pytorch.org/tutorials/)。\n",
        "\n",
        "|模型介面|名稱|常見用途|\n",
        "|-|-|-|\n",
        "|`torch.nn.Linear`|線性層（Linear Layer）|轉換特徵|\n",
        "|`torch.nn.Embedding`|嵌入層（Embedding Layer）|學習特徵向量表達法|\n",
        "|`torch.nn.Conv1d`|1 維卷積層（1-Dimensional Convolution Layer）|抽取連續資料區域特徵|\n",
        "|`torch.nn.Conv2d`|2 維卷積層（2-Dimensional Convolution Layer）|抽取平面圖片區域特徵|\n",
        "|`torch.nn.Conv3d`|3 維卷積層（3-Dimensional Convolution Layer）|抽取立體圖片區域特徵|\n",
        "|`torch.nn.RNN`|循環神經網路（Recurrent Neural Network）|壓縮動態長度文字|\n",
        "|`torch.nn.LSTM`|長短期記憶神經網路（Long Short-Term Memory）|有效壓縮動態長度文字|\n",
        "|`torch.nn.Transformer`|多面向自我注意力機制模型（Multi-Head Self-Attention）|機器翻譯|\n",
        "\n",
        "如果需要使用深度學習模型，必須透過繼承 `torch.nn.Module` 來定義**模型結構**與**運算流程**：\n",
        "使用 `nn.Module` 定義模型時必須要記得以下規則：\n",
        "\n",
        "- 在類別方法 `__init__` 中定義模型結構\n",
        "    - 必須要執行 `super(MyModel, self).__init__()`\n",
        "    - 為什麼需要：[colab link](https://colab.research.google.com/drive/1LL1RVaoGoGYE68HCaMOEVSCR8bEPgqqc?usp=sharing)\n",
        "- 必須透過定義類別方法 `forward` 才能定義計算流程"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QWrkuLw005aB"
      },
      "source": [
        "\n",
        "### 啟動函數（Activation Functions）\n",
        "\n",
        "若模型需要啟動函數，可以使用 `torch.nn.functional` 中事先定義好的啟動函數：\n",
        "常見的啟動函數包含：\n",
        "\n",
        "|啟動函數|名稱|定義|數值範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.nn.functional.relu`|ReLU|$$f(x_i) = \\max(0, x_i)$$|$$\\mathbb{R}^+$$|\n",
        "|`torch.nn.functional.softmax`|Softmax|$$f(x_i) = \\frac{e^{x_i}}{\\sum_{j = 0}^n e^{x_j}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.sigmoid`|Sigmoid|$$f(x_i) = \\frac{1}{1 + e^{-x_i}}$$|$$[0, 1]$$|\n",
        "|`torch.nn.functional.tanh`|Hyperbolic Tangent|$$f(x_i) = \\frac{e^{x_i} - e^{-x_i}}{e^{x_i} + e^{-x_i}}$$|$$[-1, 1]$$|\n",
        "\n",
        "<img src=\"https://i.imgur.com/2T2K61V.png\"  width=\"600\" height=\"300\">\n",
        "\n",
        "#### Why do we need Activation Functions? \n",
        "所有 Activation functions 的大略概念都是 \"creates a non-linearity in your output\"，它們的存在使模型\n",
        "能夠 fit 在非線性更為複雜的資料上。Sigmoid 是最初始的，但是因為它的數值範圍落在 0 到 0.25，gradient 在後向傳播時會消失，因此漸漸少用（相關影片：[Sigmoid and Vanishing Gradient](https://www.youtube.com/watch?v=kGAo32JgY48)）。ReLU (Rectified Linear Units) 則取而代之，它是把負數先轉為零，正數就什麼都不做直接離開 node。用意是把負值關係排除掉，可以抵抗 gradient vanishing。ReLU 有各種變形：LeakyReLU、alpha ReLU 等等。Tanh 是 Sigmoid 的變形，它的數值範圍是 -1 到 1，因此它的 gradient 不會消失，但是它的輸出是 zero-centered，因此在訓練時會比較難收斂。Softmax $softmax(\\overrightarrow{a}) = \\frac{e^{a_i}}{\\sum_k{e^{a_k}}}$是用來把輸出轉為機率分佈，讓輸出的數值總和為 1，可以用來做（單一/多）分類的機率預測。\n",
        "\n",
        "#### The reasons we need `torch.argmax()`.\n",
        "<img src=\"https://img-blog.csdn.net/20180902220822202?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JpdGNhcm1hbmxlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"  width=\"400\">\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### `torch.nn.Linear`\n",
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/Screenshot-from-2020-02-03-22-14-21-300x195.png)\n",
        "- $X$: input \n",
        "- $W, b$: the parameters we would like to fit. \n",
        "- $Z$: the output we would like to get. \n",
        "- If multiple layers are stacked, $Z$ will be the input of the next layer. In general, we would like the FINAL layer's output to be close \n",
        "to the ground truth $Y$. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmmUqpKLbr-N",
        "outputId": "8c4252de-75a9-4bac-e425-84fb8e3e4017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_x shape: torch.Size([3, 1])\n",
            "batch_y shape: torch.Size([3, 1])\n",
            "pred_y shape: torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# 建立模型\n",
        "\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn                   \n",
        "# 匯入啟動函數\n",
        "import torch.nn.functional as F         \n",
        "\n",
        "# 模型需要繼承自 nn.Module\n",
        "class MyModel(nn.Module):               \n",
        "    # 定義模型結構, 輸入層維度, 隱藏層維度, 輸出層維度\n",
        "    def __init__(self,                  \n",
        "                 in_dim,                \n",
        "                 hid_dim,               \n",
        "                 out_dim):              \n",
        "\n",
        "        # 繼承 nn.Module 所有屬性\n",
        "        super(MyModel, self).__init__() \n",
        "        \n",
        "        # 創造線性層 self.layer1\n",
        "        self.layer1 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=in_dim,         \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=hid_dim        \n",
        "        )\n",
        "        # 創造線性層 self.layer2\n",
        "        self.layer2 = nn.Linear(        \n",
        "            # 設定線性層輸入維度\n",
        "            in_features=hid_dim,        \n",
        "            # 設定線性層輸出維度\n",
        "            out_features=out_dim      \n",
        "        )\n",
        "        \n",
        "    # [Important] 定義運算流程\n",
        "    def forward(self, batch_x): \n",
        "        # Why use ReLU?       \n",
        "        # 使用線性層 self.layer1 輸入 batch_x 計算得到 h\n",
        "                                     # batch_x's shape: (batch_size, in_dim)\n",
        "        h = self.layer1(batch_x)     # h = Wx + b, h's shape: (batch_size, hid_dim)   \n",
        "                                    # 使用 ReLU 啟動函數輸入 h 得到 a\n",
        "        a = F.relu(h)                # a = ReLU(h), a's shape: (batch_size, hid_dim)        \n",
        "                                    # 使用線性層 self.layer2 輸入 a 計算得到 y\n",
        "        y = self.layer2(a)           # y = Wa + b, y's shape: (batch_size, out_dim) \n",
        "        \n",
        "        \n",
        "        # 輸出 y\n",
        "        return y                        \n",
        "    \n",
        "# 創造 MyModel 模型實例\n",
        "my_model = MyModel(                     \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=10,                         \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    print('batch_x shape:', batch_x.shape)\n",
        "    print('batch_y shape:', batch_y.shape) \n",
        "    pred_y = my_model(batch_x)   # this part calls my_model.forward(batch_x)       \n",
        "    print('pred_y shape:', pred_y.shape) # should be the same as batch_y in most of the cases, sometimes this should be postprocessed \n",
        "    # to match the shape of batch_y, HERE is the simplest case that the shape of pred_y is the same as batch_y\n",
        "    break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOTX8Jw1Ci2"
      },
      "source": [
        "### 目標函數（Objective Functions）\n",
        "\n",
        "使用 `torch.nn` 中事先定義好的目標函數進行模型最佳化，計算模型預測結果與標記訓練資料的誤差值，並透過向後傳播（Back Propagation）演算法取得相對於誤差值的梯度（Gradient）。\n",
        "- 基本上就是去計算每個參數的偏微分。\n",
        "- 和 gradient descent 是完全相同的概念，只是在神經網路中 neurons 數量龐大，因此需要有有效率的演算法去計算 gradient。這個演算法就是 back propagation。\n",
        "- 使用了 Chain Rule 的概念。計算每個參數內對 cost function 的偏微分。這個 cost function 就是「正確答案與預測答案的距離」，更適當的名字是 loss function。\n",
        "- 對一個 weight matrix $W \\in R^{a \\times b}$ 內，$W_{ij}$ 是 $l$層$i$ 神經元與 $l-1$ 層 $j$ 神經元之間的權重。\n",
        "    - ![](https://i.imgur.com/fk5HCm4.png)\n",
        "- 想更新這個權重值，就要計算 $\\frac{\\partial C}{\\partial W_{ij}}$，其中 $C$ 是 loss function。使用 Chain Rule，可以拆解成 $\\frac{\\partial C}{\\partial W_{ij}} =  \\frac{\\partial C}{\\partial Z_{i}} \\frac{\\partial Z_{i}}{\\partial W_{ij}}$，$Z_i$ 是 $i$ 所在的神經元的輸入值，$a^i$ 是 $i$ 神經元的輸出值。（下圖上標意義解釋：上標 $l$ 是你的層數（你現在更新的是哪一層的權重矩陣？實際上每一層都需要算），$r$ 是第$r$組資料）。所以這兩個 terms 分別要怎麼計算？請去看下面第一個影片。\n",
        "    - ![](https://i.imgur.com/3EihDh7.png)\n",
        "- Resources (a lot of maths): \n",
        "    - [DNN Back propagation](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/index.html)\n",
        "    - [Computational Graph 的角度去看 Back propagation](https://www.youtube.com/watch?v=-yhm3WdGFok)\n",
        "\n",
        "```python\n",
        "# 匯入神經網路模型\n",
        "import torch.nn as nn             \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()          \n",
        "\n",
        "# 計算 batch_x 得到 pred_y\n",
        "pred_y = my_model(batch_x)        \n",
        "# 計算 pred_y 與 batch_y 的均方誤差\n",
        "loss = criterion(pred_y, batch_y) \n",
        "\n",
        "# 使用向後傳播計算梯度\n",
        "loss.backward()                   \n",
        "```\n",
        "\n",
        "常見的目標函數包含：\n",
        "\n",
        "|目標函數|名稱|\n",
        "|-|-|\n",
        "|`torch.nn.MSELoss`|均方誤差（Mean Square Error）|\n",
        "|`torch.nn.CrossEntropyLoss`|交叉熵（Cross Entropy）|\n",
        "|`torch.nn.BCELoss`|二元交叉熵（Binary Cross Entropy）|\n",
        "|`torch.nn.NLLLoss`|負對數似然（Negative Log Likelihood）|\n",
        "\n",
        "## MSELoss \n",
        "- [PyTorch Documentation](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
        "<img src=\"https://i.imgur.com/dqKaK25.png\"  width=\"400\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LdZoW-abr-N",
        "outputId": "cbd3f16c-31cd-4ced-f4c4-1772b491c74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(255.2659, grad_fn=<MseLossBackward0>)\n",
            "tensor(323.1541, grad_fn=<MseLossBackward0>)\n",
            "tensor(333.6842, grad_fn=<MseLossBackward0>)\n",
            "tensor(487.3440, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 目標函數\n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    print(loss)\n",
        "    \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()                     "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "igh-yFNr1K3o"
      },
      "source": [
        "### 最佳化（Optimization）\n",
        "\n",
        "![Gradient Descent](https://img-blog.csdnimg.cn/20181110102438617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpX2tfeQ==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "使用 `torch.optim` 中的不同的最佳化策略進行梯度下降（Gradient Descent）演算法：\n",
        "\n",
        "$$\n",
        "\\theta_t = \\theta_{t - 1} - \\text{lr} \\cdot \\nabla \\mathcal{L}(x)\n",
        "$$\n",
        "\n",
        "進行最佳化時需要注意以下事項：\n",
        "\n",
        "- 創造最佳化工具時必須指定哪些參數被更新\n",
        "    - 使用 `model.parameters()` 取得模型中所有可以被更新的參數\n",
        "    - 學習率（Learning Rate）負責決定模型參數更新的幅度，可以透過 `lr` 參數設定\n",
        "- 必須先計算誤差並且透過誤差向後傳播（`loss.backward()`），才能執行梯度下降更新參數（`optimizer.step()`）\n",
        "\n",
        "#### Stochastic Gradient Descent (SGD)\n",
        "<img src=\"https://www.samvitjain.com/blog/assets/gradient-descent/comparison.png\"  width=\"350\">\n",
        "\n",
        "- SGD 的核心概念就是用 小batch 訓練， GD 可以說就是 batch_size = dataset_size 的狀態。\n",
        "- SGD 比 GD 更適合用於深度學習模型的訓練，因為它可以更快地收斂、更有效地處理大資料集，並且因為具有更大的隨機性更容易跳出 local minima。不過，SGD 也有一些缺點，例如可能會出現收斂不穩定、震盪等問題。為了解決這些問題，有許多基於SGD的改進算法被提出，例如 Momentum、Adagrad、RMSprop、Adam 等。\n",
        "- [(PyTorch Documentation) Stochastic Gradient Descent](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)\n",
        "- [NTU EE ML Lecture 3-1: Gradient Descent](https://www.youtube.com/watch?v=yKKNr-QKz2Q&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "FqC3vN9gbr-N"
      },
      "outputs": [],
      "source": [
        "# 最佳化\n",
        "\n",
        "# 匯入計算梯度下降演算法的工具\n",
        "from torch.optim import SGD             \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    # 設定計算梯度下降的目標\n",
        "    my_model.parameters(),              \n",
        "    # 設定學習率\n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 透過 my_data_loader 對資料集 my_dataset 進行抽樣\n",
        "for batch_x, batch_y in my_data_loader: \n",
        "    \n",
        "    # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "    pred_y = my_model(batch_x)          \n",
        "    \n",
        "    # 計算 pred_y 與 batch_y 的均方誤差\n",
        "    loss = criterion(pred_y, batch_y)   \n",
        "    # 使用向後傳播計算梯度\n",
        "    loss.backward()\n",
        "    \n",
        "    # 使用梯度下降更新模型參數\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 清空計算過後的梯度值\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1tspVHbr-N",
        "outputId": "51d33a4c-331e-4c32-82bc-471739c4065b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, training loss: 291.6145309448242\n",
            "Epoch 0, testing loss: 291.96514587402345\n",
            "Epoch 1, training loss: 237.84595489501956\n",
            "Epoch 1, testing loss: 238.10436553955077\n",
            "Epoch 2, training loss: 192.33082656860353\n",
            "Epoch 2, testing loss: 192.51479492187497\n",
            "Epoch 3, training loss: 153.82884826660157\n",
            "Epoch 3, testing loss: 153.9531997680664\n",
            "Epoch 4, training loss: 121.50878868103028\n",
            "Epoch 4, testing loss: 121.58625717163086\n"
          ]
        }
      ],
      "source": [
        "# 驗證\n",
        "\n",
        "# 如果有可用 GPU 時採用 GPU cuda:0\n",
        "if torch.cuda.is_available():                   \n",
        "    device = torch.device('cuda:0')\n",
        "# 若無 GPU 可用則使用 CPU\n",
        "else:                                           \n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# 創造訓練資料集\n",
        "train_dataset = MyDataset(1000)         \n",
        "# 創造測試資料集\n",
        "test_dataset = MyDataset(500)           \n",
        "\n",
        "# 設定超參數\n",
        "\n",
        "# 設定每次抽樣的數量\n",
        "batch_size = 50                         \n",
        "# 設定資料集總訓練次數\n",
        "n_epoch = 5                          \n",
        "# 設定隱藏層維度\n",
        "hid_dim = 100                            \n",
        "\n",
        "# 創造 DataLoader 實例\n",
        "train_data_loader = DataLoader(         \n",
        "    # 對資料集 train_dataset 進行抽樣\n",
        "    train_dataset,                      \n",
        "    # 設定每次抽樣的數量\n",
        "    batch_size=batch_size,              \n",
        "    # 設定隨機抽樣\n",
        "    shuffle=True,                       \n",
        "    # 指定格式化的方法\n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "# 創造 DataLoader 實例\n",
        "test_data_loader = DataLoader(          \n",
        "    test_dataset,                       \n",
        "    batch_size=batch_size,              \n",
        "    shuffle=True,                       \n",
        "    collate_fn=collate_fn               \n",
        ")\n",
        "\n",
        "# 創造 MyModel 模型實例\n",
        "model = MyModel(                        \n",
        "    # 設定輸入層維度\n",
        "    in_dim=1,                           \n",
        "    # 設定隱藏層維度\n",
        "    hid_dim=hid_dim,                    \n",
        "    # 設定輸出層維度\n",
        "    out_dim=1                           \n",
        ")\n",
        "# 將模型搬移至 GPU\n",
        "model = model.to(device)                \n",
        "\n",
        "# 創造均方誤差計算工具\n",
        "criterion = nn.MSELoss()                \n",
        "\n",
        "# 創造計算隨機梯度下降的工具\n",
        "optimizer = SGD(                        \n",
        "    model.parameters(),                 \n",
        "    lr=0.0001                           \n",
        ")\n",
        "\n",
        "# 總共訓練 n_epoch 次\n",
        "for epoch in range(n_epoch):            \n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        # 將訓練資料搬移至 GPU\n",
        "        batch_x = batch_x.to(device)    \n",
        "        # 將訓練資料標記搬移至 GPU\n",
        "        batch_y = batch_y.to(device)    \n",
        "        \n",
        "        # 自動呼叫 forward 計算 batch_x 得到 pred_y\n",
        "        pred_y = model(batch_x)  # shape: (batch_size, 1)      \n",
        "        # 計算 pred_y (預測標記）與 batch_y （真實標記）的均方誤差\n",
        "        loss = criterion(pred_y, batch_y) \n",
        "        \n",
        "        # 使用向後傳播計算梯度\n",
        "        loss.backward()                 \n",
        "        # 使用梯度下降更新模型參數\n",
        "        optimizer.step()\n",
        "        # 清空計算過後的梯度值\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # 此區塊不會計算梯度\n",
        "    with torch.no_grad():               \n",
        "        # 統計訓練資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in train_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(train_data_loader)\n",
        "        \n",
        "        print('Epoch {}, training loss: {}'.format(epoch, total_loss))\n",
        "        \n",
        "        # 統計測試資料誤差\n",
        "        total_loss = 0                  \n",
        "        for batch_x, batch_y in test_data_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            \n",
        "            pred_y = model(batch_x)\n",
        "            loss = criterion(pred_y, batch_y)\n",
        "            \n",
        "            total_loss += float(loss) / len(test_data_loader)\n",
        "            \n",
        "        print('Epoch {}, testing loss: {}'.format(epoch, total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "JkmZGlVEbr-O",
        "outputId": "cdebfe36-079d-4e4f-a458-0b29bd72d253"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in train_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出訓練資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出訓練資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "        \n",
        "    plt.title('Training data performance')\n",
        "    plt.show()\n",
        "    \n",
        "    for batch_x, batch_y in test_data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        pred_y = model(batch_x)\n",
        "        \n",
        "        batch_x = batch_x.to('cpu')\n",
        "        batch_y = batch_y.to('cpu')\n",
        "        pred_y = pred_y.to('cpu')\n",
        "        # 畫出測試資料答案分佈\n",
        "        plt.scatter(batch_x, batch_y, color='red') \n",
        "        # 畫出測試資料預測分佈\n",
        "        plt.scatter(batch_x, pred_y, color='blue') \n",
        "    \n",
        "    plt.title('Testing data performance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMbkzFUU1S2K"
      },
      "source": [
        "### 測試\n",
        "\n",
        "深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 `with torch.no_grad():`：\n",
        "\n",
        "### 儲存 & 載入模型\n",
        "\n",
        "使用 `torch.save()` 配合 `model.state_dict()` 儲存訓練後的模型參數；\n",
        "使用 `model.load_state_dict()` 配合 `torch.load()` 載入儲存的訓練過的模型參數。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Pnq25QSFbr-O"
      },
      "outputs": [],
      "source": [
        "# 儲存 & 載入模型\n",
        "\n",
        "# 儲存模型參數\n",
        "# torch.save(model.state_dict(), './data/model.ckpt')    \n",
        "# 載入模型參數\n",
        "# model.load_state_dict(torch.load('./data/model.ckpt')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VHNeeFnbr-O"
      },
      "source": [
        "## 練習\n",
        "\n",
        "### 練習 1：調整超參數\n",
        "\n",
        "請試著更改前述範例中的超參數讓模型表現變好：\n",
        "\n",
        "- 增加訓練次數 `n_epoch`\n",
        "- 增大單一訓練資料次數 `batch_size`\n",
        "- 增大隱藏層的維度 `hid_dim`\n",
        "- 更改啟動函數 `F.relu`\n",
        "\n",
        "### 練習 2：加深模型\n",
        "\n",
        "請試著更改前述範例中的模型深度讓模型表現變好：\n",
        "\n",
        "- 增加 1 個或多個 `nn.Linear`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 簡單的機器學習任務練習\n",
        "- MNIST 資料集：手寫數字圖像分類任務 (Image Classification)\n",
        "  - ![](https://thumbs.gfycat.com/AdorableJoyfulLemming-max-1mb.gif)\n",
        "  - MNIST 一筆 data $\\in \\mathbb{R}^{784}$ （784 維的 feature vector）\n",
        "  - [datahacker/cnn/#005 PyTorch - Convolutional Neural Network on MNIST Handwritten Digit Recognition in PyTorch 1.3.ipynb](https://github.com/maticvl/dataHacker/blob/master/CNN/%23005%20PyTorch%20-%20Convolutional%20Neural%20Network%20on%20MNIST%20Handwritten%20Digit%20Recognition%20in%20PyTorch%201.3.ipynb)\n",
        "- Kaggle Titanic Survival Prediction (Feature Classification)\n",
        "    - [Example Notebook: Introduction to Pytorch (a very gentle start)](https://www.kaggle.com/code/frtgnn/introduction-to-pytorch-a-very-gentle-start)\n",
        "- Real-and-Fake Text Classification (Text Classifcation)\n",
        "    - [A step-by-step guide: LSTM Text Classification Using Pytorch](https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0)\n",
        "- 分類問題是最簡單也是最核心的，所有任務（文字生成 text-generation，文字翻譯 translation，問答 QA，序列標注 sequence labeling 等等）全都是分類問題的變形而已，只是因為資料形式不同，這些任務的資料前處理與模型預測後處理會比分類問題更加複雜和不直覺。建議從最直觀的分類問題下手練習。\n",
        "- 例子都是提供 PyTorch 架構的範例。為什麼選擇 PyTorch 進行教學與開發？PyTorch 文檔詳細，community 活躍。Keras 較為簡單但相對的彈性低，對想要在模型內開發的人而言十分侷限（如果之後想要從事 ML 相關，使用 keras 者勢必需要轉換跑道）。Tensorflow 對初學者來說相對不友善。\n",
        "\n",
        "### 推薦深度學習或自然語言處理學習資源\n",
        "  - 比較輕鬆入門深度學習的方式(老師很好笑，數學很硬）：\n",
        "    - [Hung-Yi Lee 's NTU ML Course Website](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)\n",
        "      - 如果想要更加熟悉，可以寫裡面的作業（大概寫 Regression, Classifcation, CNN, Self-attention, Transformer, BERT 就能夠 cover 這堂課需要的所有技能，比較有趣的作業可以寫看看 Explainable AI）。\n",
        "    - [Hung Yi Lee's Youtube Channel](https://www.youtube.com/@HungyiLeeNTU)\n",
        "  - 史丹佛的教科書/NTU 資訊所 NLP 課程用書：[Stanford Textbook: Speech & language Processing](https://web.stanford.edu/~jurafsky/slp3/) \n",
        "這本書寫很仔細，從 sequence models 和 word embeddings 開始講，後面的章節是分成多個不同 NLP 任務講解。想要知道一些 NLP 的基礎，詳讀以下章節應該可以收穫良多：\n",
        "    - 6:\tVector Semantics and Embeddings\t6: Vector Semantics\t[new in this edition]\n",
        "    - 7:\tNeural Networks and Neural Language Models\t7: Neural Networks [new in this edition]\n",
        "    - 9:\tRNNs and LSTMs\t\t[new in this edition]\n",
        "    - 10:\tTransformers and Pretrained Language Models\n",
        "  - Andrew Ng's Machine Learning Resources\n",
        "    - [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models)\n",
        "  - [PyTorch Introduction by NTU EE](https://colab.research.google.com/drive/1Xed5YSpLsLfkn66OhhyNzr05VE89enng#scrollTo=jifMOIcNMTh5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "5d79344b50f250bbd6ad2de2adfaeedd1b2740d625477f4cf63f23f68cf7a998"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
